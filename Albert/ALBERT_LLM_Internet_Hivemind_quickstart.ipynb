{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDRyPYFJlIy0",
        "outputId": "1f391762-6145-48fe-b0ac-77642ed1db59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-11 16:15:40--  https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 13.248.244.96, 35.71.179.82, 75.2.60.68, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|13.248.244.96|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14796857 (14M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-v3-stable-linux-amd64.tgz.1’\n",
            "\n",
            "ngrok-v3-stable-lin 100%[===================>]  14.11M  7.27MB/s    in 1.9s    \n",
            "\n",
            "2024-12-11 16:15:43 (7.27 MB/s) - ‘ngrok-v3-stable-linux-amd64.tgz.1’ saved [14796857/14796857]\n",
            "\n",
            "ngrok\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ],
      "source": [
        "# ngrok\n",
        "!wget https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz\n",
        "!tar -xvzf ngrok-v3-stable-linux-amd64.tgz\n",
        "\n",
        "# 替换 YOUR_NGROK_AUTH_TOKEN 为你的 ngrok 认证令牌\n",
        "!./ngrok authtoken 2q0WqdIL8HEbZMSU8CXwTFZrR5y_2A9nKPfF8zj8mC2tGkiF1\n",
        "!pip install pyngrok\n",
        "from pyngrok import ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DtA5PA1yakb",
        "outputId": "2115eaef-de37-4e7e-febc-10aaec11d4b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.0.1\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (3.30.5)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 triton-2.0.0\n",
            "Collecting torchvision==0.12.0\n",
            "  Downloading torchvision-0.12.0-cp310-cp310-manylinux1_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (4.12.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (2.32.3)\n",
            "Collecting torch==1.11.0 (from torchvision==0.12.0)\n",
            "  Downloading torch-1.11.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (11.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (2024.8.30)\n",
            "Downloading torchvision-0.12.0-cp310-cp310-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-1.11.0-cp310-cp310-manylinux1_x86_64.whl (750.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1\n",
            "    Uninstalling torch-2.0.1:\n",
            "      Successfully uninstalled torch-2.0.1\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu121\n",
            "    Uninstalling torchvision-0.20.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.13.2 requires torch>=1.13.0, but you have torch 1.11.0 which is incompatible.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 1.11.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.11.0 torchvision-0.12.0\n",
            "1.11.0+cu102\n",
            "0.12.0+cu102\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.0.1\n",
        "!pip install torchvision==0.12.0\n",
        "import torch\n",
        "import torchvision\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VmBR9wXRhmhT",
        "outputId": "7444bebf-1ac1-4958-d84a-4dc72cbda668"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers~=4.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (4.46.3)\n",
            "Collecting datasets~=1.5 (from -r requirements.txt (line 2))\n",
            "  Downloading datasets-1.18.4-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting torch_optimizer==0.1.0 (from -r requirements.txt (line 3))\n",
            "  Downloading torch_optimizer-0.1.0-py3-none-any.whl.metadata (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb==0.10.26 (from -r requirements.txt (line 4))\n",
            "  Downloading wandb-0.10.26-py2.py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2.32.3)\n",
            "Collecting nltk==3.6.7 (from -r requirements.txt (line 7))\n",
            "  Downloading nltk-3.6.7-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from torch_optimizer==0.1.0->-r requirements.txt (line 3)) (1.11.0)\n",
            "Collecting pytorch-ranger>=0.1.1 (from torch_optimizer==0.1.0->-r requirements.txt (line 3))\n",
            "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl.metadata (509 bytes)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.10.26->-r requirements.txt (line 4)) (8.1.7)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.10.26->-r requirements.txt (line 4)) (3.1.43)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.10/dist-packages (from wandb==0.10.26->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.10.26->-r requirements.txt (line 4)) (2.3)\n",
            "Collecting shortuuid>=0.5.0 (from wandb==0.10.26->-r requirements.txt (line 4))\n",
            "  Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.10.26->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.10.26->-r requirements.txt (line 4)) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.10.26->-r requirements.txt (line 4)) (2.19.0)\n",
            "Collecting subprocess32>=3.5.3 (from wandb==0.10.26->-r requirements.txt (line 4))\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.4/97.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.10.26->-r requirements.txt (line 4)) (0.4.0)\n",
            "Collecting configparser>=3.8.1 (from wandb==0.10.26->-r requirements.txt (line 4))\n",
            "  Downloading configparser-7.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.10.26->-r requirements.txt (line 4)) (4.25.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb==0.10.26->-r requirements.txt (line 4)) (6.0.2)\n",
            "Collecting pathtools (from wandb==0.10.26->-r requirements.txt (line 4))\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk==3.6.7->-r requirements.txt (line 7)) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk==3.6.7->-r requirements.txt (line 7)) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk==3.6.7->-r requirements.txt (line 7)) (4.66.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers~=4.6->-r requirements.txt (line 1)) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.6->-r requirements.txt (line 1)) (0.26.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.6->-r requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.6->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.6->-r requirements.txt (line 1)) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.6->-r requirements.txt (line 1)) (0.4.5)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets~=1.5->-r requirements.txt (line 2)) (17.0.0)\n",
            "Collecting dill (from datasets~=1.5->-r requirements.txt (line 2))\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets~=1.5->-r requirements.txt (line 2)) (2.2.2)\n",
            "Collecting xxhash (from datasets~=1.5->-r requirements.txt (line 2))\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets~=1.5->-r requirements.txt (line 2))\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->datasets~=1.5->-r requirements.txt (line 2)) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets~=1.5->-r requirements.txt (line 2)) (3.11.9)\n",
            "Collecting responses<0.19 (from datasets~=1.5->-r requirements.txt (line 2))\n",
            "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 6)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 6)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 6)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 6)) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=1.5->-r requirements.txt (line 2)) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=1.5->-r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=1.5->-r requirements.txt (line 2)) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=1.5->-r requirements.txt (line 2)) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=1.5->-r requirements.txt (line 2)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=1.5->-r requirements.txt (line 2)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=1.5->-r requirements.txt (line 2)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=1.5->-r requirements.txt (line 2)) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython>=1.0.0->wandb==0.10.26->-r requirements.txt (line 4)) (4.0.11)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers~=4.6->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets~=1.5->-r requirements.txt (line 2)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets~=1.5->-r requirements.txt (line 2)) (2024.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb==0.10.26->-r requirements.txt (line 4)) (5.0.1)\n",
            "Downloading torch_optimizer-0.1.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wandb-0.10.26-py2.py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nltk-3.6.7-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-1.18.4-py3-none-any.whl (312 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.1/312.1 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading configparser-7.1.0-py3-none-any.whl (17 kB)\n",
            "Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n",
            "Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
            "Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.17-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: subprocess32, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6489 sha256=95b7b60f8e7376fb69eae64596d4c8a988cda0b05dd2b8083e547262931db05e\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/19/61/d440ccd46a2a014bce61fc5c6c8495dedd32ef04cba8b34b28\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8793 sha256=bbe65b93309259428bc927d483d3113f177973155b15f8e7cd9d97452e1d3604\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built subprocess32 pathtools\n",
            "Installing collected packages: pathtools, xxhash, subprocess32, shortuuid, nltk, dill, configparser, responses, pytorch-ranger, multiprocess, wandb, torch_optimizer, datasets\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.9.1\n",
            "    Uninstalling nltk-3.9.1:\n",
            "      Successfully uninstalled nltk-3.9.1\n",
            "  Attempting uninstall: wandb\n",
            "    Found existing installation: wandb 0.18.7\n",
            "    Uninstalling wandb-0.18.7:\n",
            "      Successfully uninstalled wandb-0.18.7\n",
            "Successfully installed configparser-7.1.0 datasets-1.18.4 dill-0.3.9 multiprocess-0.70.17 nltk-3.6.7 pathtools-0.1.2 pytorch-ranger-0.1.1 responses-0.18.0 shortuuid-1.0.13 subprocess32-3.5.4 torch_optimizer-0.1.0 wandb-0.10.26 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "backports"
                ]
              },
              "id": "0f9b23c2bbe34a20b2fbd201c32daf00"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fBRlm39zgeX2"
      },
      "outputs": [],
      "source": [
        "!chmod 755 ./tokenize_wikitext103.py\n",
        "!chmod 755 ./run_training_monitor.py\n",
        "!chmod 755 ./run_trainer.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWBqBRjTljoR",
        "outputId": "93f13ca7-640b-42f8-9bcb-4a7d61e76e6f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (1.18.4)\n",
            "Collecting datasets\n",
            "  Using cached datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.9)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Using cached datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "Installing collected packages: fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.9\n",
            "    Uninstalling dill-0.3.9:\n",
            "      Successfully uninstalled dill-0.3.9\n",
            "  Attempting uninstall: multiprocess\n",
            "    Found existing installation: multiprocess 0.70.17\n",
            "    Uninstalling multiprocess-0.70.17:\n",
            "      Successfully uninstalled multiprocess-0.70.17\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 1.18.4\n",
            "    Uninstalling datasets-1.18.4:\n",
            "      Successfully uninstalled datasets-1.18.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\n",
            "peft 0.13.2 requires torch>=1.13.0, but you have torch 1.11.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./tokenize_wikitext103.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6wUO-h8lDRW",
        "outputId": "e8c84397-6658-4d4c-f1f0-3988f97438a8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "tokenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 171kB/s]\n",
            "spiece.model: 100% 760k/760k [00:00<00:00, 1.48MB/s]\n",
            "tokenizer.json: 100% 1.31M/1.31M [00:00<00:00, 1.88MB/s]\n",
            "config.json: 100% 685/685 [00:00<00:00, 4.49MB/s]\n",
            "README.md: 100% 10.5k/10.5k [00:00<00:00, 42.0MB/s]\n",
            "test-00000-of-00001.parquet: 100% 722k/722k [00:00<00:00, 14.2MB/s]\n",
            "train-00000-of-00002.parquet: 100% 156M/156M [00:00<00:00, 226MB/s]\n",
            "train-00001-of-00002.parquet: 100% 156M/156M [00:00<00:00, 250MB/s]\n",
            "validation-00000-of-00001.parquet: 100% 655k/655k [00:00<00:00, 237MB/s]\n",
            "Generating test split: 100% 4358/4358 [00:00<00:00, 118537.10 examples/s]\n",
            "Generating train split: 100% 1801350/1801350 [00:02<00:00, 898250.39 examples/s]\n",
            "Generating validation split: 100% 3760/3760 [00:00<00:00, 605117.91 examples/s]\n",
            "Map (num_proc=8): 100% 4358/4358 [00:01<00:00, 3525.61 examples/s]\n",
            "Map (num_proc=8):  37% 660000/1801350 [01:52<02:41, 7056.11 examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (701 > 512). Running this sequence through the model will result in indexing errors\n",
            "Map (num_proc=8):  86% 1555000/1801350 [04:23<00:27, 9101.08 examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
            "Map (num_proc=8): 100% 1801350/1801350 [05:06<00:00, 5871.11 examples/s]\n",
            "Map (num_proc=8): 100% 3760/3760 [00:00<00:00, 4155.50 examples/s]\n",
            "Saving the dataset (1/1 shards): 100% 1723/1723 [00:00<00:00, 169217.83 examples/s]\n",
            "Saving the dataset (2/2 shards): 100% 711735/711735 [00:01<00:00, 522057.52 examples/s]\n",
            "Saving the dataset (1/1 shards): 100% 1557/1557 [00:00<00:00, 176945.60 examples/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rdeu1yfaAxxD",
        "outputId": "0472739f-021a-4f60-f9b6-2ac19e6610e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/learning-at-home/hivemind.git\n",
            "  Cloning https://github.com/learning-at-home/hivemind.git to /tmp/pip-req-build-pityyhb1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/learning-at-home/hivemind.git /tmp/pip-req-build-pityyhb1\n",
            "  Resolved https://github.com/learning-at-home/hivemind.git to commit 10f82ee9e080c4fdbc95f2f26971a7afd55f43fa\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting multiaddr@ git+https://github.com/multiformats/py-multiaddr.git@e01dbd38f2c0464c0f78b556691d655265018cce (from hivemind==1.2.0.dev0)\n",
            "  Using cached multiaddr-0.0.9-py2.py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from hivemind==1.2.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.2.0.dev0) (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.2.0.dev0) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.2.0.dev0) (1.13.1)\n",
            "Requirement already satisfied: prefetch_generator>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.2.0.dev0) (1.0.3)\n",
            "Requirement already satisfied: msgpack>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.2.0.dev0) (1.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from hivemind==1.2.0.dev0) (2.4.0)\n",
            "Requirement already satisfied: uvloop>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.2.0.dev0) (0.21.0)\n",
            "Requirement already satisfied: grpcio-tools>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.2.0.dev0) (1.68.1)\n",
            "Requirement already satisfied: protobuf<5.28.0,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.2.0.dev0) (5.27.5)\n",
            "Requirement already satisfied: configargparse>=1.2.3 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.2.0.dev0) (1.7)\n",
            "Requirement already satisfied: py-multihash>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.2.0.dev0) (0.2.3)\n",
            "Requirement already satisfied: cryptography>=3.4.6 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.2.0.dev0) (43.0.3)\n",
            "Collecting pydantic>=2.0.0 (from hivemind==1.2.0.dev0)\n",
            "  Using cached pydantic-2.10.3-py3-none-any.whl.metadata (172 kB)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.2.0.dev0) (24.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.4.6->hivemind==1.2.0.dev0) (1.17.1)\n",
            "Requirement already satisfied: grpcio>=1.68.1 in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.33.2->hivemind==1.2.0.dev0) (1.68.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.33.2->hivemind==1.2.0.dev0) (75.1.0)\n",
            "Requirement already satisfied: base58<2.0,>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from py-multihash>=0.2.3->hivemind==1.2.0.dev0) (1.0.3)\n",
            "Requirement already satisfied: morphys<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from py-multihash>=0.2.3->hivemind==1.2.0.dev0) (1.0)\n",
            "Requirement already satisfied: six<2.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from py-multihash>=0.2.3->hivemind==1.2.0.dev0) (1.16.0)\n",
            "Requirement already satisfied: varint<2.0,>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from py-multihash>=0.2.3->hivemind==1.2.0.dev0) (1.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0.0->hivemind==1.2.0.dev0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0.0->hivemind==1.2.0.dev0) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0.0->hivemind==1.2.0.dev0) (4.12.2)\n",
            "Requirement already satisfied: netaddr in /usr/local/lib/python3.10/dist-packages (from multiaddr@ git+https://github.com/multiformats/py-multiaddr.git@e01dbd38f2c0464c0f78b556691d655265018cce->hivemind==1.2.0.dev0) (1.3.0)\n",
            "Requirement already satisfied: py-cid in /usr/local/lib/python3.10/dist-packages (from multiaddr@ git+https://github.com/multiformats/py-multiaddr.git@e01dbd38f2c0464c0f78b556691d655265018cce->hivemind==1.2.0.dev0) (0.3.0)\n",
            "Requirement already satisfied: py-multicodec>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from multiaddr@ git+https://github.com/multiformats/py-multiaddr.git@e01dbd38f2c0464c0f78b556691d655265018cce->hivemind==1.2.0.dev0) (0.2.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.4.6->hivemind==1.2.0.dev0) (2.22)\n",
            "Requirement already satisfied: py-multibase<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from py-cid->multiaddr@ git+https://github.com/multiformats/py-multiaddr.git@e01dbd38f2c0464c0f78b556691d655265018cce->hivemind==1.2.0.dev0) (1.0.3)\n",
            "Requirement already satisfied: python-baseconv<2.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from py-multibase<2.0.0,>=1.0.0->py-cid->multiaddr@ git+https://github.com/multiformats/py-multiaddr.git@e01dbd38f2c0464c0f78b556691d655265018cce->hivemind==1.2.0.dev0) (1.2.2)\n",
            "Using cached pydantic-2.10.3-py3-none-any.whl (456 kB)\n",
            "Building wheels for collected packages: hivemind\n",
            "  Building wheel for hivemind (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hivemind: filename=hivemind-1.2.0.dev0-py3-none-any.whl size=9494550 sha256=cbf381466a0920a3d8dfa2d4db62787a3cd9d114c5822d436913f65ca722b699\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5quolq0w/wheels/04/2c/90/1f55c41ab69211d1b69c70069d92adfc7f803510012370a83d\n",
            "Successfully built hivemind\n",
            "Installing collected packages: pydantic, hivemind\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.3\n",
            "    Uninstalling pydantic-1.10.3:\n",
            "      Successfully uninstalled pydantic-1.10.3\n",
            "  Attempting uninstall: hivemind\n",
            "    Found existing installation: hivemind 0.9.9.post1\n",
            "    Uninstalling hivemind-0.9.9.post1:\n",
            "      Successfully uninstalled hivemind-0.9.9.post1\n",
            "Successfully installed hivemind-1.2.0.dev0 pydantic-2.10.3\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/learning-at-home/hivemind.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMjVfOuweHmn",
        "outputId": "ab6aba1c-b6ce-41b6-d76b-4808a24a1d56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (5.27.5)\n",
            "Collecting protobuf\n",
            "  Using cached protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.10.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Using cached protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.27.5\n",
            "    Uninstalling protobuf-5.27.5:\n",
            "      Successfully uninstalled protobuf-5.27.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "hivemind 1.2.0.dev0 requires protobuf<5.28.0,>=3.12.2, but you have protobuf 5.29.1 which is incompatible.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.1 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-5.29.1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade wandb protobuf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "fd946c58a40e64fa7ef780fb501955d3d74d9971"
      ],
      "metadata": {
        "id": "YfPfKvveUU0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install hivemind==0.9.9.post1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YajfEUhqM36Q",
        "outputId": "46f2b3f2-6c12-4bac-a35b-656c84baa412"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hivemind==0.9.9.post1 in /usr/local/lib/python3.10/dist-packages (0.9.9.post1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from hivemind==0.9.9.post1) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from hivemind==0.9.9.post1) (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from hivemind==0.9.9.post1) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from hivemind==0.9.9.post1) (1.13.1)\n",
            "Requirement already satisfied: prefetch-generator>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from hivemind==0.9.9.post1) (1.0.3)\n",
            "Requirement already satisfied: msgpack>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from hivemind==0.9.9.post1) (1.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from hivemind==0.9.9.post1) (2.4.0)\n",
            "Requirement already satisfied: uvloop>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from hivemind==0.9.9.post1) (0.21.0)\n",
            "Requirement already satisfied: grpcio>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from hivemind==0.9.9.post1) (1.68.1)\n",
            "Requirement already satisfied: grpcio-tools>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from hivemind==0.9.9.post1) (1.68.1)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from hivemind==0.9.9.post1) (5.27.5)\n",
            "Requirement already satisfied: configargparse>=1.2.3 in /usr/local/lib/python3.10/dist-packages (from hivemind==0.9.9.post1) (1.7)\n",
            "Requirement already satisfied: multiaddr>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from hivemind==0.9.9.post1) (0.0.9)\n",
            "Requirement already satisfied: pymultihash>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from hivemind==0.9.9.post1) (0.8.2)\n",
            "Requirement already satisfied: cryptography>=3.4.6 in /usr/local/lib/python3.10/dist-packages (from hivemind==0.9.9.post1) (43.0.3)\n",
            "Requirement already satisfied: pydantic>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from hivemind==0.9.9.post1) (1.10.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.4.6->hivemind==0.9.9.post1) (1.17.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.33.2->hivemind==0.9.9.post1) (75.1.0)\n",
            "Requirement already satisfied: varint in /usr/local/lib/python3.10/dist-packages (from multiaddr>=0.0.9->hivemind==0.9.9.post1) (1.0.2)\n",
            "Requirement already satisfied: base58 in /usr/local/lib/python3.10/dist-packages (from multiaddr>=0.0.9->hivemind==0.9.9.post1) (1.0.3)\n",
            "Requirement already satisfied: netaddr in /usr/local/lib/python3.10/dist-packages (from multiaddr>=0.0.9->hivemind==0.9.9.post1) (1.3.0)\n",
            "Requirement already satisfied: py-cid in /usr/local/lib/python3.10/dist-packages (from multiaddr>=0.0.9->hivemind==0.9.9.post1) (0.3.0)\n",
            "Requirement already satisfied: py-multicodec>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from multiaddr>=0.0.9->hivemind==0.9.9.post1) (0.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.8.1->hivemind==0.9.9.post1) (4.12.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.4.6->hivemind==0.9.9.post1) (2.22)\n",
            "Requirement already satisfied: morphys<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from py-multicodec>=0.2.0->multiaddr>=0.0.9->hivemind==0.9.9.post1) (1.0)\n",
            "Requirement already satisfied: six<2.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from py-multicodec>=0.2.0->multiaddr>=0.0.9->hivemind==0.9.9.post1) (1.16.0)\n",
            "Requirement already satisfied: py-multibase<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from py-cid->multiaddr>=0.0.9->hivemind==0.9.9.post1) (1.0.3)\n",
            "Requirement already satisfied: py-multihash<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from py-cid->multiaddr>=0.0.9->hivemind==0.9.9.post1) (0.2.3)\n",
            "Requirement already satisfied: python-baseconv<2.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from py-multibase<2.0.0,>=1.0.0->py-cid->multiaddr>=0.0.9->hivemind==0.9.9.post1) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install Pydantic==1.10.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euDwBjdELv2U",
        "outputId": "ced7e646-9b15-43ce-f577-942f9e1bb35f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pydantic==1.10.3 in /usr/local/lib/python3.10/dist-packages (1.10.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from Pydantic==1.10.3) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install sentencepiece\n",
        "# !pip install whatsmyip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv87l-jXLaA_",
        "outputId": "4c14d02f-9ca7-425d-bf81-df936bb69849"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Collecting whatsmyip\n",
            "  Downloading whatsmyip-0.1.4.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dnspython>=1.15.0 (from whatsmyip)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: requests>=2.12.4 in /usr/local/lib/python3.10/dist-packages (from whatsmyip) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from whatsmyip) (2.2.3)\n",
            "Requirement already satisfied: click>=6.7 in /usr/local/lib/python3.10/dist-packages (from whatsmyip) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.12.4->whatsmyip) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.12.4->whatsmyip) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.12.4->whatsmyip) (2024.8.30)\n",
            "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: whatsmyip\n",
            "  Building wheel for whatsmyip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whatsmyip: filename=whatsmyip-0.1.4-py36,py37-none-any.whl size=5370 sha256=5be8b3c869dacc59917e9ea9a25393bdb217063c7b3a25b8be0ccd74bd6bcf66\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/bf/a2/556076a838f657b5cc5d8809c43a32d859b4e6515d30df51c8\n",
            "Successfully built whatsmyip\n",
            "Installing collected packages: dnspython, whatsmyip\n",
            "Successfully installed dnspython-2.7.0 whatsmyip-0.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !chmod 755 ./run_first_peer.py"
      ],
      "metadata": {
        "id": "jPpFqfd9LFkk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !./run_first_peer.py --wandb_project ALBERT_LLM_Internet_Hivemind"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72Pxc4GvK4NA",
        "outputId": "80041fb3-45b5-476f-9cfc-35df0a5022e8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-11 14:53:10.009094: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-11 14:53:10.028996: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-11 14:53:10.035064: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-11 14:53:10.050069: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-11 14:53:11.158132: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/./run_first_peer.py\", line 11, in <module>\n",
            "    import wandb\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/__init__.py\", line 21, in <module>\n",
            "    from wandb import sdk as wandb_sdk\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/__init__.py\", line 28, in <module>\n",
            "    from .wandb_init import _attach, init\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 39, in <module>\n",
            "    from . import wandb_login, wandb_setup\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_login.py\", line 19, in <module>\n",
            "    from .wandb_settings import Settings\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_settings.py\", line 25, in <module>\n",
            "    from pydantic import (\n",
            "ImportError: cannot import name 'computed_field' from 'pydantic' (/usr/local/lib/python3.10/dist-packages/pydantic/__init__.cpython-310-x86_64-linux-gnu.so)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./run_trainer.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-uLWsbdd6Jr",
        "outputId": "dba1f2cb-c62a-484c-e049-eac6f3ec8bb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-11 16:18:16.463476: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-11 16:18:16.482720: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-11 16:18:16.488530: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-11 16:18:16.502389: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-11 16:18:17.545336: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Dec 11 16:18:19.061 [\u001b[1m\u001b[34mINFO\u001b[0m] Found 0 initial peers: []\n",
            "Dec 11 16:18:19.062 [\u001b[1m\u001b[34mINFO\u001b[0m] Training/evaluation parameters:\n",
            "AlbertTrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-06,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "clamp_value=10000.0,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=4,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=2,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=no,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=None,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O2,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=2,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.00176,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=logs,\n",
            "logging_first_step=True,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=100,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=1000000000000000000000000000000,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=outputs,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=4,\n",
            "per_device_train_batch_size=4,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=outputs,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=2,\n",
            "seed=42,\n",
            "seq_length=512,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "total_steps=125000,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=5000,\n",
            "weight_decay=0.01,\n",
            ")\n",
            "Dec 11 16:18:19.288 [\u001b[1m\u001b[34mINFO\u001b[0m] loading configuration file config.json from cache at data/models--albert-large-v2/snapshots/dfed3a5ef4499fb3351c4ebbcf487375d1e942c8/config.json\n",
            "Dec 11 16:18:19.289 [\u001b[1m\u001b[34mINFO\u001b[0m] Model config AlbertConfig {\n",
            "  \"architectures\": [\n",
            "    \"AlbertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0,\n",
            "  \"bos_token_id\": 2,\n",
            "  \"classifier_dropout_prob\": 0.1,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"eos_token_id\": 3,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_dropout_prob\": 0,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"albert\",\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.46.3\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "Dec 11 16:18:19.289 [\u001b[1m\u001b[34mINFO\u001b[0m] loading file spiece.model\n",
            "Dec 11 16:18:19.289 [\u001b[1m\u001b[34mINFO\u001b[0m] loading file tokenizer.json\n",
            "Dec 11 16:18:19.289 [\u001b[1m\u001b[34mINFO\u001b[0m] loading file added_tokens.json\n",
            "Dec 11 16:18:19.289 [\u001b[1m\u001b[34mINFO\u001b[0m] loading file special_tokens_map.json\n",
            "Dec 11 16:18:19.289 [\u001b[1m\u001b[34mINFO\u001b[0m] loading file tokenizer_config.json\n",
            "Dec 11 16:18:19.342 [\u001b[1m\u001b[34mINFO\u001b[0m] Checkpoint dir outputs, contents []\n",
            "Dec 11 16:18:19.342 [\u001b[1m\u001b[34mINFO\u001b[0m] Training from scratch\n",
            "Dec 11 16:18:19.647 [\u001b[1m\u001b[34mINFO\u001b[0m] You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 30000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "Dec 11 16:18:23.958 [\u001b[1m\u001b[34mINFO\u001b[0m] Running a DHT instance. To connect other peers to this one, use \u001b[1m\u001b[34m--initial_peers /ip4/127.0.0.1/tcp/33657/p2p/12D3KooWCkxGoZdmfXaGqhvHKQVCrcBtF6SEjbqDkbgHJHrTwbd2\u001b[0m\n",
            "Dec 11 16:18:23.958 [\u001b[1m\u001b[34mINFO\u001b[0m] Full list of visible multiaddresses: /ip4/127.0.0.1/tcp/33657/p2p/12D3KooWCkxGoZdmfXaGqhvHKQVCrcBtF6SEjbqDkbgHJHrTwbd2 /ip4/172.28.0.12/tcp/33657/p2p/12D3KooWCkxGoZdmfXaGqhvHKQVCrcBtF6SEjbqDkbgHJHrTwbd2\n",
            "[<Multiaddr /ip4/127.0.0.1/tcp/33657/p2p/12D3KooWCkxGoZdmfXaGqhvHKQVCrcBtF6SEjbqDkbgHJHrTwbd2>, <Multiaddr /ip4/172.28.0.12/tcp/33657/p2p/12D3KooWCkxGoZdmfXaGqhvHKQVCrcBtF6SEjbqDkbgHJHrTwbd2>]\n",
            "[33657, 33657]\n",
            "Dec 11 16:18:23.966 [\u001b[1m\u001b[34mINFO\u001b[0m] Opening tunnel named: tcp-33657-de20fc09-bc05-473d-9108-49ad69b3956f\n",
            "Dec 11 16:18:23.988 [\u001b[1m\u001b[34mINFO\u001b[0m] t=2024-12-11T16:18:23+0000 lvl=info msg=\"no configuration paths supplied\"\n",
            "Dec 11 16:18:23.988 [\u001b[1m\u001b[34mINFO\u001b[0m] t=2024-12-11T16:18:23+0000 lvl=info msg=\"using configuration at default config path\" path=/root/.config/ngrok/ngrok.yml\n",
            "Dec 11 16:18:23.988 [\u001b[1m\u001b[34mINFO\u001b[0m] t=2024-12-11T16:18:23+0000 lvl=info msg=\"open config file\" path=/root/.config/ngrok/ngrok.yml err=nil\n",
            "Dec 11 16:18:24.002 [\u001b[1m\u001b[34mINFO\u001b[0m] t=2024-12-11T16:18:24+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040 allow_hosts=[]\n",
            "Dec 11 16:18:24.267 [\u001b[1m\u001b[34mINFO\u001b[0m] t=2024-12-11T16:18:24+0000 lvl=info msg=\"client session established\" obj=tunnels.session\n",
            "Dec 11 16:18:24.267 [\u001b[1m\u001b[34mINFO\u001b[0m] t=2024-12-11T16:18:24+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n",
            "Dec 11 16:18:24.270 [\u001b[1m\u001b[34mINFO\u001b[0m] t=2024-12-11T16:18:24+0000 lvl=info msg=start pg=/api/tunnels id=03a92416ef48050a\n",
            "Dec 11 16:18:24.270 [\u001b[1m\u001b[34mINFO\u001b[0m] t=2024-12-11T16:18:24+0000 lvl=info msg=end pg=/api/tunnels id=03a92416ef48050a status=200 dur=232.047µs\n",
            "Dec 11 16:18:24.271 [\u001b[1m\u001b[34mINFO\u001b[0m] t=2024-12-11T16:18:24+0000 lvl=info msg=start pg=/api/tunnels id=51f471a7d85039d0\n",
            "Dec 11 16:18:24.271 [\u001b[1m\u001b[34mINFO\u001b[0m] t=2024-12-11T16:18:24+0000 lvl=info msg=end pg=/api/tunnels id=51f471a7d85039d0 status=200 dur=82.749µs\n",
            "Dec 11 16:18:24.272 [\u001b[1m\u001b[34mINFO\u001b[0m] t=2024-12-11T16:18:24+0000 lvl=info msg=start pg=/api/tunnels id=ada698953b4c57fb\n",
            "Dec 11 16:18:24.332 [\u001b[1m\u001b[34mINFO\u001b[0m] t=2024-12-11T16:18:24+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=tcp-33657-de20fc09-bc05-473d-9108-49ad69b3956f addr=//localhost:33657 url=tcp://0.tcp.jp.ngrok.io:12810\n",
            "Dec 11 16:18:24.332 [\u001b[1m\u001b[34mINFO\u001b[0m] t=2024-12-11T16:18:24+0000 lvl=info msg=end pg=/api/tunnels id=ada698953b4c57fb status=201 dur=60.017941ms\n",
            "Dec 11 16:18:24.332 [\u001b[1m\u001b[34mINFO\u001b[0m] Ngrok tunnel created: tcp://0.tcp.jp.ngrok.io:12810\n",
            "Dec 11 16:18:24.332 [\u001b[1m\u001b[34mINFO\u001b[0m] DHT is now accessible via: tcp://0.tcp.jp.ngrok.io:12810\n",
            "Dec 11 16:18:24.395 [\u001b[1m\u001b[34mINFO\u001b[0m] Found no active peers: None\n",
            "Dec 11 16:18:24.467 [\u001b[1m\u001b[34mINFO\u001b[0m] Initializing optimizer manually since it has no tensors in state dict. To override this, provide initialize_optimizer=False\n",
            "/content/./run_trainer.py:345: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `TrainerWithIndependentShuffling.__init__`. Use `processing_class` instead.\n",
            "  trainer = TrainerWithIndependentShuffling(\n",
            "Dec 11 16:18:25.844 [\u001b[1m\u001b[38;5;208mWARN\u001b[0m] [\u001b[1mtransformers.trainer.__init__:649\u001b[0m] max_steps is given, it will override any value given in num_train_epochs\n",
            "Dec 11 16:18:25.845 [\u001b[1m\u001b[34mINFO\u001b[0m] Using auto half precision backend\n",
            "training_args.do_train = True\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2066: FutureWarning: `model_path` is deprecated and will be removed in a future version. Use `resume_from_checkpoint` instead.\n",
            "  warnings.warn(\n",
            "Dec 11 16:18:26.141 [\u001b[1m\u001b[34mINFO\u001b[0m] The following columns in the training set don't have a corresponding argument in `AlbertForPreTraining.forward` and have been ignored: special_tokens_mask. If special_tokens_mask are not expected by `AlbertForPreTraining.forward`,  you can safely ignore this message.\n",
            "Dec 11 16:18:26.243 [\u001b[1m\u001b[34mINFO\u001b[0m] ***** Running training *****\n",
            "Dec 11 16:18:26.243 [\u001b[1m\u001b[34mINFO\u001b[0m]   Num examples = 711,735\n",
            "Dec 11 16:18:26.243 [\u001b[1m\u001b[34mINFO\u001b[0m]   Num Epochs = 11,240,122,742,140,344,172,558,365\n",
            "Dec 11 16:18:26.243 [\u001b[1m\u001b[34mINFO\u001b[0m]   Instantaneous batch size per device = 4\n",
            "Dec 11 16:18:26.243 [\u001b[1m\u001b[34mINFO\u001b[0m]   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "Dec 11 16:18:26.243 [\u001b[1m\u001b[34mINFO\u001b[0m]   Gradient Accumulation steps = 2\n",
            "Dec 11 16:18:26.243 [\u001b[1m\u001b[34mINFO\u001b[0m]   Total optimization steps = 1,000,000,000,000,000,000,000,000,000,000\n",
            "Dec 11 16:18:26.243 [\u001b[1m\u001b[34mINFO\u001b[0m]   Number of trainable parameters = 17,847,474\n",
            "Dec 11 16:18:26.248 [\u001b[1m\u001b[34mINFO\u001b[0m] Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmortis\u001b[0m (\u001b[33mmortis-new-york-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20241211_161826-pwm5gcpc\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33moutputs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mortis-new-york-university/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mortis-new-york-university/huggingface/runs/pwm5gcpc\u001b[0m\n",
            "Dec 11 16:18:27.404 [\u001b[1m\u001b[34mINFO\u001b[0m] Found no active peers: None\n",
            "Dec 11 16:18:27.636 [\u001b[1m\u001b[34mINFO\u001b[0m] Loading state from peers\n",
            "Dec 11 16:18:28.942 [\u001b[1m\u001b[34mINFO\u001b[0m] Step #0\n",
            "Dec 11 16:18:28.943 [\u001b[1m\u001b[34mINFO\u001b[0m] Your current contribution: 8 samples\n",
            "Dec 11 16:18:28.943 [\u001b[1m\u001b[34mINFO\u001b[0m] Performance: 12.564 samples/sec\n",
            "Dec 11 16:18:28.943 [\u001b[1m\u001b[34mINFO\u001b[0m] Local loss: 11.00810\n",
            "Dec 11 16:18:30.408 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 24 samples for epoch #0 from 1 peers. ETA 418.63 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:19:00.410 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 352 samples for epoch #0 from 1 peers. ETA 326.19 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:19:30.413 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 704 samples for epoch #0 from 1 peers. ETA 268.89 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:20:00.417 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1032 samples for epoch #0 from 1 peers. ETA 289.89 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:20:30.420 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1376 samples for epoch #0 from 1 peers. ETA 231.21 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:21:00.423 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1728 samples for epoch #0 from 1 peers. ETA 206.19 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:21:30.426 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2072 samples for epoch #0 from 1 peers. ETA 164.69 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:22:00.430 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2400 samples for epoch #0 from 1 peers. ETA 167.04 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:22:30.433 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2704 samples for epoch #0 from 1 peers. ETA 135.09 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:23:00.436 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3016 samples for epoch #0 from 1 peers. ETA 100.90 sec (refresh in 25.22 sec)\n",
            "Dec 11 16:23:25.663 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3288 samples for epoch #0 from 1 peers. ETA 74.10 sec (refresh in 18.52 sec)\n",
            "Dec 11 16:23:44.191 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3480 samples for epoch #0 from 1 peers. ETA 58.63 sec (refresh in 14.66 sec)\n",
            "Dec 11 16:23:58.853 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3640 samples for epoch #0 from 1 peers. ETA 41.18 sec (refresh in 10.30 sec)\n",
            "Dec 11 16:24:09.151 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3744 samples for epoch #0 from 1 peers. ETA 31.25 sec (refresh in 7.81 sec)\n",
            "Dec 11 16:24:16.967 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3832 samples for epoch #0 from 1 peers. ETA 24.71 sec (refresh in 6.18 sec)\n",
            "Dec 11 16:24:23.148 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3896 samples for epoch #0 from 1 peers. ETA 16.04 sec (refresh in 4.01 sec)\n",
            "Dec 11 16:24:27.160 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3944 samples for epoch #0 from 1 peers. ETA 13.99 sec (refresh in 3.50 sec)\n",
            "Dec 11 16:24:30.662 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3976 samples for epoch #0 from 1 peers. ETA 11.14 sec (refresh in 2.79 sec)\n",
            "Dec 11 16:24:32.253 [\u001b[1m\u001b[34mINFO\u001b[0m] Saving model checkpoint to outputs/checkpoint-500\n",
            "Dec 11 16:24:32.255 [\u001b[1m\u001b[34mINFO\u001b[0m] Configuration saved in outputs/checkpoint-500/config.json\n",
            "Dec 11 16:24:32.398 [\u001b[1m\u001b[34mINFO\u001b[0m] Model weights saved in outputs/checkpoint-500/model.safetensors\n",
            "Dec 11 16:24:32.399 [\u001b[1m\u001b[34mINFO\u001b[0m] tokenizer config file saved in outputs/checkpoint-500/tokenizer_config.json\n",
            "Dec 11 16:24:32.400 [\u001b[1m\u001b[34mINFO\u001b[0m] Special tokens file saved in outputs/checkpoint-500/special_tokens_map.json\n",
            "Dec 11 16:24:33.450 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4000 samples for epoch #0 from 1 peers. ETA 9.36 sec (refresh in 2.34 sec)\n",
            "Dec 11 16:24:35.794 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4032 samples for epoch #0 from 1 peers. ETA 5.73 sec (refresh in 1.43 sec)\n",
            "Dec 11 16:24:36.940 [\u001b[1m\u001b[34mINFO\u001b[0m] Pre-scheduling gradient averaging round in 5.00 sec\n",
            "Dec 11 16:24:37.231 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4048 samples for epoch #0 from 1 peers. ETA 4.09 sec (refresh in 1.02 sec)\n",
            "Dec 11 16:24:38.258 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4056 samples for epoch #0 from 1 peers. ETA 3.18 sec (refresh in 0.80 sec)\n",
            "Dec 11 16:24:39.057 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4064 samples for epoch #0 from 1 peers. ETA 2.93 sec (refresh in 0.73 sec)\n",
            "Dec 11 16:24:39.794 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4072 samples for epoch #0 from 1 peers. ETA 2.21 sec (refresh in 0.55 sec)\n",
            "Dec 11 16:24:40.351 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4072 samples for epoch #0 from 1 peers. ETA 1.66 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:24:40.854 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4080 samples for epoch #0 from 1 peers. ETA 1.46 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:24:41.357 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4080 samples for epoch #0 from 1 peers. ETA 0.96 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:24:41.860 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4088 samples for epoch #0 from 1 peers. ETA 0.41 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:24:42.205 [\u001b[1m\u001b[34mINFO\u001b[0m] Beginning optimizer step #0\n",
            "Dec 11 16:24:42.206 [\u001b[1m\u001b[34mINFO\u001b[0m] Skipping pre-scheduled averaging round: there are no other peers\n",
            "Dec 11 16:24:42.207 [\u001b[1m\u001b[34mINFO\u001b[0m] Proceeding with local gradients\n",
            "Dec 11 16:24:42.254 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 1\n",
            "Dec 11 16:24:42.265 [\u001b[1m\u001b[34mINFO\u001b[0m] Step #1\n",
            "Dec 11 16:24:42.265 [\u001b[1m\u001b[34mINFO\u001b[0m] Your current contribution: 4096 samples\n",
            "Dec 11 16:24:42.265 [\u001b[1m\u001b[34mINFO\u001b[0m] Performance: 10.073 samples/sec\n",
            "Dec 11 16:24:42.265 [\u001b[1m\u001b[34mINFO\u001b[0m] Local loss: 11.01225\n",
            "Dec 11 16:24:42.364 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 0 samples for epoch #1 from 1 peers. ETA 406.54 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:25:12.368 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 352 samples for epoch #1 from 1 peers. ETA 331.39 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:25:42.371 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 704 samples for epoch #1 from 1 peers. ETA 294.53 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:26:12.373 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1040 samples for epoch #1 from 1 peers. ETA 258.85 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:26:42.377 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1336 samples for epoch #1 from 1 peers. ETA 287.88 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:27:12.379 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1664 samples for epoch #1 from 1 peers. ETA 225.79 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:27:42.382 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2032 samples for epoch #1 from 1 peers. ETA 172.34 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:28:12.385 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2336 samples for epoch #1 from 1 peers. ETA 172.86 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:28:42.388 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2672 samples for epoch #1 from 1 peers. ETA 121.77 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:29:12.392 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3040 samples for epoch #1 from 1 peers. ETA 82.95 sec (refresh in 20.74 sec)\n",
            "Dec 11 16:29:33.132 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3240 samples for epoch #1 from 1 peers. ETA 78.19 sec (refresh in 19.55 sec)\n",
            "Dec 11 16:29:52.682 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3448 samples for epoch #1 from 1 peers. ETA 66.76 sec (refresh in 16.69 sec)\n",
            "Dec 11 16:30:09.375 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3624 samples for epoch #1 from 1 peers. ETA 41.71 sec (refresh in 10.43 sec)\n",
            "Dec 11 16:30:19.806 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3736 samples for epoch #1 from 1 peers. ETA 32.31 sec (refresh in 8.08 sec)\n",
            "Dec 11 16:30:27.888 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3832 samples for epoch #1 from 1 peers. ETA 21.18 sec (refresh in 5.29 sec)\n",
            "Dec 11 16:30:33.013 [\u001b[1m\u001b[34mINFO\u001b[0m] Saving model checkpoint to outputs/checkpoint-1000\n",
            "Dec 11 16:30:33.015 [\u001b[1m\u001b[34mINFO\u001b[0m] Configuration saved in outputs/checkpoint-1000/config.json\n",
            "Dec 11 16:30:33.154 [\u001b[1m\u001b[34mINFO\u001b[0m] Model weights saved in outputs/checkpoint-1000/model.safetensors\n",
            "Dec 11 16:30:33.155 [\u001b[1m\u001b[34mINFO\u001b[0m] tokenizer config file saved in outputs/checkpoint-1000/tokenizer_config.json\n",
            "Dec 11 16:30:33.155 [\u001b[1m\u001b[34mINFO\u001b[0m] Special tokens file saved in outputs/checkpoint-1000/special_tokens_map.json\n",
            "Dec 11 16:30:33.185 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3896 samples for epoch #1 from 1 peers. ETA 17.32 sec (refresh in 4.33 sec)\n",
            "Dec 11 16:30:37.519 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3920 samples for epoch #1 from 1 peers. ETA 17.48 sec (refresh in 4.37 sec)\n",
            "Dec 11 16:30:41.894 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3968 samples for epoch #1 from 1 peers. ETA 12.79 sec (refresh in 3.20 sec)\n",
            "Dec 11 16:30:45.095 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4000 samples for epoch #1 from 1 peers. ETA 9.68 sec (refresh in 2.42 sec)\n",
            "Dec 11 16:30:47.517 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4032 samples for epoch #1 from 1 peers. ETA 6.03 sec (refresh in 1.51 sec)\n",
            "Dec 11 16:30:49.028 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4040 samples for epoch #1 from 1 peers. ETA 4.36 sec (refresh in 1.09 sec)\n",
            "Dec 11 16:30:49.198 [\u001b[1m\u001b[34mINFO\u001b[0m] Pre-scheduling gradient averaging round in 5.00 sec\n",
            "Dec 11 16:30:50.123 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4056 samples for epoch #1 from 1 peers. ETA 3.50 sec (refresh in 0.88 sec)\n",
            "Dec 11 16:30:51.002 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4064 samples for epoch #1 from 1 peers. ETA 2.64 sec (refresh in 0.66 sec)\n",
            "Dec 11 16:30:51.666 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4072 samples for epoch #1 from 1 peers. ETA 1.65 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:30:52.169 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4080 samples for epoch #1 from 1 peers. ETA 1.01 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:30:52.672 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4088 samples for epoch #1 from 1 peers. ETA 0.30 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:30:52.812 [\u001b[1m\u001b[34mINFO\u001b[0m] Beginning optimizer step #1\n",
            "Dec 11 16:30:52.813 [\u001b[1m\u001b[34mINFO\u001b[0m] Skipping pre-scheduled averaging round: there are no other peers\n",
            "Dec 11 16:30:52.813 [\u001b[1m\u001b[34mINFO\u001b[0m] Proceeding with local gradients\n",
            "Dec 11 16:30:52.859 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 2\n",
            "Dec 11 16:30:52.865 [\u001b[1m\u001b[34mINFO\u001b[0m] Step #2\n",
            "Dec 11 16:30:52.865 [\u001b[1m\u001b[34mINFO\u001b[0m] Your current contribution: 8184 samples\n",
            "Dec 11 16:30:52.865 [\u001b[1m\u001b[34mINFO\u001b[0m] Performance: 11.519 samples/sec\n",
            "Dec 11 16:30:52.866 [\u001b[1m\u001b[34mINFO\u001b[0m] Local loss: 11.00888\n",
            "Dec 11 16:30:53.176 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 0 samples for epoch #2 from 1 peers. ETA 355.27 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:31:23.179 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 328 samples for epoch #2 from 1 peers. ETA 334.73 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:31:53.183 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 648 samples for epoch #2 from 1 peers. ETA 329.05 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:32:06.537 [\u001b[1m\u001b[34mINFO\u001b[0m] t=2024-12-11T16:32:06+0000 lvl=info msg=\"join connections\" obj=join id=b44c3356cec8 l=127.0.0.1:33657 r=34.124.219.181:34021\n",
            "Dec 11 16:32:23.296 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1000 samples for epoch #2 from 1 peers. ETA 275.12 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:32:53.703 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1344 samples for epoch #2 from 1 peers. ETA 252.72 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:33:23.827 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1820 samples for epoch #2 from 2 peers. ETA 98.64 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:33:53.945 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2488 samples for epoch #2 from 2 peers. ETA 72.63 sec (refresh in 29.05 sec)\n",
            "Dec 11 16:34:23.111 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3136 samples for epoch #2 from 2 peers. ETA 43.14 sec (refresh in 17.26 sec)\n",
            "Dec 11 16:34:40.481 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3508 samples for epoch #2 from 2 peers. ETA 27.26 sec (refresh in 10.90 sec)\n",
            "Dec 11 16:34:51.519 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3776 samples for epoch #2 from 2 peers. ETA 13.12 sec (refresh in 5.25 sec)\n",
            "Dec 11 16:34:56.882 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3900 samples for epoch #2 from 2 peers. ETA 8.06 sec (refresh in 3.23 sec)\n",
            "Dec 11 16:35:00.003 [\u001b[1m\u001b[34mINFO\u001b[0m] Pre-scheduling gradient averaging round in 5.00 sec\n",
            "Dec 11 16:35:00.220 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3980 samples for epoch #2 from 2 peers. ETA 4.51 sec (refresh in 1.81 sec)\n",
            "Dec 11 16:35:02.141 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4016 samples for epoch #2 from 2 peers. ETA 2.85 sec (refresh in 1.14 sec)\n",
            "Dec 11 16:35:03.394 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4044 samples for epoch #2 from 2 peers. ETA 1.67 sec (refresh in 0.67 sec)\n",
            "Dec 11 16:35:04.218 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4068 samples for epoch #2 from 2 peers. ETA 0.91 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:35:04.834 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4080 samples for epoch #2 from 2 peers. ETA 0.17 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:35:05.542 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 0 samples for epoch #3 from 2 peers. ETA 178.98 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:35:05.610 [\u001b[1m\u001b[34mINFO\u001b[0m] Beginning optimizer step #2\n",
            "Dec 11 16:35:05.639 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 3\n",
            "Dec 11 16:35:05.645 [\u001b[1m\u001b[34mINFO\u001b[0m] Step #3\n",
            "Dec 11 16:35:05.645 [\u001b[1m\u001b[34mINFO\u001b[0m] Your current contribution: 10976 samples\n",
            "Dec 11 16:35:05.645 [\u001b[1m\u001b[34mINFO\u001b[0m] Performance: 11.365 samples/sec\n",
            "Dec 11 16:35:05.645 [\u001b[1m\u001b[34mINFO\u001b[0m] Local loss: 11.00569\n",
            "Dec 11 16:35:13.635 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged gradients with 2 peers\n",
            "Dec 11 16:35:20.897 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 11 16:35:21.609 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 11 16:35:35.656 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 684 samples for epoch #3 from 2 peers. ETA 147.52 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:36:05.768 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1384 samples for epoch #3 from 2 peers. ETA 110.08 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:36:35.546 [\u001b[1m\u001b[34mINFO\u001b[0m] Saving model checkpoint to outputs/checkpoint-1500\n",
            "Dec 11 16:36:35.547 [\u001b[1m\u001b[34mINFO\u001b[0m] Configuration saved in outputs/checkpoint-1500/config.json\n",
            "Dec 11 16:36:35.687 [\u001b[1m\u001b[34mINFO\u001b[0m] Model weights saved in outputs/checkpoint-1500/model.safetensors\n",
            "Dec 11 16:36:35.688 [\u001b[1m\u001b[34mINFO\u001b[0m] tokenizer config file saved in outputs/checkpoint-1500/tokenizer_config.json\n",
            "Dec 11 16:36:35.688 [\u001b[1m\u001b[34mINFO\u001b[0m] Special tokens file saved in outputs/checkpoint-1500/special_tokens_map.json\n",
            "Dec 11 16:36:35.914 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2044 samples for epoch #3 from 2 peers. ETA 90.13 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:36:35.914 [\u001b[1m\u001b[34mINFO\u001b[0m] Deleting older checkpoint [outputs/checkpoint-500] due to args.save_total_limit\n",
            "Dec 11 16:37:06.028 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2720 samples for epoch #3 from 2 peers. ETA 58.84 sec (refresh in 23.54 sec)\n",
            "Dec 11 16:37:29.677 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3256 samples for epoch #3 from 2 peers. ETA 36.94 sec (refresh in 14.78 sec)\n",
            "Dec 11 16:37:44.566 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3588 samples for epoch #3 from 2 peers. ETA 22.30 sec (refresh in 8.92 sec)\n",
            "Dec 11 16:37:53.598 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3812 samples for epoch #3 from 2 peers. ETA 11.51 sec (refresh in 4.61 sec)\n",
            "Dec 11 16:37:58.318 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3920 samples for epoch #3 from 2 peers. ETA 6.72 sec (refresh in 2.69 sec)\n",
            "Dec 11 16:38:00.614 [\u001b[1m\u001b[34mINFO\u001b[0m] Pre-scheduling gradient averaging round in 5.00 sec\n",
            "Dec 11 16:38:01.119 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3988 samples for epoch #3 from 2 peers. ETA 4.18 sec (refresh in 1.67 sec)\n",
            "Dec 11 16:38:02.904 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4036 samples for epoch #3 from 2 peers. ETA 2.25 sec (refresh in 0.90 sec)\n",
            "Dec 11 16:38:03.918 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4056 samples for epoch #3 from 2 peers. ETA 1.29 sec (refresh in 0.52 sec)\n",
            "Dec 11 16:38:04.634 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4068 samples for epoch #3 from 2 peers. ETA 0.69 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:38:05.254 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4092 samples for epoch #3 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:38:05.553 [\u001b[1m\u001b[34mINFO\u001b[0m] Beginning optimizer step #3\n",
            "Dec 11 16:38:05.579 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 4\n",
            "Dec 11 16:38:05.587 [\u001b[1m\u001b[34mINFO\u001b[0m] Step #4\n",
            "Dec 11 16:38:05.587 [\u001b[1m\u001b[34mINFO\u001b[0m] Your current contribution: 12960 samples\n",
            "Dec 11 16:38:05.587 [\u001b[1m\u001b[34mINFO\u001b[0m] Performance: 12.351 samples/sec\n",
            "Dec 11 16:38:05.587 [\u001b[1m\u001b[34mINFO\u001b[0m] Local loss: 11.00968\n",
            "Dec 11 16:38:05.867 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 0 samples for epoch #4 from 2 peers. ETA 167.41 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:38:11.673 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged gradients with 2 peers\n",
            "Dec 11 16:38:18.447 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 11 16:38:18.813 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 11 16:38:35.981 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 636 samples for epoch #4 from 2 peers. ETA 163.86 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:39:06.095 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1304 samples for epoch #4 from 2 peers. ETA 125.46 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:39:36.234 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2016 samples for epoch #4 from 2 peers. ETA 89.13 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:40:06.354 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2708 samples for epoch #4 from 2 peers. ETA 60.83 sec (refresh in 24.33 sec)\n",
            "Dec 11 16:40:30.800 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3268 samples for epoch #4 from 2 peers. ETA 36.07 sec (refresh in 14.43 sec)\n",
            "Dec 11 16:40:45.351 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3592 samples for epoch #4 from 2 peers. ETA 22.12 sec (refresh in 8.85 sec)\n",
            "Dec 11 16:40:54.312 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3792 samples for epoch #4 from 2 peers. ETA 13.56 sec (refresh in 5.42 sec)\n",
            "Dec 11 16:40:59.851 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3912 samples for epoch #4 from 2 peers. ETA 7.70 sec (refresh in 3.08 sec)\n",
            "Dec 11 16:41:03.055 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3976 samples for epoch #4 from 2 peers. ETA 4.81 sec (refresh in 1.92 sec)\n",
            "Dec 11 16:41:03.066 [\u001b[1m\u001b[34mINFO\u001b[0m] Pre-scheduling gradient averaging round in 5.00 sec\n",
            "Dec 11 16:41:05.095 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4028 samples for epoch #4 from 2 peers. ETA 2.78 sec (refresh in 1.11 sec)\n",
            "Dec 11 16:41:06.322 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4056 samples for epoch #4 from 2 peers. ETA 1.46 sec (refresh in 0.59 sec)\n",
            "Dec 11 16:41:07.024 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4076 samples for epoch #4 from 2 peers. ETA 0.64 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:41:07.640 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4092 samples for epoch #4 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:41:08.389 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 0 samples for epoch #5 from 2 peers. ETA 175.64 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:41:08.390 [\u001b[1m\u001b[34mINFO\u001b[0m] Beginning optimizer step #4\n",
            "Dec 11 16:41:08.417 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 5\n",
            "Dec 11 16:41:08.423 [\u001b[1m\u001b[34mINFO\u001b[0m] Step #5\n",
            "Dec 11 16:41:08.423 [\u001b[1m\u001b[34mINFO\u001b[0m] Your current contribution: 14936 samples\n",
            "Dec 11 16:41:08.423 [\u001b[1m\u001b[34mINFO\u001b[0m] Performance: 10.783 samples/sec\n",
            "Dec 11 16:41:08.423 [\u001b[1m\u001b[34mINFO\u001b[0m] Local loss: 11.00344\n",
            "Dec 11 16:41:16.437 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged gradients with 2 peers\n",
            "Dec 11 16:41:24.927 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 11 16:41:25.195 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 11 16:41:38.506 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 712 samples for epoch #5 from 2 peers. ETA 136.49 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:42:08.622 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1396 samples for epoch #5 from 2 peers. ETA 119.93 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:42:36.717 [\u001b[1m\u001b[34mINFO\u001b[0m] Saving model checkpoint to outputs/checkpoint-2000\n",
            "Dec 11 16:42:36.718 [\u001b[1m\u001b[34mINFO\u001b[0m] Configuration saved in outputs/checkpoint-2000/config.json\n",
            "Dec 11 16:42:36.862 [\u001b[1m\u001b[34mINFO\u001b[0m] Model weights saved in outputs/checkpoint-2000/model.safetensors\n",
            "Dec 11 16:42:36.863 [\u001b[1m\u001b[34mINFO\u001b[0m] tokenizer config file saved in outputs/checkpoint-2000/tokenizer_config.json\n",
            "Dec 11 16:42:36.863 [\u001b[1m\u001b[34mINFO\u001b[0m] Special tokens file saved in outputs/checkpoint-2000/special_tokens_map.json\n",
            "Dec 11 16:42:37.104 [\u001b[1m\u001b[34mINFO\u001b[0m] Deleting older checkpoint [outputs/checkpoint-1000] due to args.save_total_limit\n",
            "Dec 11 16:42:38.740 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2096 samples for epoch #5 from 2 peers. ETA 83.72 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:43:08.857 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2780 samples for epoch #5 from 2 peers. ETA 52.10 sec (refresh in 20.84 sec)\n",
            "Dec 11 16:43:29.812 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3252 samples for epoch #5 from 2 peers. ETA 38.35 sec (refresh in 15.34 sec)\n",
            "Dec 11 16:43:45.267 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3584 samples for epoch #5 from 2 peers. ETA 22.85 sec (refresh in 9.14 sec)\n",
            "Dec 11 16:43:54.541 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3796 samples for epoch #5 from 2 peers. ETA 12.77 sec (refresh in 5.11 sec)\n",
            "Dec 11 16:43:59.764 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3920 samples for epoch #5 from 2 peers. ETA 6.86 sec (refresh in 2.74 sec)\n",
            "Dec 11 16:44:01.919 [\u001b[1m\u001b[34mINFO\u001b[0m] Pre-scheduling gradient averaging round in 5.00 sec\n",
            "Dec 11 16:44:02.631 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3980 samples for epoch #5 from 2 peers. ETA 4.47 sec (refresh in 1.79 sec)\n",
            "Dec 11 16:44:04.535 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4020 samples for epoch #5 from 2 peers. ETA 2.69 sec (refresh in 1.08 sec)\n",
            "Dec 11 16:44:05.728 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4052 samples for epoch #5 from 2 peers. ETA 1.67 sec (refresh in 0.67 sec)\n",
            "Dec 11 16:44:06.513 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4072 samples for epoch #5 from 2 peers. ETA 0.64 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:44:07.128 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4088 samples for epoch #5 from 2 peers. ETA 0.11 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:44:07.590 [\u001b[1m\u001b[34mINFO\u001b[0m] Beginning optimizer step #5\n",
            "Dec 11 16:44:07.617 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 6\n",
            "Dec 11 16:44:07.624 [\u001b[1m\u001b[34mINFO\u001b[0m] Step #6\n",
            "Dec 11 16:44:07.624 [\u001b[1m\u001b[34mINFO\u001b[0m] Your current contribution: 16936 samples\n",
            "Dec 11 16:44:07.624 [\u001b[1m\u001b[34mINFO\u001b[0m] Performance: 10.670 samples/sec\n",
            "Dec 11 16:44:07.624 [\u001b[1m\u001b[34mINFO\u001b[0m] Local loss: 11.00045\n",
            "Dec 11 16:44:07.750 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 0 samples for epoch #6 from 2 peers. ETA 177.62 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:44:16.226 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged gradients with 2 peers\n",
            "Dec 11 16:44:24.522 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 11 16:44:24.883 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 11 16:44:37.866 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 664 samples for epoch #6 from 2 peers. ETA 152.92 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:45:07.982 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1352 samples for epoch #6 from 2 peers. ETA 123.26 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:45:38.099 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2028 samples for epoch #6 from 2 peers. ETA 90.43 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:46:08.214 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2696 samples for epoch #6 from 2 peers. ETA 61.24 sec (refresh in 24.50 sec)\n",
            "Dec 11 16:46:32.828 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3256 samples for epoch #6 from 2 peers. ETA 35.19 sec (refresh in 14.07 sec)\n",
            "Dec 11 16:46:47.017 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3576 samples for epoch #6 from 2 peers. ETA 23.79 sec (refresh in 9.51 sec)\n",
            "Dec 11 16:46:56.648 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3796 samples for epoch #6 from 2 peers. ETA 12.96 sec (refresh in 5.18 sec)\n",
            "Dec 11 16:47:01.947 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3920 samples for epoch #6 from 2 peers. ETA 7.30 sec (refresh in 2.92 sec)\n",
            "Dec 11 16:47:04.806 [\u001b[1m\u001b[34mINFO\u001b[0m] Pre-scheduling gradient averaging round in 5.00 sec\n",
            "Dec 11 16:47:04.985 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3984 samples for epoch #6 from 2 peers. ETA 4.77 sec (refresh in 1.91 sec)\n",
            "Dec 11 16:47:07.034 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4028 samples for epoch #6 from 2 peers. ETA 2.17 sec (refresh in 0.87 sec)\n",
            "Dec 11 16:47:08.016 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4052 samples for epoch #6 from 2 peers. ETA 1.44 sec (refresh in 0.57 sec)\n",
            "Dec 11 16:47:08.708 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4068 samples for epoch #6 from 2 peers. ETA 0.78 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:47:09.323 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4084 samples for epoch #6 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:47:09.940 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4096 samples for epoch #6 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:47:10.438 [\u001b[1m\u001b[34mINFO\u001b[0m] Beginning optimizer step #6\n",
            "Dec 11 16:47:10.465 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 7\n",
            "Dec 11 16:47:10.473 [\u001b[1m\u001b[34mINFO\u001b[0m] Step #7\n",
            "Dec 11 16:47:10.473 [\u001b[1m\u001b[34mINFO\u001b[0m] Your current contribution: 18920 samples\n",
            "Dec 11 16:47:10.473 [\u001b[1m\u001b[34mINFO\u001b[0m] Performance: 10.374 samples/sec\n",
            "Dec 11 16:47:10.473 [\u001b[1m\u001b[34mINFO\u001b[0m] Local loss: 11.01058\n",
            "Dec 11 16:47:10.694 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4 samples for epoch #7 from 2 peers. ETA 184.00 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:47:19.541 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged gradients with 2 peers\n",
            "Dec 11 16:47:27.847 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 11 16:47:28.345 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 11 16:47:40.809 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 652 samples for epoch #7 from 2 peers. ETA 166.09 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:48:10.926 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1356 samples for epoch #7 from 2 peers. ETA 112.42 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:48:41.051 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2032 samples for epoch #7 from 2 peers. ETA 87.67 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:48:42.304 [\u001b[1m\u001b[34mINFO\u001b[0m] Saving model checkpoint to outputs/checkpoint-2500\n",
            "Dec 11 16:48:42.306 [\u001b[1m\u001b[34mINFO\u001b[0m] Configuration saved in outputs/checkpoint-2500/config.json\n",
            "Dec 11 16:48:42.450 [\u001b[1m\u001b[34mINFO\u001b[0m] Model weights saved in outputs/checkpoint-2500/model.safetensors\n",
            "Dec 11 16:48:42.451 [\u001b[1m\u001b[34mINFO\u001b[0m] tokenizer config file saved in outputs/checkpoint-2500/tokenizer_config.json\n",
            "Dec 11 16:48:42.452 [\u001b[1m\u001b[34mINFO\u001b[0m] Special tokens file saved in outputs/checkpoint-2500/special_tokens_map.json\n",
            "Dec 11 16:48:42.705 [\u001b[1m\u001b[34mINFO\u001b[0m] Deleting older checkpoint [outputs/checkpoint-1500] due to args.save_total_limit\n",
            "Dec 11 16:49:11.167 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2720 samples for epoch #7 from 2 peers. ETA 57.81 sec (refresh in 23.12 sec)\n",
            "Dec 11 16:49:34.406 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3288 samples for epoch #7 from 2 peers. ETA 33.45 sec (refresh in 13.38 sec)\n",
            "Dec 11 16:49:47.902 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3596 samples for epoch #7 from 2 peers. ETA 20.16 sec (refresh in 8.06 sec)\n",
            "Dec 11 16:49:56.110 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3796 samples for epoch #7 from 2 peers. ETA 12.47 sec (refresh in 4.99 sec)\n",
            "Dec 11 16:50:01.222 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3904 samples for epoch #7 from 2 peers. ETA 7.65 sec (refresh in 3.06 sec)\n",
            "Dec 11 16:50:03.902 [\u001b[1m\u001b[34mINFO\u001b[0m] Pre-scheduling gradient averaging round in 5.00 sec\n",
            "Dec 11 16:50:04.395 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3984 samples for epoch #7 from 2 peers. ETA 4.40 sec (refresh in 1.76 sec)\n",
            "Dec 11 16:50:06.269 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4020 samples for epoch #7 from 2 peers. ETA 2.96 sec (refresh in 1.18 sec)\n",
            "Dec 11 16:50:07.581 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4060 samples for epoch #7 from 2 peers. ETA 1.36 sec (refresh in 0.55 sec)\n",
            "Dec 11 16:50:08.251 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4076 samples for epoch #7 from 2 peers. ETA 0.64 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:50:08.868 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4088 samples for epoch #7 from 2 peers. ETA 0.02 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:50:09.321 [\u001b[1m\u001b[34mINFO\u001b[0m] Beginning optimizer step #7\n",
            "Dec 11 16:50:09.347 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 8\n",
            "Dec 11 16:50:09.353 [\u001b[1m\u001b[34mINFO\u001b[0m] Step #8\n",
            "Dec 11 16:50:09.353 [\u001b[1m\u001b[34mINFO\u001b[0m] Your current contribution: 20936 samples\n",
            "Dec 11 16:50:09.353 [\u001b[1m\u001b[34mINFO\u001b[0m] Performance: 11.728 samples/sec\n",
            "Dec 11 16:50:09.353 [\u001b[1m\u001b[34mINFO\u001b[0m] Local loss: 11.01803\n",
            "Dec 11 16:50:09.590 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 0 samples for epoch #8 from 2 peers. ETA 176.43 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:50:15.592 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged gradients with 2 peers\n",
            "Dec 11 16:50:23.401 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 11 16:50:23.479 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 11 16:50:39.717 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 720 samples for epoch #8 from 2 peers. ETA 143.93 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:51:09.833 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1372 samples for epoch #8 from 2 peers. ETA 127.22 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:51:39.948 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2092 samples for epoch #8 from 2 peers. ETA 86.35 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:52:10.122 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2776 samples for epoch #8 from 2 peers. ETA 56.34 sec (refresh in 22.54 sec)\n",
            "Dec 11 16:52:32.779 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3296 samples for epoch #8 from 2 peers. ETA 34.20 sec (refresh in 13.68 sec)\n",
            "Dec 11 16:52:46.575 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3604 samples for epoch #8 from 2 peers. ETA 20.41 sec (refresh in 8.16 sec)\n",
            "Dec 11 16:52:54.856 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3796 samples for epoch #8 from 2 peers. ETA 12.31 sec (refresh in 4.92 sec)\n",
            "Dec 11 16:52:59.897 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3904 samples for epoch #8 from 2 peers. ETA 8.14 sec (refresh in 3.26 sec)\n",
            "Dec 11 16:53:03.270 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3988 samples for epoch #8 from 2 peers. ETA 4.46 sec (refresh in 1.79 sec)\n",
            "Dec 11 16:53:03.607 [\u001b[1m\u001b[34mINFO\u001b[0m] Pre-scheduling gradient averaging round in 5.00 sec\n",
            "Dec 11 16:53:05.172 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4032 samples for epoch #8 from 2 peers. ETA 2.50 sec (refresh in 1.00 sec)\n",
            "Dec 11 16:53:06.286 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4052 samples for epoch #8 from 2 peers. ETA 1.38 sec (refresh in 0.55 sec)\n",
            "Dec 11 16:53:06.955 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4068 samples for epoch #8 from 2 peers. ETA 0.83 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:53:07.581 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4076 samples for epoch #8 from 2 peers. ETA 0.16 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:53:08.200 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4088 samples for epoch #8 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:53:08.502 [\u001b[1m\u001b[34mINFO\u001b[0m] Beginning optimizer step #8\n",
            "Dec 11 16:53:08.529 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 9\n",
            "Dec 11 16:53:08.535 [\u001b[1m\u001b[34mINFO\u001b[0m] Step #9\n",
            "Dec 11 16:53:08.535 [\u001b[1m\u001b[34mINFO\u001b[0m] Your current contribution: 22928 samples\n",
            "Dec 11 16:53:08.536 [\u001b[1m\u001b[34mINFO\u001b[0m] Performance: 10.223 samples/sec\n",
            "Dec 11 16:53:08.536 [\u001b[1m\u001b[34mINFO\u001b[0m] Local loss: 11.01690\n",
            "Dec 11 16:53:08.815 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4 samples for epoch #9 from 2 peers. ETA 186.35 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:53:16.845 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged gradients with 2 peers\n",
            "Dec 11 16:53:24.380 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 11 16:53:25.045 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 11 16:53:38.931 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 692 samples for epoch #9 from 2 peers. ETA 153.11 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:54:09.049 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1368 samples for epoch #9 from 2 peers. ETA 125.29 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:54:36.648 [\u001b[1m\u001b[34mINFO\u001b[0m] Saving model checkpoint to outputs/checkpoint-3000\n",
            "Dec 11 16:54:36.650 [\u001b[1m\u001b[34mINFO\u001b[0m] Configuration saved in outputs/checkpoint-3000/config.json\n",
            "Dec 11 16:54:36.800 [\u001b[1m\u001b[34mINFO\u001b[0m] Model weights saved in outputs/checkpoint-3000/model.safetensors\n",
            "Dec 11 16:54:36.801 [\u001b[1m\u001b[34mINFO\u001b[0m] tokenizer config file saved in outputs/checkpoint-3000/tokenizer_config.json\n",
            "Dec 11 16:54:36.802 [\u001b[1m\u001b[34mINFO\u001b[0m] Special tokens file saved in outputs/checkpoint-3000/special_tokens_map.json\n",
            "Dec 11 16:54:37.069 [\u001b[1m\u001b[34mINFO\u001b[0m] Deleting older checkpoint [outputs/checkpoint-2000] due to args.save_total_limit\n",
            "Dec 11 16:54:39.166 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2052 samples for epoch #9 from 2 peers. ETA 86.96 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:55:09.283 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2736 samples for epoch #9 from 2 peers. ETA 60.03 sec (refresh in 24.01 sec)\n",
            "Dec 11 16:55:33.413 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3264 samples for epoch #9 from 2 peers. ETA 37.33 sec (refresh in 14.93 sec)\n",
            "Dec 11 16:55:48.467 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3600 samples for epoch #9 from 2 peers. ETA 21.51 sec (refresh in 8.60 sec)\n",
            "Dec 11 16:55:57.189 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3796 samples for epoch #9 from 2 peers. ETA 13.02 sec (refresh in 5.21 sec)\n",
            "Dec 11 16:56:02.519 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3920 samples for epoch #9 from 2 peers. ETA 7.46 sec (refresh in 2.98 sec)\n",
            "Dec 11 16:56:05.427 [\u001b[1m\u001b[34mINFO\u001b[0m] Pre-scheduling gradient averaging round in 5.00 sec\n",
            "Dec 11 16:56:05.625 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3996 samples for epoch #9 from 2 peers. ETA 4.03 sec (refresh in 1.61 sec)\n",
            "Dec 11 16:56:07.355 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4032 samples for epoch #9 from 2 peers. ETA 2.29 sec (refresh in 0.92 sec)\n",
            "Dec 11 16:56:08.402 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4060 samples for epoch #9 from 2 peers. ETA 1.10 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:56:09.030 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4072 samples for epoch #9 from 2 peers. ETA 0.60 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:56:09.654 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4084 samples for epoch #9 from 2 peers. ETA 0.22 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:56:09.946 [\u001b[1m\u001b[34mINFO\u001b[0m] Beginning optimizer step #9\n",
            "Dec 11 16:56:09.973 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 10\n",
            "Dec 11 16:56:09.979 [\u001b[1m\u001b[34mINFO\u001b[0m] Step #10\n",
            "Dec 11 16:56:09.979 [\u001b[1m\u001b[34mINFO\u001b[0m] Your current contribution: 24944 samples\n",
            "Dec 11 16:56:09.979 [\u001b[1m\u001b[34mINFO\u001b[0m] Performance: 12.125 samples/sec\n",
            "Dec 11 16:56:09.979 [\u001b[1m\u001b[34mINFO\u001b[0m] Local loss: 11.00274\n",
            "Dec 11 16:56:10.602 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 0 samples for epoch #10 from 2 peers. ETA 181.51 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:56:16.359 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged gradients with 2 peers\n",
            "Dec 11 16:56:24.495 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 11 16:56:25.043 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 11 16:56:40.718 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 668 samples for epoch #10 from 2 peers. ETA 148.47 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:57:10.835 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1352 samples for epoch #10 from 2 peers. ETA 116.75 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:57:40.952 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2052 samples for epoch #10 from 2 peers. ETA 90.95 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:58:11.067 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2736 samples for epoch #10 from 2 peers. ETA 56.79 sec (refresh in 22.72 sec)\n",
            "Dec 11 16:58:33.898 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3260 samples for epoch #10 from 2 peers. ETA 33.82 sec (refresh in 13.53 sec)\n",
            "Dec 11 16:58:47.541 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3564 samples for epoch #10 from 2 peers. ETA 25.06 sec (refresh in 10.03 sec)\n",
            "Dec 11 16:58:57.682 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3808 samples for epoch #10 from 2 peers. ETA 11.58 sec (refresh in 4.63 sec)\n",
            "Dec 11 16:59:02.432 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3916 samples for epoch #10 from 2 peers. ETA 6.82 sec (refresh in 2.73 sec)\n",
            "Dec 11 16:59:04.637 [\u001b[1m\u001b[34mINFO\u001b[0m] Pre-scheduling gradient averaging round in 5.00 sec\n",
            "Dec 11 16:59:05.276 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3972 samples for epoch #10 from 2 peers. ETA 5.04 sec (refresh in 2.02 sec)\n",
            "Dec 11 16:59:07.410 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4020 samples for epoch #10 from 2 peers. ETA 3.06 sec (refresh in 1.22 sec)\n",
            "Dec 11 16:59:08.748 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4052 samples for epoch #10 from 2 peers. ETA 1.73 sec (refresh in 0.69 sec)\n",
            "Dec 11 16:59:09.557 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4064 samples for epoch #10 from 2 peers. ETA 0.78 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:59:10.172 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4076 samples for epoch #10 from 2 peers. ETA 0.40 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:59:10.788 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4092 samples for epoch #10 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 11 16:59:11.404 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 0 samples for epoch #11 from 2 peers. ETA 191.59 sec (refresh in 30.00 sec)\n",
            "Dec 11 16:59:11.505 [\u001b[1m\u001b[34mINFO\u001b[0m] Beginning optimizer step #10\n",
            "Dec 11 16:59:11.532 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 11\n",
            "Dec 11 16:59:11.538 [\u001b[1m\u001b[34mINFO\u001b[0m] Step #11\n",
            "Dec 11 16:59:11.538 [\u001b[1m\u001b[34mINFO\u001b[0m] Your current contribution: 26976 samples\n",
            "Dec 11 16:59:11.539 [\u001b[1m\u001b[34mINFO\u001b[0m] Performance: 10.116 samples/sec\n",
            "Dec 11 16:59:11.539 [\u001b[1m\u001b[34mINFO\u001b[0m] Local loss: 11.00504\n",
            "Dec 11 16:59:20.226 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged gradients with 2 peers\n",
            "Dec 11 16:59:28.831 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 11 16:59:28.873 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 11 16:59:41.519 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 676 samples for epoch #11 from 2 peers. ETA 152.93 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:00:11.634 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1344 samples for epoch #11 from 2 peers. ETA 118.50 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:00:33.305 [\u001b[1m\u001b[34mINFO\u001b[0m] Saving model checkpoint to outputs/checkpoint-3500\n",
            "Dec 11 17:00:33.307 [\u001b[1m\u001b[34mINFO\u001b[0m] Configuration saved in outputs/checkpoint-3500/config.json\n",
            "Dec 11 17:00:33.450 [\u001b[1m\u001b[34mINFO\u001b[0m] Model weights saved in outputs/checkpoint-3500/model.safetensors\n",
            "Dec 11 17:00:33.451 [\u001b[1m\u001b[34mINFO\u001b[0m] tokenizer config file saved in outputs/checkpoint-3500/tokenizer_config.json\n",
            "Dec 11 17:00:33.451 [\u001b[1m\u001b[34mINFO\u001b[0m] Special tokens file saved in outputs/checkpoint-3500/special_tokens_map.json\n",
            "Dec 11 17:00:33.722 [\u001b[1m\u001b[34mINFO\u001b[0m] Deleting older checkpoint [outputs/checkpoint-2500] due to args.save_total_limit\n",
            "Dec 11 17:00:41.746 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2048 samples for epoch #11 from 2 peers. ETA 88.33 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:01:11.860 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2744 samples for epoch #11 from 2 peers. ETA 58.63 sec (refresh in 23.45 sec)\n",
            "Dec 11 17:01:35.458 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3260 samples for epoch #11 from 2 peers. ETA 36.51 sec (refresh in 14.61 sec)\n",
            "Dec 11 17:01:50.179 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3604 samples for epoch #11 from 2 peers. ETA 20.31 sec (refresh in 8.12 sec)\n",
            "Dec 11 17:01:58.418 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3788 samples for epoch #11 from 2 peers. ETA 13.32 sec (refresh in 5.33 sec)\n",
            "Dec 11 17:02:03.890 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3908 samples for epoch #11 from 2 peers. ETA 8.28 sec (refresh in 3.31 sec)\n",
            "Dec 11 17:02:07.230 [\u001b[1m\u001b[34mINFO\u001b[0m] Pre-scheduling gradient averaging round in 5.00 sec\n",
            "Dec 11 17:02:07.315 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3984 samples for epoch #11 from 2 peers. ETA 4.14 sec (refresh in 1.65 sec)\n",
            "Dec 11 17:02:09.082 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4024 samples for epoch #11 from 2 peers. ETA 2.90 sec (refresh in 1.16 sec)\n",
            "Dec 11 17:02:10.355 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4048 samples for epoch #11 from 2 peers. ETA 1.57 sec (refresh in 0.63 sec)\n",
            "Dec 11 17:02:11.097 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4076 samples for epoch #11 from 2 peers. ETA 0.52 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:02:11.710 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4092 samples for epoch #11 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:02:12.122 [\u001b[1m\u001b[34mINFO\u001b[0m] Beginning optimizer step #11\n",
            "Dec 11 17:02:12.149 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 12\n",
            "Dec 11 17:02:12.155 [\u001b[1m\u001b[34mINFO\u001b[0m] Step #12\n",
            "Dec 11 17:02:12.155 [\u001b[1m\u001b[34mINFO\u001b[0m] Your current contribution: 29000 samples\n",
            "Dec 11 17:02:12.155 [\u001b[1m\u001b[34mINFO\u001b[0m] Performance: 11.547 samples/sec\n",
            "Dec 11 17:02:12.155 [\u001b[1m\u001b[34mINFO\u001b[0m] Local loss: 11.01232\n",
            "Dec 11 17:02:12.322 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 0 samples for epoch #12 from 2 peers. ETA 175.79 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:02:19.178 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged gradients with 2 peers\n",
            "Dec 11 17:02:26.769 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 11 17:02:27.281 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 11 17:02:42.435 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 680 samples for epoch #12 from 2 peers. ETA 151.79 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:03:12.548 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1364 samples for epoch #12 from 2 peers. ETA 119.45 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:03:42.660 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2084 samples for epoch #12 from 2 peers. ETA 86.63 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:04:12.772 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2792 samples for epoch #12 from 2 peers. ETA 52.61 sec (refresh in 21.04 sec)\n",
            "Dec 11 17:04:33.927 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3268 samples for epoch #12 from 2 peers. ETA 36.15 sec (refresh in 14.46 sec)\n",
            "Dec 11 17:04:48.501 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3604 samples for epoch #12 from 2 peers. ETA 21.62 sec (refresh in 8.65 sec)\n",
            "Dec 11 17:04:57.268 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3792 samples for epoch #12 from 2 peers. ETA 12.76 sec (refresh in 5.10 sec)\n",
            "Dec 11 17:05:02.485 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3916 samples for epoch #12 from 2 peers. ETA 7.66 sec (refresh in 3.06 sec)\n",
            "Dec 11 17:05:05.662 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3988 samples for epoch #12 from 2 peers. ETA 4.13 sec (refresh in 1.65 sec)\n",
            "Dec 11 17:05:05.669 [\u001b[1m\u001b[34mINFO\u001b[0m] Pre-scheduling gradient averaging round in 5.00 sec\n",
            "Dec 11 17:05:07.428 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4028 samples for epoch #12 from 2 peers. ETA 2.73 sec (refresh in 1.09 sec)\n",
            "Dec 11 17:05:08.633 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4048 samples for epoch #12 from 2 peers. ETA 1.61 sec (refresh in 0.64 sec)\n",
            "Dec 11 17:05:09.389 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4064 samples for epoch #12 from 2 peers. ETA 0.93 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:05:10.003 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4080 samples for epoch #12 from 2 peers. ETA 0.13 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:05:10.421 [\u001b[1m\u001b[34mINFO\u001b[0m] Beginning optimizer step #12\n",
            "Dec 11 17:05:10.447 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 13\n",
            "Dec 11 17:05:10.453 [\u001b[1m\u001b[34mINFO\u001b[0m] Step #13\n",
            "Dec 11 17:05:10.453 [\u001b[1m\u001b[34mINFO\u001b[0m] Your current contribution: 31032 samples\n",
            "Dec 11 17:05:10.453 [\u001b[1m\u001b[34mINFO\u001b[0m] Performance: 11.903 samples/sec\n",
            "Dec 11 17:05:10.453 [\u001b[1m\u001b[34mINFO\u001b[0m] Local loss: 11.00344\n",
            "Dec 11 17:05:10.615 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 0 samples for epoch #13 from 2 peers. ETA 180.50 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:05:19.411 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged gradients with 2 peers\n",
            "Dec 11 17:05:27.530 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 11 17:05:27.607 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 11 17:05:40.730 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 652 samples for epoch #13 from 2 peers. ETA 151.28 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:06:10.849 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1332 samples for epoch #13 from 2 peers. ETA 118.85 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:06:27.579 [\u001b[1m\u001b[34mINFO\u001b[0m] Saving model checkpoint to outputs/checkpoint-4000\n",
            "Dec 11 17:06:27.581 [\u001b[1m\u001b[34mINFO\u001b[0m] Configuration saved in outputs/checkpoint-4000/config.json\n",
            "Dec 11 17:06:27.724 [\u001b[1m\u001b[34mINFO\u001b[0m] Model weights saved in outputs/checkpoint-4000/model.safetensors\n",
            "Dec 11 17:06:27.725 [\u001b[1m\u001b[34mINFO\u001b[0m] tokenizer config file saved in outputs/checkpoint-4000/tokenizer_config.json\n",
            "Dec 11 17:06:27.726 [\u001b[1m\u001b[34mINFO\u001b[0m] Special tokens file saved in outputs/checkpoint-4000/special_tokens_map.json\n",
            "Dec 11 17:06:28.014 [\u001b[1m\u001b[34mINFO\u001b[0m] Deleting older checkpoint [outputs/checkpoint-3000] due to args.save_total_limit\n",
            "Dec 11 17:06:40.963 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2020 samples for epoch #13 from 2 peers. ETA 92.26 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:07:11.076 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2720 samples for epoch #13 from 2 peers. ETA 59.03 sec (refresh in 23.61 sec)\n",
            "Dec 11 17:07:34.801 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3252 samples for epoch #13 from 2 peers. ETA 36.59 sec (refresh in 14.64 sec)\n",
            "Dec 11 17:07:49.549 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3600 samples for epoch #13 from 2 peers. ETA 21.06 sec (refresh in 8.42 sec)\n",
            "Dec 11 17:07:58.086 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3776 samples for epoch #13 from 2 peers. ETA 14.34 sec (refresh in 5.74 sec)\n",
            "Dec 11 17:08:03.935 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3888 samples for epoch #13 from 2 peers. ETA 9.72 sec (refresh in 3.89 sec)\n",
            "Dec 11 17:08:07.936 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3968 samples for epoch #13 from 2 peers. ETA 5.83 sec (refresh in 2.33 sec)\n",
            "Dec 11 17:08:08.771 [\u001b[1m\u001b[34mINFO\u001b[0m] Pre-scheduling gradient averaging round in 5.00 sec\n",
            "Dec 11 17:08:10.386 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4036 samples for epoch #13 from 2 peers. ETA 2.49 sec (refresh in 0.99 sec)\n",
            "Dec 11 17:08:11.493 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4052 samples for epoch #13 from 2 peers. ETA 1.63 sec (refresh in 0.65 sec)\n",
            "Dec 11 17:08:12.257 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4080 samples for epoch #13 from 2 peers. ETA 0.44 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:08:12.871 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4088 samples for epoch #13 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:08:12.996 [\u001b[1m\u001b[34mINFO\u001b[0m] Beginning optimizer step #13\n",
            "Dec 11 17:08:13.022 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 14\n",
            "Dec 11 17:08:13.028 [\u001b[1m\u001b[34mINFO\u001b[0m] Step #14\n",
            "Dec 11 17:08:13.028 [\u001b[1m\u001b[34mINFO\u001b[0m] Your current contribution: 33072 samples\n",
            "Dec 11 17:08:13.028 [\u001b[1m\u001b[34mINFO\u001b[0m] Performance: 11.328 samples/sec\n",
            "Dec 11 17:08:13.028 [\u001b[1m\u001b[34mINFO\u001b[0m] Local loss: 11.00105\n",
            "Dec 11 17:08:13.484 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4 samples for epoch #14 from 2 peers. ETA 180.70 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:08:20.718 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged gradients with 2 peers\n",
            "Dec 11 17:08:26.489 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 11 17:08:26.636 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 11 17:08:43.598 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 692 samples for epoch #14 from 2 peers. ETA 145.56 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:09:13.711 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1364 samples for epoch #14 from 2 peers. ETA 121.00 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:09:43.824 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2052 samples for epoch #14 from 2 peers. ETA 90.13 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:10:13.948 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2756 samples for epoch #14 from 2 peers. ETA 56.23 sec (refresh in 22.49 sec)\n",
            "Dec 11 17:10:36.552 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3264 samples for epoch #14 from 2 peers. ETA 36.60 sec (refresh in 14.64 sec)\n",
            "Dec 11 17:10:51.308 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3616 samples for epoch #14 from 2 peers. ETA 19.57 sec (refresh in 7.83 sec)\n",
            "Dec 11 17:10:59.253 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3788 samples for epoch #14 from 2 peers. ETA 13.35 sec (refresh in 5.34 sec)\n",
            "Dec 11 17:11:04.717 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3920 samples for epoch #14 from 2 peers. ETA 6.88 sec (refresh in 2.75 sec)\n",
            "Dec 11 17:11:06.918 [\u001b[1m\u001b[34mINFO\u001b[0m] Pre-scheduling gradient averaging round in 5.00 sec\n",
            "Dec 11 17:11:07.587 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3988 samples for epoch #14 from 2 peers. ETA 4.62 sec (refresh in 1.85 sec)\n",
            "Dec 11 17:11:09.550 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4024 samples for epoch #14 from 2 peers. ETA 2.88 sec (refresh in 1.15 sec)\n",
            "Dec 11 17:11:10.818 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4048 samples for epoch #14 from 2 peers. ETA 1.81 sec (refresh in 0.72 sec)\n",
            "Dec 11 17:11:11.658 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4072 samples for epoch #14 from 2 peers. ETA 0.82 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:11:12.288 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4088 samples for epoch #14 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:11:12.931 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 0 samples for epoch #15 from 2 peers. ETA 179.97 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:11:12.932 [\u001b[1m\u001b[34mINFO\u001b[0m] Beginning optimizer step #14\n",
            "Dec 11 17:11:12.958 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 15\n",
            "Dec 11 17:11:12.965 [\u001b[1m\u001b[34mINFO\u001b[0m] Step #15\n",
            "Dec 11 17:11:12.965 [\u001b[1m\u001b[34mINFO\u001b[0m] Your current contribution: 35080 samples\n",
            "Dec 11 17:11:12.965 [\u001b[1m\u001b[34mINFO\u001b[0m] Performance: 11.389 samples/sec\n",
            "Dec 11 17:11:12.965 [\u001b[1m\u001b[34mINFO\u001b[0m] Local loss: 11.01587\n",
            "Dec 11 17:11:19.921 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged gradients with 2 peers\n",
            "Dec 11 17:11:28.579 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 11 17:11:28.783 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 11 17:11:43.048 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 660 samples for epoch #15 from 2 peers. ETA 160.35 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:12:13.170 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1312 samples for epoch #15 from 2 peers. ETA 123.89 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:12:26.112 [\u001b[1m\u001b[34mINFO\u001b[0m] Saving model checkpoint to outputs/checkpoint-4500\n",
            "Dec 11 17:12:26.113 [\u001b[1m\u001b[34mINFO\u001b[0m] Configuration saved in outputs/checkpoint-4500/config.json\n",
            "Dec 11 17:12:26.258 [\u001b[1m\u001b[34mINFO\u001b[0m] Model weights saved in outputs/checkpoint-4500/model.safetensors\n",
            "Dec 11 17:12:26.259 [\u001b[1m\u001b[34mINFO\u001b[0m] tokenizer config file saved in outputs/checkpoint-4500/tokenizer_config.json\n",
            "Dec 11 17:12:26.260 [\u001b[1m\u001b[34mINFO\u001b[0m] Special tokens file saved in outputs/checkpoint-4500/special_tokens_map.json\n",
            "Dec 11 17:12:26.565 [\u001b[1m\u001b[34mINFO\u001b[0m] Deleting older checkpoint [outputs/checkpoint-3500] due to args.save_total_limit\n",
            "Dec 11 17:12:43.286 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1996 samples for epoch #15 from 2 peers. ETA 88.50 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:13:13.431 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2692 samples for epoch #15 from 2 peers. ETA 60.84 sec (refresh in 24.34 sec)\n",
            "Dec 11 17:13:37.882 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3240 samples for epoch #15 from 2 peers. ETA 40.46 sec (refresh in 16.18 sec)\n",
            "Dec 11 17:13:54.182 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3624 samples for epoch #15 from 2 peers. ETA 19.35 sec (refresh in 7.74 sec)\n",
            "Dec 11 17:14:02.038 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3800 samples for epoch #15 from 2 peers. ETA 11.90 sec (refresh in 4.76 sec)\n",
            "Dec 11 17:14:06.915 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3920 samples for epoch #15 from 2 peers. ETA 7.19 sec (refresh in 2.88 sec)\n",
            "Dec 11 17:14:09.646 [\u001b[1m\u001b[34mINFO\u001b[0m] Pre-scheduling gradient averaging round in 5.00 sec\n",
            "Dec 11 17:14:09.907 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3988 samples for epoch #15 from 2 peers. ETA 4.36 sec (refresh in 1.74 sec)\n",
            "Dec 11 17:14:11.769 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4028 samples for epoch #15 from 2 peers. ETA 2.35 sec (refresh in 0.94 sec)\n",
            "Dec 11 17:14:12.824 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4060 samples for epoch #15 from 2 peers. ETA 1.25 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:14:13.451 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4076 samples for epoch #15 from 2 peers. ETA 0.53 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:14:14.067 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4092 samples for epoch #15 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:14:14.194 [\u001b[1m\u001b[34mINFO\u001b[0m] Beginning optimizer step #15\n",
            "Dec 11 17:14:14.220 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 16\n",
            "Dec 11 17:14:14.225 [\u001b[1m\u001b[34mINFO\u001b[0m] Step #16\n",
            "Dec 11 17:14:14.226 [\u001b[1m\u001b[34mINFO\u001b[0m] Your current contribution: 37088 samples\n",
            "Dec 11 17:14:14.226 [\u001b[1m\u001b[34mINFO\u001b[0m] Performance: 11.919 samples/sec\n",
            "Dec 11 17:14:14.226 [\u001b[1m\u001b[34mINFO\u001b[0m] Local loss: 11.01102\n",
            "Dec 11 17:14:14.683 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4 samples for epoch #16 from 2 peers. ETA 164.98 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:14:20.930 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged gradients with 2 peers\n",
            "Dec 11 17:14:28.259 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 11 17:14:28.754 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 11 17:14:44.799 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 660 samples for epoch #16 from 2 peers. ETA 158.62 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:15:14.914 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1376 samples for epoch #16 from 2 peers. ETA 108.42 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:15:45.041 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2032 samples for epoch #16 from 2 peers. ETA 86.56 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:16:15.158 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2724 samples for epoch #16 from 2 peers. ETA 53.02 sec (refresh in 21.21 sec)\n",
            "Dec 11 17:16:36.483 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3200 samples for epoch #16 from 2 peers. ETA 40.22 sec (refresh in 16.09 sec)\n",
            "Dec 11 17:16:52.688 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3584 samples for epoch #16 from 2 peers. ETA 22.44 sec (refresh in 8.98 sec)\n",
            "Dec 11 17:17:01.832 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3804 samples for epoch #16 from 2 peers. ETA 11.47 sec (refresh in 4.59 sec)\n",
            "Dec 11 17:17:06.536 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3908 samples for epoch #16 from 2 peers. ETA 7.25 sec (refresh in 2.90 sec)\n",
            "Dec 11 17:17:09.292 [\u001b[1m\u001b[34mINFO\u001b[0m] Pre-scheduling gradient averaging round in 5.00 sec\n",
            "Dec 11 17:17:09.552 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3984 samples for epoch #16 from 2 peers. ETA 4.58 sec (refresh in 1.83 sec)\n",
            "Dec 11 17:17:11.500 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4016 samples for epoch #16 from 2 peers. ETA 3.69 sec (refresh in 1.48 sec)\n",
            "Dec 11 17:17:13.096 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4052 samples for epoch #16 from 2 peers. ETA 1.65 sec (refresh in 0.66 sec)\n",
            "Dec 11 17:17:13.884 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4072 samples for epoch #16 from 2 peers. ETA 0.78 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:17:14.505 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4084 samples for epoch #16 from 2 peers. ETA 0.02 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:17:14.739 [\u001b[1m\u001b[34mINFO\u001b[0m] Beginning optimizer step #16\n",
            "Dec 11 17:17:14.766 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 17\n",
            "Dec 11 17:17:14.772 [\u001b[1m\u001b[34mINFO\u001b[0m] Step #17\n",
            "Dec 11 17:17:14.772 [\u001b[1m\u001b[34mINFO\u001b[0m] Your current contribution: 39096 samples\n",
            "Dec 11 17:17:14.772 [\u001b[1m\u001b[34mINFO\u001b[0m] Performance: 10.924 samples/sec\n",
            "Dec 11 17:17:14.772 [\u001b[1m\u001b[34mINFO\u001b[0m] Local loss: 11.00970\n",
            "Dec 11 17:17:15.375 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4 samples for epoch #17 from 2 peers. ETA 188.90 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:17:20.973 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged gradients with 2 peers\n",
            "Dec 11 17:17:28.399 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 11 17:17:29.126 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 11 17:17:45.500 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 684 samples for epoch #17 from 2 peers. ETA 158.88 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:18:15.617 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1376 samples for epoch #17 from 2 peers. ETA 124.89 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:18:19.367 [\u001b[1m\u001b[34mINFO\u001b[0m] Saving model checkpoint to outputs/checkpoint-5000\n",
            "Dec 11 17:18:19.368 [\u001b[1m\u001b[34mINFO\u001b[0m] Configuration saved in outputs/checkpoint-5000/config.json\n",
            "Dec 11 17:18:19.511 [\u001b[1m\u001b[34mINFO\u001b[0m] Model weights saved in outputs/checkpoint-5000/model.safetensors\n",
            "Dec 11 17:18:19.513 [\u001b[1m\u001b[34mINFO\u001b[0m] tokenizer config file saved in outputs/checkpoint-5000/tokenizer_config.json\n",
            "Dec 11 17:18:19.513 [\u001b[1m\u001b[34mINFO\u001b[0m] Special tokens file saved in outputs/checkpoint-5000/special_tokens_map.json\n",
            "Dec 11 17:18:19.825 [\u001b[1m\u001b[34mINFO\u001b[0m] Deleting older checkpoint [outputs/checkpoint-4000] due to args.save_total_limit\n",
            "Dec 11 17:18:45.734 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2064 samples for epoch #17 from 2 peers. ETA 90.35 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:19:15.856 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2728 samples for epoch #17 from 2 peers. ETA 61.06 sec (refresh in 24.42 sec)\n",
            "Dec 11 17:19:40.397 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3288 samples for epoch #17 from 2 peers. ETA 34.21 sec (refresh in 13.68 sec)\n",
            "Dec 11 17:19:54.197 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3592 samples for epoch #17 from 2 peers. ETA 22.94 sec (refresh in 9.18 sec)\n",
            "Dec 11 17:20:03.492 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3800 samples for epoch #17 from 2 peers. ETA 12.22 sec (refresh in 4.89 sec)\n",
            "Dec 11 17:20:08.501 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3908 samples for epoch #17 from 2 peers. ETA 8.03 sec (refresh in 3.21 sec)\n",
            "Dec 11 17:20:11.828 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3976 samples for epoch #17 from 2 peers. ETA 4.91 sec (refresh in 1.96 sec)\n",
            "Dec 11 17:20:11.840 [\u001b[1m\u001b[34mINFO\u001b[0m] Pre-scheduling gradient averaging round in 5.00 sec\n",
            "Dec 11 17:20:13.908 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4024 samples for epoch #17 from 2 peers. ETA 2.82 sec (refresh in 1.13 sec)\n",
            "Dec 11 17:20:15.154 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4048 samples for epoch #17 from 2 peers. ETA 1.51 sec (refresh in 0.60 sec)\n",
            "Dec 11 17:20:15.873 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4072 samples for epoch #17 from 2 peers. ETA 0.82 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:20:16.491 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4084 samples for epoch #17 from 2 peers. ETA 0.09 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:20:16.939 [\u001b[1m\u001b[34mINFO\u001b[0m] Beginning optimizer step #17\n",
            "Dec 11 17:20:16.966 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 18\n",
            "Dec 11 17:20:16.973 [\u001b[1m\u001b[34mINFO\u001b[0m] Step #18\n",
            "Dec 11 17:20:16.973 [\u001b[1m\u001b[34mINFO\u001b[0m] Your current contribution: 41112 samples\n",
            "Dec 11 17:20:16.974 [\u001b[1m\u001b[34mINFO\u001b[0m] Performance: 10.653 samples/sec\n",
            "Dec 11 17:20:16.974 [\u001b[1m\u001b[34mINFO\u001b[0m] Local loss: 10.99615\n",
            "Dec 11 17:20:17.110 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 0 samples for epoch #18 from 2 peers. ETA 175.12 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:20:23.293 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged gradients with 2 peers\n",
            "Dec 11 17:20:31.399 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 11 17:20:32.222 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 11 17:20:47.226 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 636 samples for epoch #18 from 2 peers. ETA 162.22 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:21:17.342 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1348 samples for epoch #18 from 2 peers. ETA 116.70 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:21:47.458 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2028 samples for epoch #18 from 2 peers. ETA 98.62 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:22:17.577 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2712 samples for epoch #18 from 2 peers. ETA 62.62 sec (refresh in 25.05 sec)\n",
            "Dec 11 17:22:42.745 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3256 samples for epoch #18 from 2 peers. ETA 39.13 sec (refresh in 15.65 sec)\n",
            "Dec 11 17:22:58.515 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3632 samples for epoch #18 from 2 peers. ETA 19.32 sec (refresh in 7.73 sec)\n",
            "Dec 11 17:23:06.360 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3820 samples for epoch #18 from 2 peers. ETA 11.30 sec (refresh in 4.52 sec)\n",
            "Dec 11 17:23:11.008 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3928 samples for epoch #18 from 2 peers. ETA 6.49 sec (refresh in 2.60 sec)\n",
            "Dec 11 17:23:12.525 [\u001b[1m\u001b[34mINFO\u001b[0m] Pre-scheduling gradient averaging round in 5.00 sec\n",
            "Dec 11 17:23:13.730 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3992 samples for epoch #18 from 2 peers. ETA 4.25 sec (refresh in 1.70 sec)\n",
            "Dec 11 17:23:15.562 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4028 samples for epoch #18 from 2 peers. ETA 2.41 sec (refresh in 0.96 sec)\n",
            "Dec 11 17:23:16.653 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4056 samples for epoch #18 from 2 peers. ETA 1.40 sec (refresh in 0.56 sec)\n",
            "Dec 11 17:23:17.329 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4072 samples for epoch #18 from 2 peers. ETA 0.87 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:23:17.947 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4084 samples for epoch #18 from 2 peers. ETA 0.13 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:23:18.347 [\u001b[1m\u001b[34mINFO\u001b[0m] Beginning optimizer step #18\n",
            "Dec 11 17:23:18.373 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 19\n",
            "Dec 11 17:23:18.378 [\u001b[1m\u001b[34mINFO\u001b[0m] Step #19\n",
            "Dec 11 17:23:18.378 [\u001b[1m\u001b[34mINFO\u001b[0m] Your current contribution: 43120 samples\n",
            "Dec 11 17:23:18.378 [\u001b[1m\u001b[34mINFO\u001b[0m] Performance: 11.012 samples/sec\n",
            "Dec 11 17:23:18.379 [\u001b[1m\u001b[34mINFO\u001b[0m] Local loss: 11.00493\n",
            "Dec 11 17:23:18.630 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 0 samples for epoch #19 from 2 peers. ETA 186.61 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:23:26.292 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged gradients with 2 peers\n",
            "Dec 11 17:23:34.715 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 11 17:23:35.083 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 11 17:23:48.744 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 688 samples for epoch #19 from 2 peers. ETA 145.78 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:24:18.859 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1368 samples for epoch #19 from 2 peers. ETA 112.35 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:24:20.825 [\u001b[1m\u001b[34mINFO\u001b[0m] Saving model checkpoint to outputs/checkpoint-5500\n",
            "Dec 11 17:24:20.827 [\u001b[1m\u001b[34mINFO\u001b[0m] Configuration saved in outputs/checkpoint-5500/config.json\n",
            "Dec 11 17:24:20.967 [\u001b[1m\u001b[34mINFO\u001b[0m] Model weights saved in outputs/checkpoint-5500/model.safetensors\n",
            "Dec 11 17:24:20.968 [\u001b[1m\u001b[34mINFO\u001b[0m] tokenizer config file saved in outputs/checkpoint-5500/tokenizer_config.json\n",
            "Dec 11 17:24:20.968 [\u001b[1m\u001b[34mINFO\u001b[0m] Special tokens file saved in outputs/checkpoint-5500/special_tokens_map.json\n",
            "Dec 11 17:24:21.283 [\u001b[1m\u001b[34mINFO\u001b[0m] Deleting older checkpoint [outputs/checkpoint-4500] due to args.save_total_limit\n",
            "Dec 11 17:24:48.973 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2064 samples for epoch #19 from 2 peers. ETA 87.60 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:25:19.087 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2740 samples for epoch #19 from 2 peers. ETA 60.68 sec (refresh in 24.27 sec)\n",
            "Dec 11 17:25:43.471 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3284 samples for epoch #19 from 2 peers. ETA 37.65 sec (refresh in 15.06 sec)\n",
            "Dec 11 17:25:58.695 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3616 samples for epoch #19 from 2 peers. ETA 22.97 sec (refresh in 9.19 sec)\n",
            "Dec 11 17:26:07.998 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3836 samples for epoch #19 from 2 peers. ETA 11.04 sec (refresh in 4.42 sec)\n",
            "Dec 11 17:26:12.529 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3944 samples for epoch #19 from 2 peers. ETA 6.11 sec (refresh in 2.45 sec)\n",
            "Dec 11 17:26:14.321 [\u001b[1m\u001b[34mINFO\u001b[0m] Pre-scheduling gradient averaging round in 5.00 sec\n",
            "Dec 11 17:26:15.088 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4004 samples for epoch #19 from 2 peers. ETA 3.89 sec (refresh in 1.56 sec)\n",
            "Dec 11 17:26:16.758 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4040 samples for epoch #19 from 2 peers. ETA 2.13 sec (refresh in 0.85 sec)\n",
            "Dec 11 17:26:17.723 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4064 samples for epoch #19 from 2 peers. ETA 1.16 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:26:18.336 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4080 samples for epoch #19 from 2 peers. ETA 0.37 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:26:18.950 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4096 samples for epoch #19 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:26:19.564 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 0 samples for epoch #20 from 2 peers. ETA 170.52 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:26:19.750 [\u001b[1m\u001b[34mINFO\u001b[0m] Beginning optimizer step #19\n",
            "Dec 11 17:26:19.776 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 20\n",
            "Dec 11 17:26:19.782 [\u001b[1m\u001b[34mINFO\u001b[0m] Step #20\n",
            "Dec 11 17:26:19.782 [\u001b[1m\u001b[34mINFO\u001b[0m] Your current contribution: 45144 samples\n",
            "Dec 11 17:26:19.782 [\u001b[1m\u001b[34mINFO\u001b[0m] Performance: 11.504 samples/sec\n",
            "Dec 11 17:26:19.782 [\u001b[1m\u001b[34mINFO\u001b[0m] Local loss: 11.01117\n",
            "Dec 11 17:26:27.992 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged gradients with 2 peers\n",
            "Dec 11 17:26:36.682 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 11 17:26:36.725 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 11 17:26:49.699 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 672 samples for epoch #20 from 2 peers. ETA 139.06 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:27:19.814 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1352 samples for epoch #20 from 2 peers. ETA 122.71 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:27:49.934 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2032 samples for epoch #20 from 2 peers. ETA 90.64 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:28:20.071 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2708 samples for epoch #20 from 2 peers. ETA 62.89 sec (refresh in 25.16 sec)\n",
            "Dec 11 17:28:45.354 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3292 samples for epoch #20 from 2 peers. ETA 34.60 sec (refresh in 13.84 sec)\n",
            "Dec 11 17:28:59.312 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3592 samples for epoch #20 from 2 peers. ETA 22.38 sec (refresh in 8.95 sec)\n",
            "Dec 11 17:29:08.381 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3808 samples for epoch #20 from 2 peers. ETA 11.39 sec (refresh in 4.56 sec)\n",
            "Dec 11 17:29:13.055 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3908 samples for epoch #20 from 2 peers. ETA 7.76 sec (refresh in 3.10 sec)\n",
            "Dec 11 17:29:16.107 [\u001b[1m\u001b[34mINFO\u001b[0m] Pre-scheduling gradient averaging round in 5.00 sec\n",
            "Dec 11 17:29:16.272 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3984 samples for epoch #20 from 2 peers. ETA 4.68 sec (refresh in 1.87 sec)\n",
            "Dec 11 17:29:18.259 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4024 samples for epoch #20 from 2 peers. ETA 2.47 sec (refresh in 0.99 sec)\n",
            "Dec 11 17:29:19.363 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4052 samples for epoch #20 from 2 peers. ETA 1.54 sec (refresh in 0.62 sec)\n",
            "Dec 11 17:29:20.094 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4068 samples for epoch #20 from 2 peers. ETA 0.85 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:29:20.710 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4084 samples for epoch #20 from 2 peers. ETA 0.16 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:29:20.896 [\u001b[1m\u001b[34mINFO\u001b[0m] Beginning optimizer step #20\n",
            "Dec 11 17:29:20.922 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 21\n",
            "Dec 11 17:29:20.927 [\u001b[1m\u001b[34mINFO\u001b[0m] Step #21\n",
            "Dec 11 17:29:20.928 [\u001b[1m\u001b[34mINFO\u001b[0m] Your current contribution: 47128 samples\n",
            "Dec 11 17:29:20.928 [\u001b[1m\u001b[34mINFO\u001b[0m] Performance: 11.237 samples/sec\n",
            "Dec 11 17:29:20.928 [\u001b[1m\u001b[34mINFO\u001b[0m] Local loss: 11.00803\n",
            "Dec 11 17:29:21.379 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 0 samples for epoch #21 from 2 peers. ETA 177.09 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:29:28.837 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged gradients with 2 peers\n",
            "Dec 11 17:29:37.478 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 11 17:29:37.641 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 11 17:29:51.493 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 676 samples for epoch #21 from 2 peers. ETA 139.46 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:30:21.610 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1356 samples for epoch #21 from 2 peers. ETA 117.95 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:30:24.030 [\u001b[1m\u001b[34mINFO\u001b[0m] Saving model checkpoint to outputs/checkpoint-6000\n",
            "Dec 11 17:30:24.033 [\u001b[1m\u001b[34mINFO\u001b[0m] Configuration saved in outputs/checkpoint-6000/config.json\n",
            "Dec 11 17:30:24.189 [\u001b[1m\u001b[34mINFO\u001b[0m] Model weights saved in outputs/checkpoint-6000/model.safetensors\n",
            "Dec 11 17:30:24.190 [\u001b[1m\u001b[34mINFO\u001b[0m] tokenizer config file saved in outputs/checkpoint-6000/tokenizer_config.json\n",
            "Dec 11 17:30:24.191 [\u001b[1m\u001b[34mINFO\u001b[0m] Special tokens file saved in outputs/checkpoint-6000/special_tokens_map.json\n",
            "Dec 11 17:30:24.537 [\u001b[1m\u001b[34mINFO\u001b[0m] Deleting older checkpoint [outputs/checkpoint-5000] due to args.save_total_limit\n",
            "Dec 11 17:30:51.724 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2040 samples for epoch #21 from 2 peers. ETA 90.40 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:31:21.839 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2704 samples for epoch #21 from 2 peers. ETA 60.86 sec (refresh in 24.34 sec)\n",
            "Dec 11 17:31:46.381 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3272 samples for epoch #21 from 2 peers. ETA 33.65 sec (refresh in 13.46 sec)\n",
            "Dec 11 17:31:59.955 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3588 samples for epoch #21 from 2 peers. ETA 20.11 sec (refresh in 8.04 sec)\n",
            "Dec 11 17:32:08.113 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3772 samples for epoch #21 from 2 peers. ETA 13.17 sec (refresh in 5.27 sec)\n",
            "Dec 11 17:32:13.497 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3896 samples for epoch #21 from 2 peers. ETA 8.17 sec (refresh in 3.27 sec)\n",
            "Dec 11 17:32:16.880 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3980 samples for epoch #21 from 2 peers. ETA 4.57 sec (refresh in 1.83 sec)\n",
            "Dec 11 17:32:17.192 [\u001b[1m\u001b[34mINFO\u001b[0m] Pre-scheduling gradient averaging round in 5.00 sec\n",
            "Dec 11 17:32:18.822 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4024 samples for epoch #21 from 2 peers. ETA 2.83 sec (refresh in 1.13 sec)\n",
            "Dec 11 17:32:20.110 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4064 samples for epoch #21 from 2 peers. ETA 0.98 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:32:20.724 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4080 samples for epoch #21 from 2 peers. ETA 0.37 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:32:21.339 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4088 samples for epoch #21 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:32:21.339 [\u001b[1m\u001b[34mINFO\u001b[0m] Beginning optimizer step #21\n",
            "Dec 11 17:32:21.367 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 22\n",
            "Dec 11 17:32:21.373 [\u001b[1m\u001b[34mINFO\u001b[0m] Step #22\n",
            "Dec 11 17:32:21.373 [\u001b[1m\u001b[34mINFO\u001b[0m] Your current contribution: 49104 samples\n",
            "Dec 11 17:32:21.373 [\u001b[1m\u001b[34mINFO\u001b[0m] Performance: 11.812 samples/sec\n",
            "Dec 11 17:32:21.373 [\u001b[1m\u001b[34mINFO\u001b[0m] Local loss: 10.99463\n",
            "Dec 11 17:32:21.953 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 0 samples for epoch #22 from 2 peers. ETA 176.00 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:32:29.363 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged gradients with 2 peers\n",
            "Dec 11 17:32:38.166 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 11 17:32:38.719 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 11 17:32:52.068 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 700 samples for epoch #22 from 2 peers. ETA 148.78 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:33:22.184 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1376 samples for epoch #22 from 2 peers. ETA 125.65 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:33:52.298 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2072 samples for epoch #22 from 2 peers. ETA 91.51 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:34:22.420 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2760 samples for epoch #22 from 2 peers. ETA 60.72 sec (refresh in 24.29 sec)\n",
            "Dec 11 17:34:46.823 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3300 samples for epoch #22 from 2 peers. ETA 32.89 sec (refresh in 13.16 sec)\n",
            "Dec 11 17:35:00.097 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3600 samples for epoch #22 from 2 peers. ETA 21.40 sec (refresh in 8.56 sec)\n",
            "Dec 11 17:35:08.774 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3792 samples for epoch #22 from 2 peers. ETA 12.80 sec (refresh in 5.12 sec)\n",
            "Dec 11 17:35:14.007 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3912 samples for epoch #22 from 2 peers. ETA 7.94 sec (refresh in 3.18 sec)\n",
            "Dec 11 17:35:17.155 [\u001b[1m\u001b[34mINFO\u001b[0m] Pre-scheduling gradient averaging round in 5.00 sec\n",
            "Dec 11 17:35:17.298 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3992 samples for epoch #22 from 2 peers. ETA 4.11 sec (refresh in 1.64 sec)\n",
            "Dec 11 17:35:19.055 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4028 samples for epoch #22 from 2 peers. ETA 2.80 sec (refresh in 1.12 sec)\n",
            "Dec 11 17:35:20.292 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4052 samples for epoch #22 from 2 peers. ETA 1.41 sec (refresh in 0.57 sec)\n",
            "Dec 11 17:35:20.981 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4068 samples for epoch #22 from 2 peers. ETA 0.73 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:35:21.595 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4084 samples for epoch #22 from 2 peers. ETA 0.06 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:35:21.742 [\u001b[1m\u001b[34mINFO\u001b[0m] Beginning optimizer step #22\n",
            "Dec 11 17:35:21.767 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 23\n",
            "Dec 11 17:35:21.777 [\u001b[1m\u001b[34mINFO\u001b[0m] Step #23\n",
            "Dec 11 17:35:21.777 [\u001b[1m\u001b[34mINFO\u001b[0m] Your current contribution: 51136 samples\n",
            "Dec 11 17:35:21.778 [\u001b[1m\u001b[34mINFO\u001b[0m] Performance: 11.415 samples/sec\n",
            "Dec 11 17:35:21.778 [\u001b[1m\u001b[34mINFO\u001b[0m] Local loss: 10.99566\n",
            "Dec 11 17:35:22.209 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 0 samples for epoch #23 from 2 peers. ETA 172.84 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:35:30.505 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged gradients with 2 peers\n",
            "Dec 11 17:35:38.683 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 11 17:35:39.329 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 11 17:35:52.326 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 696 samples for epoch #23 from 2 peers. ETA 147.62 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:36:22.118 [\u001b[1m\u001b[34mINFO\u001b[0m] Saving model checkpoint to outputs/checkpoint-6500\n",
            "Dec 11 17:36:22.120 [\u001b[1m\u001b[34mINFO\u001b[0m] Configuration saved in outputs/checkpoint-6500/config.json\n",
            "Dec 11 17:36:22.265 [\u001b[1m\u001b[34mINFO\u001b[0m] Model weights saved in outputs/checkpoint-6500/model.safetensors\n",
            "Dec 11 17:36:22.266 [\u001b[1m\u001b[34mINFO\u001b[0m] tokenizer config file saved in outputs/checkpoint-6500/tokenizer_config.json\n",
            "Dec 11 17:36:22.267 [\u001b[1m\u001b[34mINFO\u001b[0m] Special tokens file saved in outputs/checkpoint-6500/special_tokens_map.json\n",
            "Dec 11 17:36:22.439 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1364 samples for epoch #23 from 2 peers. ETA 120.92 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:36:22.621 [\u001b[1m\u001b[34mINFO\u001b[0m] Deleting older checkpoint [outputs/checkpoint-5500] due to args.save_total_limit\n",
            "Dec 11 17:36:52.551 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2048 samples for epoch #23 from 2 peers. ETA 82.31 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:37:22.699 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2704 samples for epoch #23 from 2 peers. ETA 60.85 sec (refresh in 24.34 sec)\n",
            "Dec 11 17:37:47.188 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3268 samples for epoch #23 from 2 peers. ETA 38.00 sec (refresh in 15.20 sec)\n",
            "Dec 11 17:38:02.504 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3628 samples for epoch #23 from 2 peers. ETA 20.22 sec (refresh in 8.09 sec)\n",
            "Dec 11 17:38:10.705 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3816 samples for epoch #23 from 2 peers. ETA 12.02 sec (refresh in 4.81 sec)\n",
            "Dec 11 17:38:15.623 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3932 samples for epoch #23 from 2 peers. ETA 6.65 sec (refresh in 2.66 sec)\n",
            "Dec 11 17:38:17.415 [\u001b[1m\u001b[34mINFO\u001b[0m] Pre-scheduling gradient averaging round in 5.00 sec\n",
            "Dec 11 17:38:18.397 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3996 samples for epoch #23 from 2 peers. ETA 3.80 sec (refresh in 1.52 sec)\n",
            "Dec 11 17:38:20.030 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4032 samples for epoch #23 from 2 peers. ETA 2.50 sec (refresh in 1.00 sec)\n",
            "Dec 11 17:38:21.142 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4052 samples for epoch #23 from 2 peers. ETA 1.37 sec (refresh in 0.55 sec)\n",
            "Dec 11 17:38:21.832 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4064 samples for epoch #23 from 2 peers. ETA 0.92 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:38:22.531 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4076 samples for epoch #23 from 2 peers. ETA 0.45 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:38:23.159 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4100 samples for epoch #23 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:38:23.399 [\u001b[1m\u001b[34mINFO\u001b[0m] Beginning optimizer step #23\n",
            "Dec 11 17:38:23.426 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 24\n",
            "Dec 11 17:38:23.431 [\u001b[1m\u001b[34mINFO\u001b[0m] Step #24\n",
            "Dec 11 17:38:23.431 [\u001b[1m\u001b[34mINFO\u001b[0m] Your current contribution: 53120 samples\n",
            "Dec 11 17:38:23.431 [\u001b[1m\u001b[34mINFO\u001b[0m] Performance: 10.736 samples/sec\n",
            "Dec 11 17:38:23.432 [\u001b[1m\u001b[34mINFO\u001b[0m] Local loss: 10.99890\n",
            "Dec 11 17:38:23.977 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4 samples for epoch #24 from 2 peers. ETA 178.82 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:38:31.571 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged gradients with 2 peers\n",
            "Dec 11 17:38:39.591 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 11 17:38:39.720 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 11 17:38:54.090 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 692 samples for epoch #24 from 2 peers. ETA 152.21 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:39:24.094 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1160 samples for epoch #24 from 2 peers. ETA 118.34 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:39:54.098 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1480 samples for epoch #24 from 2 peers. ETA 95.48 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:40:24.102 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1800 samples for epoch #24 from 2 peers. ETA 64.07 sec (refresh in 25.63 sec)\n",
            "Dec 11 17:40:49.733 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2064 samples for epoch #24 from 2 peers. ETA 36.77 sec (refresh in 14.71 sec)\n",
            "Dec 11 17:41:04.443 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2232 samples for epoch #24 from 2 peers. ETA 21.10 sec (refresh in 8.44 sec)\n",
            "Dec 11 17:41:12.888 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1816 samples for epoch #24 from 1 peers. ETA 228.78 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:41:42.891 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2152 samples for epoch #24 from 1 peers. ETA 174.09 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:42:12.895 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2480 samples for epoch #24 from 1 peers. ETA 143.84 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:42:29.173 [\u001b[1m\u001b[34mINFO\u001b[0m] Saving model checkpoint to outputs/checkpoint-7000\n",
            "Dec 11 17:42:29.175 [\u001b[1m\u001b[34mINFO\u001b[0m] Configuration saved in outputs/checkpoint-7000/config.json\n",
            "Dec 11 17:42:29.321 [\u001b[1m\u001b[34mINFO\u001b[0m] Model weights saved in outputs/checkpoint-7000/model.safetensors\n",
            "Dec 11 17:42:29.322 [\u001b[1m\u001b[34mINFO\u001b[0m] tokenizer config file saved in outputs/checkpoint-7000/tokenizer_config.json\n",
            "Dec 11 17:42:29.322 [\u001b[1m\u001b[34mINFO\u001b[0m] Special tokens file saved in outputs/checkpoint-7000/special_tokens_map.json\n",
            "Dec 11 17:42:29.690 [\u001b[1m\u001b[34mINFO\u001b[0m] Deleting older checkpoint [outputs/checkpoint-6000] due to args.save_total_limit\n",
            "Dec 11 17:42:42.898 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2808 samples for epoch #24 from 1 peers. ETA 120.07 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:43:12.901 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3136 samples for epoch #24 from 1 peers. ETA 86.19 sec (refresh in 21.55 sec)\n",
            "Dec 11 17:43:34.453 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3384 samples for epoch #24 from 1 peers. ETA 60.08 sec (refresh in 15.02 sec)\n",
            "Dec 11 17:43:49.475 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3560 samples for epoch #24 from 1 peers. ETA 46.27 sec (refresh in 11.57 sec)\n",
            "Dec 11 17:44:01.047 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3680 samples for epoch #24 from 1 peers. ETA 40.00 sec (refresh in 10.00 sec)\n",
            "Dec 11 17:44:11.050 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3808 samples for epoch #24 from 1 peers. ETA 23.16 sec (refresh in 5.79 sec)\n",
            "Dec 11 17:44:16.842 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3864 samples for epoch #24 from 1 peers. ETA 21.20 sec (refresh in 5.30 sec)\n",
            "Dec 11 17:44:22.145 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3920 samples for epoch #24 from 1 peers. ETA 16.07 sec (refresh in 4.02 sec)\n",
            "Dec 11 17:44:26.165 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3952 samples for epoch #24 from 1 peers. ETA 12.16 sec (refresh in 3.04 sec)\n",
            "Dec 11 17:44:29.209 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3984 samples for epoch #24 from 1 peers. ETA 10.83 sec (refresh in 2.71 sec)\n",
            "Dec 11 17:44:31.919 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4016 samples for epoch #24 from 1 peers. ETA 7.49 sec (refresh in 1.87 sec)\n",
            "Dec 11 17:44:33.795 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4032 samples for epoch #24 from 1 peers. ETA 5.81 sec (refresh in 1.45 sec)\n",
            "Dec 11 17:44:34.710 [\u001b[1m\u001b[34mINFO\u001b[0m] Pre-scheduling gradient averaging round in 5.00 sec\n",
            "Dec 11 17:44:35.250 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4048 samples for epoch #24 from 1 peers. ETA 4.12 sec (refresh in 1.03 sec)\n",
            "Dec 11 17:44:36.283 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4056 samples for epoch #24 from 1 peers. ETA 3.22 sec (refresh in 0.81 sec)\n",
            "Dec 11 17:44:37.092 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4064 samples for epoch #24 from 1 peers. ETA 2.39 sec (refresh in 0.60 sec)\n",
            "Dec 11 17:44:37.692 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4080 samples for epoch #24 from 1 peers. ETA 1.46 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:44:38.195 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4088 samples for epoch #24 from 1 peers. ETA 0.64 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:44:38.699 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4088 samples for epoch #24 from 1 peers. ETA 0.14 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:44:38.818 [\u001b[1m\u001b[34mINFO\u001b[0m] Beginning optimizer step #24\n",
            "Dec 11 17:44:38.820 [\u001b[1m\u001b[34mINFO\u001b[0m] Skipping pre-scheduled averaging round: there are no other peers\n",
            "Dec 11 17:44:38.820 [\u001b[1m\u001b[34mINFO\u001b[0m] Proceeding with local gradients\n",
            "Dec 11 17:44:38.868 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 25\n",
            "Dec 11 17:44:38.874 [\u001b[1m\u001b[34mINFO\u001b[0m] Step #25\n",
            "Dec 11 17:44:38.875 [\u001b[1m\u001b[34mINFO\u001b[0m] Your current contribution: 57208 samples\n",
            "Dec 11 17:44:38.875 [\u001b[1m\u001b[34mINFO\u001b[0m] Performance: 11.020 samples/sec\n",
            "Dec 11 17:44:38.875 [\u001b[1m\u001b[34mINFO\u001b[0m] Local loss: 10.99458\n",
            "Dec 11 17:44:39.202 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 0 samples for epoch #25 from 1 peers. ETA 371.34 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:45:09.205 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 328 samples for epoch #25 from 1 peers. ETA 367.58 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:45:39.209 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 640 samples for epoch #25 from 1 peers. ETA 332.96 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:46:09.212 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 952 samples for epoch #25 from 1 peers. ETA 309.64 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:46:39.215 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1304 samples for epoch #25 from 1 peers. ETA 225.81 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:47:09.219 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1624 samples for epoch #25 from 1 peers. ETA 243.61 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:47:39.222 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1960 samples for epoch #25 from 1 peers. ETA 197.15 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:48:09.225 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2304 samples for epoch #25 from 1 peers. ETA 143.46 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:48:32.870 [\u001b[1m\u001b[34mINFO\u001b[0m] Saving model checkpoint to outputs/checkpoint-7500\n",
            "Dec 11 17:48:32.872 [\u001b[1m\u001b[34mINFO\u001b[0m] Configuration saved in outputs/checkpoint-7500/config.json\n",
            "Dec 11 17:48:33.031 [\u001b[1m\u001b[34mINFO\u001b[0m] Model weights saved in outputs/checkpoint-7500/model.safetensors\n",
            "Dec 11 17:48:33.032 [\u001b[1m\u001b[34mINFO\u001b[0m] tokenizer config file saved in outputs/checkpoint-7500/tokenizer_config.json\n",
            "Dec 11 17:48:33.032 [\u001b[1m\u001b[34mINFO\u001b[0m] Special tokens file saved in outputs/checkpoint-7500/special_tokens_map.json\n",
            "Dec 11 17:48:33.454 [\u001b[1m\u001b[34mINFO\u001b[0m] Deleting older checkpoint [outputs/checkpoint-6500] due to args.save_total_limit\n",
            "Dec 11 17:48:39.228 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2632 samples for epoch #25 from 1 peers. ETA 133.94 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:49:09.231 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2984 samples for epoch #25 from 1 peers. ETA 105.37 sec (refresh in 26.34 sec)\n",
            "Dec 11 17:49:35.578 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3296 samples for epoch #25 from 1 peers. ETA 69.73 sec (refresh in 17.43 sec)\n",
            "Dec 11 17:49:53.014 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3464 samples for epoch #25 from 1 peers. ETA 60.05 sec (refresh in 15.01 sec)\n",
            "Dec 11 17:50:08.029 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3632 samples for epoch #25 from 1 peers. ETA 41.90 sec (refresh in 10.48 sec)\n",
            "Dec 11 17:50:18.507 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3752 samples for epoch #25 from 1 peers. ETA 30.95 sec (refresh in 7.74 sec)\n",
            "Dec 11 17:50:26.247 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3848 samples for epoch #25 from 1 peers. ETA 20.23 sec (refresh in 5.06 sec)\n",
            "Dec 11 17:50:31.308 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3904 samples for epoch #25 from 1 peers. ETA 14.16 sec (refresh in 3.54 sec)\n",
            "Dec 11 17:50:34.851 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3928 samples for epoch #25 from 1 peers. ETA 15.98 sec (refresh in 4.00 sec)\n",
            "Dec 11 17:50:38.850 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 3976 samples for epoch #25 from 1 peers. ETA 10.70 sec (refresh in 2.67 sec)\n",
            "Dec 11 17:50:41.527 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4008 samples for epoch #25 from 1 peers. ETA 7.77 sec (refresh in 1.94 sec)\n",
            "Dec 11 17:50:43.474 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4024 samples for epoch #25 from 1 peers. ETA 6.26 sec (refresh in 1.56 sec)\n",
            "Dec 11 17:50:45.041 [\u001b[1m\u001b[34mINFO\u001b[0m] Pre-scheduling gradient averaging round in 5.00 sec\n",
            "Dec 11 17:50:45.044 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4040 samples for epoch #25 from 1 peers. ETA 4.45 sec (refresh in 1.11 sec)\n",
            "Dec 11 17:50:46.160 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4056 samples for epoch #25 from 1 peers. ETA 3.47 sec (refresh in 0.87 sec)\n",
            "Dec 11 17:50:47.031 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4064 samples for epoch #25 from 1 peers. ETA 3.02 sec (refresh in 0.75 sec)\n",
            "Dec 11 17:50:47.789 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4064 samples for epoch #25 from 1 peers. ETA 2.26 sec (refresh in 0.57 sec)\n",
            "Dec 11 17:50:48.357 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4072 samples for epoch #25 from 1 peers. ETA 1.84 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:50:48.860 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4080 samples for epoch #25 from 1 peers. ETA 1.50 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:50:49.364 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4080 samples for epoch #25 from 1 peers. ETA 1.00 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:50:49.868 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4088 samples for epoch #25 from 1 peers. ETA 0.52 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:50:50.371 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 4088 samples for epoch #25 from 1 peers. ETA 0.02 sec (refresh in 0.50 sec)\n",
            "Dec 11 17:50:50.481 [\u001b[1m\u001b[34mINFO\u001b[0m] Beginning optimizer step #25\n",
            "Dec 11 17:50:50.482 [\u001b[1m\u001b[34mINFO\u001b[0m] Skipping pre-scheduled averaging round: there are no other peers\n",
            "Dec 11 17:50:50.482 [\u001b[1m\u001b[34mINFO\u001b[0m] Proceeding with local gradients\n",
            "Dec 11 17:50:50.528 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 26\n",
            "Dec 11 17:50:50.533 [\u001b[1m\u001b[34mINFO\u001b[0m] Step #26\n",
            "Dec 11 17:50:50.534 [\u001b[1m\u001b[34mINFO\u001b[0m] Your current contribution: 61296 samples\n",
            "Dec 11 17:50:50.534 [\u001b[1m\u001b[34mINFO\u001b[0m] Performance: 9.800 samples/sec\n",
            "Dec 11 17:50:50.534 [\u001b[1m\u001b[34mINFO\u001b[0m] Local loss: 11.00212\n",
            "Dec 11 17:50:50.874 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 0 samples for epoch #26 from 1 peers. ETA 417.60 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:51:20.878 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 336 samples for epoch #26 from 1 peers. ETA 320.30 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:51:50.882 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 672 samples for epoch #26 from 1 peers. ETA 308.79 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:52:20.885 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 992 samples for epoch #26 from 1 peers. ETA 312.11 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:52:50.888 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1336 samples for epoch #26 from 1 peers. ETA 235.59 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:53:20.891 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1664 samples for epoch #26 from 1 peers. ETA 229.45 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:53:50.895 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 1976 samples for epoch #26 from 1 peers. ETA 197.45 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:54:20.899 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2304 samples for epoch #26 from 1 peers. ETA 150.31 sec (refresh in 30.00 sec)\n",
            "Dec 11 17:54:36.150 [\u001b[1m\u001b[34mINFO\u001b[0m] Saving model checkpoint to outputs/checkpoint-8000\n",
            "Dec 11 17:54:36.152 [\u001b[1m\u001b[34mINFO\u001b[0m] Configuration saved in outputs/checkpoint-8000/config.json\n",
            "Dec 11 17:54:36.293 [\u001b[1m\u001b[34mINFO\u001b[0m] Model weights saved in outputs/checkpoint-8000/model.safetensors\n",
            "Dec 11 17:54:36.294 [\u001b[1m\u001b[34mINFO\u001b[0m] tokenizer config file saved in outputs/checkpoint-8000/tokenizer_config.json\n",
            "Dec 11 17:54:36.295 [\u001b[1m\u001b[34mINFO\u001b[0m] Special tokens file saved in outputs/checkpoint-8000/special_tokens_map.json\n",
            "Dec 11 17:54:36.668 [\u001b[1m\u001b[34mINFO\u001b[0m] Deleting older checkpoint [outputs/checkpoint-7000] due to args.save_total_limit\n",
            "Dec 11 17:54:50.902 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2640 samples for epoch #26 from 1 peers. ETA 119.67 sec (refresh in 29.92 sec)\n",
            "Dec 11 17:55:20.821 [\u001b[1m\u001b[34mINFO\u001b[0m] albert accumulated 2960 samples for epoch #26 from 1 peers. ETA 102.33 sec (refresh in 25.58 sec)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVnieeBOgfjI",
        "outputId": "85e9ab6c-07bf-4418-a7f9-8da42ab03e97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-11 16:12:02.980614: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-11 16:12:03.000222: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-11 16:12:03.006091: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-11 16:12:03.020334: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-11 16:12:04.153101: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "monitor_args=TrainingMonitorArguments(run_id='albert', initial_peers=[], use_ipfs=False, host_maddrs=['/ip4/0.0.0.0/tcp/0'], announce_maddrs=[], identity_path=None, use_google_dns=False, refresh_period=30, wandb_project='ALBERT_LLM_Internet_Hivemind', store_checkpoints=True, save_checkpoint_step_interval=5, model_config_path='albert-large-v2', repo_path=None, repo_url=None, upload_interval=None)\n",
            "Dec 11 16:12:05.761 [\u001b[1m\u001b[34mINFO\u001b[0m] Received public IP address of this machine: 35.229.129.0\n",
            "Received public IP address of this machine: 35.229.129.0\n",
            "version = ip_address(address).version = /ip4/35.229.129.0/tcp/43339\n",
            "monitor_args.run_id=albert\n",
            "Before: ['/ip4/35.229.129.0/tcp/43339']\n",
            "[<Multiaddr /ip4/35.229.129.0/tcp/43339/p2p/12D3KooWR2BRFFT3ChyR19NnEGjT45LMHEzy6ksL6rmhB9tsqrU1>]\n",
            "[43339]\n",
            "Dec 11 16:12:06.297 [\u001b[1m\u001b[34mINFO\u001b[0m] Opening tunnel named: tcp-43339-0be62d21-3abb-4e2d-96f7-bbb22b3c31c4\n",
            "Dec 11 16:12:06.321 [\u001b[1m\u001b[34mINFO\u001b[0m] t=2024-12-11T16:12:06+0000 lvl=info msg=\"no configuration paths supplied\"\n",
            "Dec 11 16:12:06.322 [\u001b[1m\u001b[34mINFO\u001b[0m] t=2024-12-11T16:12:06+0000 lvl=info msg=\"using configuration at default config path\" path=/root/.config/ngrok/ngrok.yml\n",
            "Dec 11 16:12:06.322 [\u001b[1m\u001b[34mINFO\u001b[0m] t=2024-12-11T16:12:06+0000 lvl=info msg=\"open config file\" path=/root/.config/ngrok/ngrok.yml err=nil\n",
            "Dec 11 16:12:06.338 [\u001b[1m\u001b[34mINFO\u001b[0m] t=2024-12-11T16:12:06+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040 allow_hosts=[]\n",
            "Dec 11 16:12:06.662 [\u001b[1m\u001b[34mINFO\u001b[0m] t=2024-12-11T16:12:06+0000 lvl=info msg=\"client session established\" obj=tunnels.session\n",
            "Dec 11 16:12:06.663 [\u001b[1m\u001b[34mINFO\u001b[0m] t=2024-12-11T16:12:06+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n",
            "Dec 11 16:12:06.666 [\u001b[1m\u001b[34mINFO\u001b[0m] t=2024-12-11T16:12:06+0000 lvl=info msg=start pg=/api/tunnels id=f9f9e87767c133ca\n",
            "Dec 11 16:12:06.666 [\u001b[1m\u001b[34mINFO\u001b[0m] t=2024-12-11T16:12:06+0000 lvl=info msg=end pg=/api/tunnels id=f9f9e87767c133ca status=200 dur=355.561µs\n",
            "Dec 11 16:12:06.667 [\u001b[1m\u001b[34mINFO\u001b[0m] t=2024-12-11T16:12:06+0000 lvl=info msg=start pg=/api/tunnels id=ce02ed1d1bcbd7c1\n",
            "Dec 11 16:12:06.667 [\u001b[1m\u001b[34mINFO\u001b[0m] t=2024-12-11T16:12:06+0000 lvl=info msg=end pg=/api/tunnels id=ce02ed1d1bcbd7c1 status=200 dur=87.014µs\n",
            "Dec 11 16:12:06.668 [\u001b[1m\u001b[34mINFO\u001b[0m] t=2024-12-11T16:12:06+0000 lvl=info msg=start pg=/api/tunnels id=37515a086c1b50e9\n",
            "Dec 11 16:12:06.718 [\u001b[1m\u001b[34mINFO\u001b[0m] t=2024-12-11T16:12:06+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=tcp-43339-0be62d21-3abb-4e2d-96f7-bbb22b3c31c4 addr=//localhost:43339 url=tcp://0.tcp.jp.ngrok.io:16957\n",
            "Dec 11 16:12:06.718 [\u001b[1m\u001b[34mINFO\u001b[0m] t=2024-12-11T16:12:06+0000 lvl=info msg=end pg=/api/tunnels id=37515a086c1b50e9 status=201 dur=49.450941ms\n",
            "Dec 11 16:12:06.718 [\u001b[1m\u001b[34mINFO\u001b[0m] Ngrok tunnel created: tcp://0.tcp.jp.ngrok.io:16957\n",
            "After: ['/ip4/0.0.0.0/tcp/43339']\n",
            "Dec 11 16:12:06.721 [\u001b[1m\u001b[34mINFO\u001b[0m] Running a DHT instance. To connect other peers to this one, use \u001b[1m\u001b[34m--initial_peers /ip4/35.229.129.0/tcp/43339/p2p/12D3KooWR2BRFFT3ChyR19NnEGjT45LMHEzy6ksL6rmhB9tsqrU1\u001b[0m\n",
            "Dec 11 16:12:06.721 [\u001b[1m\u001b[34mINFO\u001b[0m] Full list of visible multiaddresses: /ip4/35.229.129.0/tcp/43339/p2p/12D3KooWR2BRFFT3ChyR19NnEGjT45LMHEzy6ksL6rmhB9tsqrU1\n",
            "Dec 11 16:12:06.721 [\u001b[1m\u001b[34mINFO\u001b[0m] DHT is now accessible via: tcp://0.tcp.jp.ngrok.io:16957\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmortis\u001b[0m (\u001b[33mmortis-new-york-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20241211_161207-mownfci4\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrobust-silence-22\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mortis-new-york-university/ALBERT_LLM_Internet_Hivemind\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mortis-new-york-university/ALBERT_LLM_Internet_Hivemind/runs/mownfci4\u001b[0m\n",
            "While True:0\n",
            "metrics_dict = None\n",
            "While True:1\n",
            "metrics_dict = None\n",
            "While True:2\n",
            "metrics_dict = None\n",
            "While True:3\n",
            "metrics_dict = None\n",
            "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mrobust-silence-22\u001b[0m at: \u001b[34mhttps://wandb.ai/mortis-new-york-university/ALBERT_LLM_Internet_Hivemind/runs/mownfci4\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241211_161207-mownfci4/logs\u001b[0m\n",
            "Dec 11 16:14:10.712 [\u001b[1m\u001b[34mINFO\u001b[0m] t=2024-12-11T16:14:10+0000 lvl=info msg=\"received stop request\" obj=app stopReq=\"{err:<nil> restart:false}\"\n"
          ]
        }
      ],
      "source": [
        "!./run_training_monitor.py --wandb_project ALBERT_LLM_Internet_Hivemind"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./run_trainer.py  --initial_peers /dns4/4.tcp.ngrok.io/tcp/10981/p2p/12D3KooWH1kSLua9snDWY5FrSa6yMBPE2aDJQUKENUWkfBEN3bD4 --per_device_train_batch_size 4"
      ],
      "metadata": {
        "id": "PGPfvSyY8pJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnMcP-3USHCz"
      },
      "outputs": [],
      "source": [
        "import hivemind\n",
        "dht = hivemind.DHT(\n",
        "    host_maddrs=[\"/ip4/0.0.0.0/tcp/0\", \"/ip4/0.0.0.0/udp/0/quic\"],\n",
        "    start=True)\n",
        "\n",
        "print('\\n'.join(str(addr) for addr in dht.get_visible_maddrs()))\n",
        "print(\"Global IP:\", hivemind.utils.networking.choose_ip_address(dht.get_visible_maddrs()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfHvpBTqAuLB"
      },
      "outputs": [],
      "source": [
        "print('\\n'.join(str(addr) for addr in dht.get_visible_maddrs()))\n",
        "print(\"Global IP:\", hivemind.utils.networking.choose_ip_address(dht.get_visible_maddrs()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKQlGfBbOk3o"
      },
      "outputs": [],
      "source": [
        "# 暴露端口 33637（假设该端口用于通信）\n",
        "!nohup ./ngrok tcp 36249 > ngrok.log 2>&1 &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xBNXyGVzyMM",
        "outputId": "3aadd906-b7d2-4564-e847-935e272e6323"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tcp://0.tcp.jp.ngrok.io:15048\n"
          ]
        }
      ],
      "source": [
        "!curl -s http://127.0.0.1:4040/api/tunnels | grep -Eo '\"public_url\":\"tcp://[^\"]+\"' | cut -d':' -f2- | tr -d '\"'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rspjs0HL4Hop",
        "outputId": "8fb7e937-e811-4f83-beb2-30ad72e21945"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IP Address of 0.tcp.jp.ngrok.io: 35.76.159.227\n"
          ]
        }
      ],
      "source": [
        "import socket\n",
        "\n",
        "# 输入你的 ngrok 公网地址\n",
        "ngrok_host = \"0.tcp.jp.ngrok.io\"\n",
        "\n",
        "# 获取 IP 地址\n",
        "ip_address = socket.gethostbyname(ngrok_host)\n",
        "\n",
        "# 输出 IP 地址\n",
        "print(f\"IP Address of {ngrok_host}: {ip_address}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d4208eb89de342aba6b90408c476312f",
            "943cc0e49e1e4211b718440252381750",
            "0f3a0a362a714d8bbb6f96eac7c9e2a2",
            "18f0df7e5e844cf48109442f79851652",
            "91a0adb1c7234f458ba0ee2b0d96ea38",
            "a21052c85ece4b4fa65a6f0ce72c99ae",
            "e65a65f7bcbc42828ae6601a7c2addd8",
            "8eb16492fdbe468cb5e4833997176ef4",
            "05e661dcbd6f44bfaa7f22c1354e6810",
            "dc194b33400f4e65a64a071e59e9f430",
            "756252a23c474f0981707478ea6d9ce3",
            "abfa51b4884042b8ab465752d3e4a7df",
            "a92722172922468b93e0065e8992a549",
            "080d26b376f243f6b33655b978f7d822",
            "0ea3abd6bb15432384c71d97f5819508",
            "02e3ae6e1e28406d90a8867e66424e64",
            "c149fb64aee540518facfc37823db46b",
            "4b147433804f429aafe1416e5e1056fd",
            "9e682648ddb544baa373415eb141a9eb",
            "1da0d0041ea84b989734b40d38cbda0c",
            "99e01f47b4744683a39650e920209823",
            "adef8f315fe545ac9b8f7322cbaf76e4"
          ]
        },
        "id": "XkhGVgjLUBiV",
        "outputId": "ccc15b23-8213-44c2-ca85-c086e0a95b5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4208eb89de342aba6b90408c476312f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Dec 10 09:04:56.311 [\u001b[1m\u001b[34mINFO\u001b[0m] Found no active peers: None\n",
            "Dec 10 09:04:56.321 [\u001b[1m\u001b[34mINFO\u001b[0m] Initializing optimizer manually since it has no tensors in state dict. To override this, provide initialize_optimizer=False\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To join the training, use initial_peers = ['/ip4/172.28.0.12/tcp/33539/p2p/12D3KooWE851VaSCr8NTw1ZkSKdpp1Xu5Ke6rxf3CmwzNwu7z3WW', '/ip4/127.0.0.1/tcp/33539/p2p/12D3KooWE851VaSCr8NTw1ZkSKdpp1Xu5Ke6rxf3CmwzNwu7z3WW', '/ip4/172.28.0.12/udp/42771/quic/p2p/12D3KooWE851VaSCr8NTw1ZkSKdpp1Xu5Ke6rxf3CmwzNwu7z3WW', '/ip4/127.0.0.1/udp/42771/quic/p2p/12D3KooWE851VaSCr8NTw1ZkSKdpp1Xu5Ke6rxf3CmwzNwu7z3WW']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Dec 10 09:04:56.391 [\u001b[1m\u001b[38;5;208mWARN\u001b[0m] [\u001b[1mhivemind.averaging.matchmaking.__init__:54\u001b[0m] It is recommended to use request_timeout smaller than min_matchmaking_time. Otherwise, matchmaking can cause deadlocks in some rare cases. Please see Matchmaking docstring.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abfa51b4884042b8ab465752d3e4a7df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Dec 10 09:04:59.331 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2016 samples for epoch #0 from 1 peers. ETA 10.98 sec (refresh in 2.75 sec)\n",
            "Dec 10 09:05:02.081 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 4224 samples for epoch #0 from 1 peers. ETA 5.42 sec (refresh in 1.35 sec)\n",
            "Dec 10 09:05:03.441 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 5664 samples for epoch #0 from 1 peers. ETA 3.95 sec (refresh in 0.99 sec)\n",
            "Dec 10 09:05:04.435 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6720 samples for epoch #0 from 1 peers. ETA 2.98 sec (refresh in 0.74 sec)\n",
            "Dec 10 09:05:05.193 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7520 samples for epoch #0 from 1 peers. ETA 2.26 sec (refresh in 0.57 sec)\n",
            "Dec 10 09:05:05.767 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8064 samples for epoch #0 from 1 peers. ETA 1.85 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:05:06.273 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8608 samples for epoch #0 from 1 peers. ETA 1.32 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:05:06.784 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9120 samples for epoch #0 from 1 peers. ETA 0.85 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:05:07.294 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9664 samples for epoch #0 from 1 peers. ETA 0.31 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:05:07.639 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 1\n",
            "Dec 10 09:05:07.799 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 160 samples for epoch #1 from 1 peers. ETA 9.31 sec (refresh in 2.33 sec)\n",
            "Dec 10 09:05:10.142 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2624 samples for epoch #1 from 1 peers. ETA 6.90 sec (refresh in 1.72 sec)\n",
            "Dec 10 09:05:11.870 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 4224 samples for epoch #1 from 1 peers. ETA 7.48 sec (refresh in 1.87 sec)\n",
            "Dec 10 09:05:13.746 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 5664 samples for epoch #1 from 1 peers. ETA 5.78 sec (refresh in 1.44 sec)\n",
            "Dec 10 09:05:15.195 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6688 samples for epoch #1 from 1 peers. ETA 4.66 sec (refresh in 1.17 sec)\n",
            "Dec 10 09:05:16.367 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7712 samples for epoch #1 from 1 peers. ETA 2.27 sec (refresh in 0.57 sec)\n",
            "Dec 10 09:05:16.941 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8288 samples for epoch #1 from 1 peers. ETA 1.61 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:05:17.450 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8832 samples for epoch #1 from 1 peers. ETA 1.05 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:05:17.957 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9376 samples for epoch #1 from 1 peers. ETA 0.57 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:05:18.470 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9888 samples for epoch #1 from 1 peers. ETA 0.08 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:05:18.568 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 2\n",
            "Dec 10 09:05:18.975 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 416 samples for epoch #2 from 1 peers. ETA 8.85 sec (refresh in 2.21 sec)\n",
            "Dec 10 09:05:21.196 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2752 samples for epoch #2 from 1 peers. ETA 6.89 sec (refresh in 1.72 sec)\n",
            "Dec 10 09:05:22.927 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 4544 samples for epoch #2 from 1 peers. ETA 5.03 sec (refresh in 1.26 sec)\n",
            "Dec 10 09:05:24.195 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 5888 samples for epoch #2 from 1 peers. ETA 3.80 sec (refresh in 0.95 sec)\n",
            "Dec 10 09:05:25.160 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6912 samples for epoch #2 from 1 peers. ETA 2.82 sec (refresh in 0.71 sec)\n",
            "Dec 10 09:05:25.891 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7648 samples for epoch #2 from 1 peers. ETA 2.32 sec (refresh in 0.58 sec)\n",
            "Dec 10 09:05:26.477 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8064 samples for epoch #2 from 1 peers. ETA 2.48 sec (refresh in 0.62 sec)\n",
            "Dec 10 09:05:27.105 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8544 samples for epoch #2 from 1 peers. ETA 1.91 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:05:27.609 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8896 samples for epoch #2 from 1 peers. ETA 1.47 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:05:28.121 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9280 samples for epoch #2 from 1 peers. ETA 0.92 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:05:28.625 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9632 samples for epoch #2 from 1 peers. ETA 0.48 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:05:29.112 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 3\n",
            "Dec 10 09:05:29.140 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 0 samples for epoch #3 from 1 peers. ETA 13.57 sec (refresh in 3.39 sec)\n",
            "Dec 10 09:05:32.538 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 3040 samples for epoch #3 from 1 peers. ETA 6.66 sec (refresh in 1.66 sec)\n",
            "Dec 10 09:05:34.210 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 4800 samples for epoch #3 from 1 peers. ETA 4.88 sec (refresh in 1.22 sec)\n",
            "Dec 10 09:05:35.434 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6080 samples for epoch #3 from 1 peers. ETA 3.62 sec (refresh in 0.91 sec)\n",
            "Dec 10 09:05:36.346 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7008 samples for epoch #3 from 1 peers. ETA 2.85 sec (refresh in 0.71 sec)\n",
            "Dec 10 09:05:37.064 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7744 samples for epoch #3 from 1 peers. ETA 2.18 sec (refresh in 0.54 sec)\n",
            "Dec 10 09:05:37.612 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8320 samples for epoch #3 from 1 peers. ETA 1.65 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:05:38.117 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8864 samples for epoch #3 from 1 peers. ETA 1.03 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:05:38.625 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9376 samples for epoch #3 from 1 peers. ETA 0.60 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:05:39.139 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9920 samples for epoch #3 from 1 peers. ETA 0.05 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:05:39.209 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 4\n",
            "Dec 10 09:05:39.645 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 416 samples for epoch #4 from 1 peers. ETA 9.79 sec (refresh in 2.45 sec)\n",
            "Dec 10 09:05:42.105 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2624 samples for epoch #4 from 1 peers. ETA 9.86 sec (refresh in 2.47 sec)\n",
            "Dec 10 09:05:44.583 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 4384 samples for epoch #4 from 1 peers. ETA 8.23 sec (refresh in 2.06 sec)\n",
            "Dec 10 09:05:46.647 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6304 samples for epoch #4 from 1 peers. ETA 3.58 sec (refresh in 0.90 sec)\n",
            "Dec 10 09:05:47.548 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7232 samples for epoch #4 from 1 peers. ETA 2.65 sec (refresh in 0.66 sec)\n",
            "Dec 10 09:05:48.215 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7968 samples for epoch #4 from 1 peers. ETA 1.86 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:05:48.721 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8480 samples for epoch #4 from 1 peers. ETA 1.45 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:05:49.225 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9024 samples for epoch #4 from 1 peers. ETA 0.87 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:05:49.732 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9536 samples for epoch #4 from 1 peers. ETA 0.43 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:05:50.155 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 5\n",
            "Dec 10 09:05:50.237 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #5 from 1 peers. ETA 9.06 sec (refresh in 2.27 sec)\n",
            "Dec 10 09:05:52.510 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2432 samples for epoch #5 from 1 peers. ETA 7.60 sec (refresh in 1.90 sec)\n",
            "Dec 10 09:05:54.414 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 4448 samples for epoch #5 from 1 peers. ETA 5.07 sec (refresh in 1.27 sec)\n",
            "Dec 10 09:05:55.693 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 5664 samples for epoch #5 from 1 peers. ETA 5.10 sec (refresh in 1.27 sec)\n",
            "Dec 10 09:05:56.982 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6624 samples for epoch #5 from 1 peers. ETA 4.28 sec (refresh in 1.07 sec)\n",
            "Dec 10 09:05:58.062 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7424 samples for epoch #5 from 1 peers. ETA 3.37 sec (refresh in 0.84 sec)\n",
            "Dec 10 09:05:58.919 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8032 samples for epoch #5 from 1 peers. ETA 2.81 sec (refresh in 0.70 sec)\n",
            "Dec 10 09:05:59.637 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8512 samples for epoch #5 from 1 peers. ETA 2.18 sec (refresh in 0.54 sec)\n",
            "Dec 10 09:06:00.187 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8992 samples for epoch #5 from 1 peers. ETA 1.13 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:06:00.694 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9504 samples for epoch #5 from 1 peers. ETA 0.51 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:06:01.165 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 6\n",
            "Dec 10 09:06:01.199 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 0 samples for epoch #6 from 1 peers. ETA 9.46 sec (refresh in 2.37 sec)\n",
            "Dec 10 09:06:03.595 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2496 samples for epoch #6 from 1 peers. ETA 7.14 sec (refresh in 1.79 sec)\n",
            "Dec 10 09:06:05.390 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 4448 samples for epoch #6 from 1 peers. ETA 5.11 sec (refresh in 1.28 sec)\n",
            "Dec 10 09:06:06.685 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 5728 samples for epoch #6 from 1 peers. ETA 4.30 sec (refresh in 1.08 sec)\n",
            "Dec 10 09:06:07.771 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6880 samples for epoch #6 from 1 peers. ETA 2.90 sec (refresh in 0.72 sec)\n",
            "Dec 10 09:06:08.500 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7648 samples for epoch #6 from 1 peers. ETA 2.19 sec (refresh in 0.55 sec)\n",
            "Dec 10 09:06:09.056 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8256 samples for epoch #6 from 1 peers. ETA 1.57 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:06:09.560 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8736 samples for epoch #6 from 1 peers. ETA 1.23 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:06:10.068 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9248 samples for epoch #6 from 1 peers. ETA 0.71 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:06:10.574 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9600 samples for epoch #6 from 1 peers. ETA 0.49 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:06:11.080 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9984 samples for epoch #6 from 1 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:06:11.105 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 7\n",
            "Dec 10 09:06:11.585 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 320 samples for epoch #7 from 1 peers. ETA 13.24 sec (refresh in 3.31 sec)\n",
            "Dec 10 09:06:15.106 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2880 samples for epoch #7 from 1 peers. ETA 7.32 sec (refresh in 1.83 sec)\n",
            "Dec 10 09:06:17.147 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 5312 samples for epoch #7 from 2 peers. ETA 2.51 sec (refresh in 1.00 sec)\n",
            "Dec 10 09:06:18.360 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7168 samples for epoch #7 from 2 peers. ETA 1.50 sec (refresh in 0.60 sec)\n",
            "Dec 10 09:06:19.160 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8512 samples for epoch #7 from 2 peers. ETA 0.59 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:06:19.872 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9536 samples for epoch #7 from 2 peers. ETA 0.01 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:06:19.874 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 8\n",
            "Dec 10 09:06:19.919 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:06:20.566 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #8 from 2 peers. ETA 6.04 sec (refresh in 2.42 sec)\n",
            "Dec 10 09:06:23.176 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #8 from 2 peers. ETA 3.43 sec (refresh in 1.37 sec)\n",
            "Dec 10 09:06:23.567 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:06:23.576 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:06:24.768 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1504 samples for epoch #8 from 2 peers. ETA 9.99 sec (refresh in 4.00 sec)\n",
            "Dec 10 09:06:29.001 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6144 samples for epoch #8 from 2 peers. ETA 3.21 sec (refresh in 1.28 sec)\n",
            "Dec 10 09:06:30.485 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8096 samples for epoch #8 from 2 peers. ETA 1.04 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:06:31.183 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9024 samples for epoch #8 from 2 peers. ETA 0.46 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:06:31.641 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 9\n",
            "Dec 10 09:06:31.744 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:06:31.929 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 0 samples for epoch #9 from 2 peers. ETA 6.38 sec (refresh in 2.55 sec)\n",
            "Dec 10 09:06:34.679 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #9 from 2 peers. ETA 4.17 sec (refresh in 1.67 sec)\n",
            "Dec 10 09:06:35.254 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:06:35.259 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:06:36.557 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1856 samples for epoch #9 from 2 peers. ETA 7.32 sec (refresh in 2.93 sec)\n",
            "Dec 10 09:06:39.703 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6752 samples for epoch #9 from 2 peers. ETA 1.76 sec (refresh in 0.71 sec)\n",
            "Dec 10 09:06:40.602 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7840 samples for epoch #9 from 2 peers. ETA 1.58 sec (refresh in 0.63 sec)\n",
            "Dec 10 09:06:41.453 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8768 samples for epoch #9 from 2 peers. ETA 0.88 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:06:42.149 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9600 samples for epoch #9 from 2 peers. ETA 0.08 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:06:42.255 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 10\n",
            "Dec 10 09:06:42.307 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:06:42.844 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #10 from 2 peers. ETA 8.77 sec (refresh in 3.51 sec)\n",
            "Dec 10 09:06:45.835 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:06:45.838 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:06:46.553 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 800 samples for epoch #10 from 2 peers. ETA 21.34 sec (refresh in 8.54 sec)\n",
            "Dec 10 09:06:55.305 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 13696 samples for epoch #10 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:06:55.357 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 11\n",
            "Dec 10 09:06:55.429 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:06:55.999 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #11 from 2 peers. ETA 8.54 sec (refresh in 3.42 sec)\n",
            "Dec 10 09:06:58.981 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:06:58.987 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:06:59.625 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 640 samples for epoch #11 from 2 peers. ETA 23.71 sec (refresh in 9.48 sec)\n",
            "Dec 10 09:07:09.322 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #12 from 2 peers. ETA 5.15 sec (refresh in 2.06 sec)\n",
            "Dec 10 09:07:09.360 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 12\n",
            "Dec 10 09:07:09.433 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:07:11.574 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #12 from 2 peers. ETA 3.06 sec (refresh in 1.22 sec)\n",
            "Dec 10 09:07:12.024 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:07:12.027 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:07:13.003 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1344 samples for epoch #12 from 2 peers. ETA 11.68 sec (refresh in 4.67 sec)\n",
            "Dec 10 09:07:17.872 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9152 samples for epoch #12 from 2 peers. ETA 0.31 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:07:18.199 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 13\n",
            "Dec 10 09:07:18.243 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:07:18.564 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #13 from 2 peers. ETA 5.86 sec (refresh in 2.35 sec)\n",
            "Dec 10 09:07:21.110 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #13 from 2 peers. ETA 4.75 sec (refresh in 1.90 sec)\n",
            "Dec 10 09:07:23.203 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #13 from 2 peers. ETA 3.54 sec (refresh in 1.42 sec)\n",
            "Dec 10 09:07:24.792 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:07:24.795 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:07:24.817 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #13 from 2 peers. ETA 1.99 sec (refresh in 0.80 sec)\n",
            "Dec 10 09:07:25.817 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1216 samples for epoch #13 from 2 peers. ETA 13.52 sec (refresh in 5.41 sec)\n",
            "Dec 10 09:07:31.427 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 10080 samples for epoch #13 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:07:31.440 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 14\n",
            "Dec 10 09:07:31.500 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:07:32.129 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #14 from 2 peers. ETA 5.68 sec (refresh in 2.27 sec)\n",
            "Dec 10 09:07:34.716 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #14 from 2 peers. ETA 3.63 sec (refresh in 1.45 sec)\n",
            "Dec 10 09:07:35.141 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:07:35.143 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:07:36.371 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1088 samples for epoch #14 from 2 peers. ETA 16.24 sec (refresh in 6.50 sec)\n",
            "Dec 10 09:07:43.065 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #15 from 2 peers. ETA 6.34 sec (refresh in 2.54 sec)\n",
            "Dec 10 09:07:43.096 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 15\n",
            "Dec 10 09:07:43.146 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:07:45.793 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #15 from 2 peers. ETA 3.50 sec (refresh in 1.40 sec)\n",
            "Dec 10 09:07:46.097 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:07:46.100 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:07:47.410 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1888 samples for epoch #15 from 2 peers. ETA 6.87 sec (refresh in 2.75 sec)\n",
            "Dec 10 09:07:50.356 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 5760 samples for epoch #15 from 2 peers. ETA 3.31 sec (refresh in 1.33 sec)\n",
            "Dec 10 09:07:51.907 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7488 samples for epoch #15 from 2 peers. ETA 1.92 sec (refresh in 0.77 sec)\n",
            "Dec 10 09:07:52.878 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8576 samples for epoch #15 from 2 peers. ETA 1.00 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:07:53.593 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9504 samples for epoch #15 from 2 peers. ETA 0.09 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:07:53.703 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 16\n",
            "Dec 10 09:07:53.753 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:07:54.289 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #16 from 2 peers. ETA 6.78 sec (refresh in 2.71 sec)\n",
            "Dec 10 09:07:57.197 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #16 from 2 peers. ETA 3.87 sec (refresh in 1.55 sec)\n",
            "Dec 10 09:07:57.392 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:07:57.395 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:07:58.963 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2208 samples for epoch #16 from 2 peers. ETA 6.06 sec (refresh in 2.42 sec)\n",
            "Dec 10 09:08:01.591 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6464 samples for epoch #16 from 2 peers. ETA 1.96 sec (refresh in 0.79 sec)\n",
            "Dec 10 09:08:02.825 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8256 samples for epoch #16 from 2 peers. ETA 0.69 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:08:03.544 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9472 samples for epoch #16 from 2 peers. ETA 0.11 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:08:03.703 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 17\n",
            "Dec 10 09:08:03.752 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:08:04.238 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #17 from 2 peers. ETA 6.61 sec (refresh in 2.64 sec)\n",
            "Dec 10 09:08:07.074 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #17 from 2 peers. ETA 3.77 sec (refresh in 1.51 sec)\n",
            "Dec 10 09:08:07.338 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:08:07.341 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:08:08.808 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2048 samples for epoch #17 from 2 peers. ETA 6.66 sec (refresh in 2.66 sec)\n",
            "Dec 10 09:08:11.683 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 5632 samples for epoch #17 from 2 peers. ETA 1.51 sec (refresh in 0.60 sec)\n",
            "Dec 10 09:08:12.498 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6432 samples for epoch #17 from 2 peers. ETA 0.73 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:08:13.197 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7072 samples for epoch #17 from 2 peers. ETA 0.05 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:08:13.254 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 18\n",
            "Dec 10 09:08:13.296 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:08:13.889 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #18 from 2 peers. ETA 5.68 sec (refresh in 2.27 sec)\n",
            "Dec 10 09:08:16.355 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #18 from 2 peers. ETA 4.29 sec (refresh in 1.72 sec)\n",
            "Dec 10 09:08:18.302 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #18 from 2 peers. ETA 3.20 sec (refresh in 1.28 sec)\n",
            "Dec 10 09:08:19.775 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #18 from 2 peers. ETA 2.37 sec (refresh in 0.95 sec)\n",
            "Dec 10 09:08:20.917 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #18 from 2 peers. ETA 1.73 sec (refresh in 0.69 sec)\n",
            "Dec 10 09:08:21.803 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #18 from 2 peers. ETA 1.23 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:08:22.496 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #18 from 2 peers. ETA 0.84 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:08:23.191 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #18 from 2 peers. ETA 0.45 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:08:23.265 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaging failed with <class 'concurrent.futures._base.TimeoutError'>\n",
            "Dec 10 09:08:23.268 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:08:23.637 [\u001b[1m\u001b[31mERROR\u001b[0m] [\u001b[1mhivemind.averaging.averager._step:480\u001b[0m] Averaging step failed: could not find a group\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/hivemind/averaging/averager.py\", line 450, in _step\n",
            "    raise AllreduceException(\"Averaging step failed: could not find a group\")\n",
            "hivemind.averaging.partition.AllreduceException: Averaging step failed: could not find a group\n",
            "Dec 10 09:08:23.680 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 19\n",
            "Dec 10 09:08:23.731 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:08:23.905 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 0 samples for epoch #19 from 2 peers. ETA 12.04 sec (refresh in 4.82 sec)\n",
            "Dec 10 09:08:28.919 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #19 from 2 peers. ETA 11.20 sec (refresh in 4.48 sec)\n",
            "Dec 10 09:08:33.598 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #19 from 2 peers. ETA 10.58 sec (refresh in 4.23 sec)\n",
            "Dec 10 09:08:33.694 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaging failed with <class 'concurrent.futures._base.TimeoutError'>\n",
            "Dec 10 09:08:33.698 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:08:34.069 [\u001b[1m\u001b[31mERROR\u001b[0m] [\u001b[1mhivemind.averaging.averager._step:480\u001b[0m] Averaging step failed: could not find a group\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/hivemind/averaging/averager.py\", line 450, in _step\n",
            "    raise AllreduceException(\"Averaging step failed: could not find a group\")\n",
            "hivemind.averaging.partition.AllreduceException: Averaging step failed: could not find a group\n",
            "Dec 10 09:08:38.024 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 3968 samples for epoch #19 from 2 peers. ETA 3.59 sec (refresh in 1.44 sec)\n",
            "Dec 10 09:08:39.775 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 5664 samples for epoch #19 from 2 peers. ETA 2.48 sec (refresh in 0.99 sec)\n",
            "Dec 10 09:08:40.963 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6848 samples for epoch #19 from 2 peers. ETA 1.76 sec (refresh in 0.70 sec)\n",
            "Dec 10 09:08:41.875 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7552 samples for epoch #19 from 2 peers. ETA 1.55 sec (refresh in 0.62 sec)\n",
            "Dec 10 09:08:42.692 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8064 samples for epoch #19 from 2 peers. ETA 1.34 sec (refresh in 0.54 sec)\n",
            "Dec 10 09:08:43.425 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8544 samples for epoch #19 from 2 peers. ETA 0.95 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:08:44.141 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9024 samples for epoch #19 from 2 peers. ETA 0.59 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:08:44.838 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9472 samples for epoch #19 from 2 peers. ETA 0.29 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:08:44.850 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 20\n",
            "Dec 10 09:08:44.908 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:08:45.570 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #20 from 2 peers. ETA 7.20 sec (refresh in 2.88 sec)\n",
            "Dec 10 09:08:48.644 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #20 from 2 peers. ETA 5.81 sec (refresh in 2.32 sec)\n",
            "Dec 10 09:08:51.163 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #20 from 2 peers. ETA 4.67 sec (refresh in 1.87 sec)\n",
            "Dec 10 09:08:53.223 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #20 from 2 peers. ETA 3.73 sec (refresh in 1.49 sec)\n",
            "Dec 10 09:08:54.859 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaging failed with <class 'concurrent.futures._base.TimeoutError'>\n",
            "Dec 10 09:08:54.862 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:08:54.912 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #20 from 2 peers. ETA 2.97 sec (refresh in 1.19 sec)\n",
            "Dec 10 09:08:55.228 [\u001b[1m\u001b[31mERROR\u001b[0m] [\u001b[1mhivemind.averaging.averager._step:480\u001b[0m] Averaging step failed: could not find a group\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/hivemind/averaging/averager.py\", line 450, in _step\n",
            "    raise AllreduceException(\"Averaging step failed: could not find a group\")\n",
            "hivemind.averaging.partition.AllreduceException: Averaging step failed: could not find a group\n",
            "Dec 10 09:08:56.308 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1024 samples for epoch #20 from 2 peers. ETA 8.15 sec (refresh in 3.26 sec)\n",
            "Dec 10 09:08:59.773 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 3232 samples for epoch #20 from 2 peers. ETA 4.92 sec (refresh in 1.97 sec)\n",
            "Dec 10 09:09:01.953 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 4928 samples for epoch #20 from 2 peers. ETA 2.98 sec (refresh in 1.19 sec)\n",
            "Dec 10 09:09:03.379 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6336 samples for epoch #20 from 2 peers. ETA 1.94 sec (refresh in 0.77 sec)\n",
            "Dec 10 09:09:04.355 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7296 samples for epoch #20 from 2 peers. ETA 1.43 sec (refresh in 0.57 sec)\n",
            "Dec 10 09:09:05.131 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8000 samples for epoch #20 from 2 peers. ETA 1.06 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:09:05.831 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8672 samples for epoch #20 from 2 peers. ETA 0.69 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:09:06.529 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9344 samples for epoch #20 from 2 peers. ETA 0.26 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:09:06.813 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 21\n",
            "Dec 10 09:09:06.858 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:09:07.227 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #21 from 2 peers. ETA 5.86 sec (refresh in 2.34 sec)\n",
            "Dec 10 09:09:09.767 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #21 from 2 peers. ETA 4.44 sec (refresh in 1.78 sec)\n",
            "Dec 10 09:09:11.739 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #21 from 2 peers. ETA 3.34 sec (refresh in 1.34 sec)\n",
            "Dec 10 09:09:13.271 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #21 from 2 peers. ETA 2.48 sec (refresh in 0.99 sec)\n",
            "Dec 10 09:09:14.458 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #21 from 2 peers. ETA 1.82 sec (refresh in 0.73 sec)\n",
            "Dec 10 09:09:15.380 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #21 from 2 peers. ETA 1.31 sec (refresh in 0.52 sec)\n",
            "Dec 10 09:09:16.095 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #21 from 2 peers. ETA 0.91 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:09:16.787 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #21 from 2 peers. ETA 0.52 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:09:16.828 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaging failed with <class 'concurrent.futures._base.TimeoutError'>\n",
            "Dec 10 09:09:16.832 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:09:17.206 [\u001b[1m\u001b[31mERROR\u001b[0m] [\u001b[1mhivemind.averaging.averager._step:480\u001b[0m] Averaging step failed: could not find a group\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/hivemind/averaging/averager.py\", line 450, in _step\n",
            "    raise AllreduceException(\"Averaging step failed: could not find a group\")\n",
            "hivemind.averaging.partition.AllreduceException: Averaging step failed: could not find a group\n",
            "Dec 10 09:09:17.486 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 480 samples for epoch #21 from 2 peers. ETA 11.33 sec (refresh in 4.53 sec)\n",
            "Dec 10 09:09:17.490 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 22\n",
            "Dec 10 09:09:17.548 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:09:22.215 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #22 from 1 peers. ETA 63.62 sec (refresh in 10.00 sec)\n",
            "Dec 10 09:09:27.513 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaging failed with <class 'concurrent.futures._base.TimeoutError'>\n",
            "Dec 10 09:09:27.516 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:09:27.885 [\u001b[1m\u001b[31mERROR\u001b[0m] [\u001b[1mhivemind.averaging.averager._step:480\u001b[0m] Averaging step failed: could not find a group\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/hivemind/averaging/averager.py\", line 450, in _step\n",
            "    raise AllreduceException(\"Averaging step failed: could not find a group\")\n",
            "hivemind.averaging.partition.AllreduceException: Averaging step failed: could not find a group\n",
            "Dec 10 09:09:32.438 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8768 samples for epoch #22 from 2 peers. ETA 0.64 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:09:33.145 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9696 samples for epoch #22 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:09:33.147 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 23\n",
            "Dec 10 09:09:33.209 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:09:33.845 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #23 from 2 peers. ETA 7.43 sec (refresh in 2.97 sec)\n",
            "Dec 10 09:09:37.019 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1408 samples for epoch #23 from 2 peers. ETA 3.59 sec (refresh in 1.43 sec)\n",
            "Dec 10 09:09:38.659 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2432 samples for epoch #23 from 2 peers. ETA 1.92 sec (refresh in 0.77 sec)\n",
            "Dec 10 09:09:39.626 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 3104 samples for epoch #23 from 2 peers. ETA 0.97 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:09:40.323 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 3552 samples for epoch #23 from 2 peers. ETA 0.30 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:09:41.018 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #24 from 2 peers. ETA 6.70 sec (refresh in 2.68 sec)\n",
            "Dec 10 09:09:42.899 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:09:42.902 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:09:42.908 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 24\n",
            "Dec 10 09:09:42.959 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:09:43.902 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 480 samples for epoch #24 from 2 peers. ETA 7.95 sec (refresh in 3.18 sec)\n",
            "Dec 10 09:09:47.289 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2592 samples for epoch #24 from 2 peers. ETA 2.82 sec (refresh in 1.13 sec)\n",
            "Dec 10 09:09:48.614 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 3296 samples for epoch #24 from 2 peers. ETA 1.56 sec (refresh in 0.62 sec)\n",
            "Dec 10 09:09:49.442 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 3648 samples for epoch #24 from 2 peers. ETA 0.78 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:09:50.150 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 4032 samples for epoch #24 from 2 peers. ETA 0.04 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:09:50.851 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #25 from 2 peers. ETA 7.71 sec (refresh in 3.08 sec)\n",
            "Dec 10 09:09:52.830 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:09:52.833 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:09:52.838 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 25\n",
            "Dec 10 09:09:52.881 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:09:54.138 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 800 samples for epoch #25 from 2 peers. ETA 6.35 sec (refresh in 2.54 sec)\n",
            "Dec 10 09:09:56.879 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2592 samples for epoch #25 from 2 peers. ETA 2.81 sec (refresh in 1.12 sec)\n",
            "Dec 10 09:09:58.213 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 3520 samples for epoch #25 from 2 peers. ETA 1.26 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:09:58.934 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 3968 samples for epoch #25 from 2 peers. ETA 0.67 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:09:59.639 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 4480 samples for epoch #25 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:10:00.338 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #26 from 2 peers. ETA 6.25 sec (refresh in 2.50 sec)\n",
            "Dec 10 09:10:02.589 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:10:02.591 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:10:02.595 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 26\n",
            "Dec 10 09:10:02.683 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:10:03.071 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 160 samples for epoch #26 from 2 peers. ETA 11.28 sec (refresh in 4.51 sec)\n",
            "Dec 10 09:10:07.776 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2880 samples for epoch #26 from 2 peers. ETA 2.30 sec (refresh in 0.92 sec)\n",
            "Dec 10 09:10:08.896 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 3616 samples for epoch #26 from 2 peers. ETA 1.15 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:10:09.597 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 4064 samples for epoch #26 from 2 peers. ETA 0.50 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:10:10.292 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 4512 samples for epoch #26 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:10:10.989 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #27 from 2 peers. ETA 7.14 sec (refresh in 2.86 sec)\n",
            "Dec 10 09:10:12.391 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:10:12.397 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:10:12.399 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 27\n",
            "Dec 10 09:10:12.455 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:10:14.070 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 928 samples for epoch #27 from 2 peers. ETA 6.22 sec (refresh in 2.49 sec)\n",
            "Dec 10 09:10:16.763 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2368 samples for epoch #27 from 2 peers. ETA 3.66 sec (refresh in 1.46 sec)\n",
            "Dec 10 09:10:18.432 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 3200 samples for epoch #27 from 2 peers. ETA 1.88 sec (refresh in 0.75 sec)\n",
            "Dec 10 09:10:19.381 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 3648 samples for epoch #27 from 2 peers. ETA 1.00 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:10:20.095 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 4000 samples for epoch #27 from 2 peers. ETA 0.26 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:10:20.803 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 0 samples for epoch #28 from 2 peers. ETA 8.51 sec (refresh in 3.40 sec)\n",
            "Dec 10 09:10:22.034 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:10:22.036 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:10:22.052 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 28\n",
            "Dec 10 09:10:22.091 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:10:24.408 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1408 samples for epoch #28 from 2 peers. ETA 4.91 sec (refresh in 1.97 sec)\n",
            "Dec 10 09:10:26.575 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2816 samples for epoch #28 from 2 peers. ETA 2.66 sec (refresh in 1.06 sec)\n",
            "Dec 10 09:10:27.849 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 3712 samples for epoch #28 from 2 peers. ETA 1.32 sec (refresh in 0.53 sec)\n",
            "Dec 10 09:10:28.588 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 4192 samples for epoch #28 from 2 peers. ETA 0.59 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:10:29.291 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 4672 samples for epoch #28 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:10:29.988 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #29 from 2 peers. ETA 6.99 sec (refresh in 2.80 sec)\n",
            "Dec 10 09:10:31.820 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:10:31.823 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:10:31.836 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 29\n",
            "Dec 10 09:10:31.885 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:10:32.979 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 448 samples for epoch #29 from 2 peers. ETA 9.04 sec (refresh in 3.61 sec)\n",
            "Dec 10 09:10:36.789 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2496 samples for epoch #29 from 2 peers. ETA 2.62 sec (refresh in 1.05 sec)\n",
            "Dec 10 09:10:38.047 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 3328 samples for epoch #29 from 2 peers. ETA 1.36 sec (refresh in 0.54 sec)\n",
            "Dec 10 09:10:38.787 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 3840 samples for epoch #29 from 2 peers. ETA 0.61 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:10:39.483 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 4288 samples for epoch #29 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:10:40.179 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #30 from 2 peers. ETA 7.00 sec (refresh in 2.80 sec)\n",
            "Dec 10 09:10:41.609 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:10:41.612 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:10:41.625 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 30\n",
            "Dec 10 09:10:41.687 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:10:43.197 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 864 samples for epoch #30 from 2 peers. ETA 6.42 sec (refresh in 2.57 sec)\n",
            "Dec 10 09:10:45.967 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2624 samples for epoch #30 from 2 peers. ETA 3.18 sec (refresh in 1.27 sec)\n",
            "Dec 10 09:10:47.440 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 3392 samples for epoch #30 from 2 peers. ETA 1.96 sec (refresh in 0.78 sec)\n",
            "Dec 10 09:10:48.438 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 3840 samples for epoch #30 from 2 peers. ETA 1.03 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:10:49.154 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 4192 samples for epoch #30 from 2 peers. ETA 0.31 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:10:49.871 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 0 samples for epoch #31 from 2 peers. ETA 8.25 sec (refresh in 3.30 sec)\n",
            "Dec 10 09:10:51.383 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:10:51.390 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:10:51.399 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 31\n",
            "Dec 10 09:10:51.462 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:10:53.373 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1216 samples for epoch #31 from 2 peers. ETA 5.61 sec (refresh in 2.25 sec)\n",
            "Dec 10 09:10:55.820 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2816 samples for epoch #31 from 2 peers. ETA 2.90 sec (refresh in 1.16 sec)\n",
            "Dec 10 09:10:57.181 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 3744 samples for epoch #31 from 2 peers. ETA 1.43 sec (refresh in 0.57 sec)\n",
            "Dec 10 09:10:57.961 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 4224 samples for epoch #31 from 2 peers. ETA 0.73 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:10:58.656 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 4672 samples for epoch #31 from 2 peers. ETA 0.06 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:10:59.351 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #32 from 2 peers. ETA 6.91 sec (refresh in 2.76 sec)\n",
            "Dec 10 09:11:01.146 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:11:01.150 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:11:01.153 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 32\n",
            "Dec 10 09:11:01.211 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:11:02.314 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 416 samples for epoch #32 from 2 peers. ETA 9.68 sec (refresh in 3.87 sec)\n",
            "Dec 10 09:11:06.392 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2464 samples for epoch #32 from 2 peers. ETA 3.02 sec (refresh in 1.21 sec)\n",
            "Dec 10 09:11:07.799 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 3392 samples for epoch #32 from 2 peers. ETA 1.37 sec (refresh in 0.55 sec)\n",
            "Dec 10 09:11:08.545 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 3872 samples for epoch #32 from 2 peers. ETA 0.68 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:11:09.243 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 4352 samples for epoch #32 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:11:09.937 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #33 from 2 peers. ETA 7.31 sec (refresh in 2.92 sec)\n",
            "Dec 10 09:11:10.806 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:11:10.809 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:11:10.815 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 33\n",
            "Dec 10 09:11:10.864 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:11:13.056 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 96 samples for epoch #33 from 2 peers. ETA 9.53 sec (refresh in 3.81 sec)\n",
            "Dec 10 09:11:17.066 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 96 samples for epoch #33 from 2 peers. ETA 5.52 sec (refresh in 2.21 sec)\n",
            "Dec 10 09:11:19.472 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 96 samples for epoch #33 from 2 peers. ETA 3.12 sec (refresh in 1.25 sec)\n",
            "Dec 10 09:11:20.842 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaging failed with <class 'concurrent.futures._base.TimeoutError'>\n",
            "Dec 10 09:11:20.846 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:11:20.916 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 96 samples for epoch #33 from 2 peers. ETA 1.67 sec (refresh in 0.67 sec)\n",
            "Dec 10 09:11:21.216 [\u001b[1m\u001b[31mERROR\u001b[0m] [\u001b[1mhivemind.averaging.averager._step:480\u001b[0m] Averaging step failed: could not find a group\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/hivemind/averaging/averager.py\", line 450, in _step\n",
            "    raise AllreduceException(\"Averaging step failed: could not find a group\")\n",
            "hivemind.averaging.partition.AllreduceException: Averaging step failed: could not find a group\n",
            "Dec 10 09:11:21.793 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 736 samples for epoch #33 from 2 peers. ETA 22.05 sec (refresh in 8.82 sec)\n",
            "Dec 10 09:11:30.827 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8832 samples for epoch #33 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:11:30.852 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 34\n",
            "Dec 10 09:11:30.921 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:11:31.524 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #34 from 2 peers. ETA 9.59 sec (refresh in 3.84 sec)\n",
            "Dec 10 09:11:35.559 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #34 from 2 peers. ETA 6.20 sec (refresh in 2.48 sec)\n",
            "Dec 10 09:11:38.236 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #34 from 2 peers. ETA 3.95 sec (refresh in 1.58 sec)\n",
            "Dec 10 09:11:40.044 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #34 from 2 peers. ETA 2.42 sec (refresh in 0.97 sec)\n",
            "Dec 10 09:11:40.868 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaging failed with <class 'concurrent.futures._base.TimeoutError'>\n",
            "Dec 10 09:11:40.872 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:11:41.238 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 160 samples for epoch #34 from 2 peers. ETA 49.46 sec (refresh in 10.00 sec)\n",
            "Dec 10 09:11:41.263 [\u001b[1m\u001b[31mERROR\u001b[0m] [\u001b[1mhivemind.averaging.averager._step:480\u001b[0m] Averaging step failed: could not find a group\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/hivemind/averaging/averager.py\", line 450, in _step\n",
            "    raise AllreduceException(\"Averaging step failed: could not find a group\")\n",
            "hivemind.averaging.partition.AllreduceException: Averaging step failed: could not find a group\n",
            "Dec 10 09:11:51.490 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7936 samples for epoch #34 from 2 peers. ETA 1.73 sec (refresh in 0.69 sec)\n",
            "Dec 10 09:11:52.395 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8736 samples for epoch #34 from 2 peers. ETA 1.00 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:11:53.094 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9344 samples for epoch #34 from 2 peers. ETA 0.47 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:11:53.577 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 35\n",
            "Dec 10 09:11:53.640 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:11:53.883 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 0 samples for epoch #35 from 2 peers. ETA 9.84 sec (refresh in 3.93 sec)\n",
            "Dec 10 09:11:58.014 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #35 from 2 peers. ETA 6.17 sec (refresh in 2.47 sec)\n",
            "Dec 10 09:12:00.694 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #35 from 2 peers. ETA 3.91 sec (refresh in 1.56 sec)\n",
            "Dec 10 09:12:02.453 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #35 from 2 peers. ETA 2.42 sec (refresh in 0.97 sec)\n",
            "Dec 10 09:12:03.600 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaging failed with <class 'concurrent.futures._base.TimeoutError'>\n",
            "Dec 10 09:12:03.603 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:12:03.622 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #35 from 2 peers. ETA 1.44 sec (refresh in 0.57 sec)\n",
            "Dec 10 09:12:03.967 [\u001b[1m\u001b[31mERROR\u001b[0m] [\u001b[1mhivemind.averaging.averager._step:480\u001b[0m] Averaging step failed: could not find a group\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/hivemind/averaging/averager.py\", line 450, in _step\n",
            "    raise AllreduceException(\"Averaging step failed: could not find a group\")\n",
            "hivemind.averaging.partition.AllreduceException: Averaging step failed: could not find a group\n",
            "Dec 10 09:12:04.393 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 576 samples for epoch #35 from 2 peers. ETA 31.11 sec (refresh in 10.00 sec)\n",
            "Dec 10 09:12:14.604 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8928 samples for epoch #35 from 2 peers. ETA 1.17 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:12:15.333 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9312 samples for epoch #35 from 2 peers. ETA 0.76 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:12:16.078 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9728 samples for epoch #35 from 2 peers. ETA 0.20 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:12:16.290 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 36\n",
            "Dec 10 09:12:16.362 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:12:16.771 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #36 from 2 peers. ETA 13.70 sec (refresh in 5.48 sec)\n",
            "Dec 10 09:12:23.032 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #36 from 1 peers. ETA 11.32 sec (refresh in 2.83 sec)\n",
            "Dec 10 09:12:26.066 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2272 samples for epoch #36 from 2 peers. ETA 1.68 sec (refresh in 0.67 sec)\n",
            "Dec 10 09:12:26.305 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaging failed with <class 'concurrent.futures._base.TimeoutError'>\n",
            "Dec 10 09:12:26.310 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:12:26.712 [\u001b[1m\u001b[31mERROR\u001b[0m] [\u001b[1mhivemind.averaging.averager._step:480\u001b[0m] Averaging step failed: could not find a group\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/hivemind/averaging/averager.py\", line 450, in _step\n",
            "    raise AllreduceException(\"Averaging step failed: could not find a group\")\n",
            "hivemind.averaging.partition.AllreduceException: Averaging step failed: could not find a group\n",
            "Dec 10 09:12:27.015 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 3200 samples for epoch #36 from 2 peers. ETA 8.04 sec (refresh in 3.22 sec)\n",
            "Dec 10 09:12:30.458 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7360 samples for epoch #36 from 2 peers. ETA 2.02 sec (refresh in 0.81 sec)\n",
            "Dec 10 09:12:31.532 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8544 samples for epoch #36 from 2 peers. ETA 0.86 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:12:32.241 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9440 samples for epoch #36 from 2 peers. ETA 0.17 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:12:32.439 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 37\n",
            "Dec 10 09:12:32.501 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:12:32.941 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #37 from 2 peers. ETA 7.83 sec (refresh in 3.13 sec)\n",
            "Dec 10 09:12:36.196 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:12:36.200 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:12:36.284 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #37 from 2 peers. ETA 4.49 sec (refresh in 1.80 sec)\n",
            "Dec 10 09:12:38.353 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2784 samples for epoch #37 from 2 peers. ETA 5.08 sec (refresh in 2.03 sec)\n",
            "Dec 10 09:12:40.629 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6016 samples for epoch #37 from 2 peers. ETA 2.42 sec (refresh in 0.97 sec)\n",
            "Dec 10 09:12:41.808 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7680 samples for epoch #37 from 2 peers. ETA 1.34 sec (refresh in 0.54 sec)\n",
            "Dec 10 09:12:42.564 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8672 samples for epoch #37 from 2 peers. ETA 0.69 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:12:43.274 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9504 samples for epoch #37 from 2 peers. ETA 0.10 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:12:43.391 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 38\n",
            "Dec 10 09:12:43.504 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:12:43.972 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #38 from 2 peers. ETA 8.13 sec (refresh in 3.25 sec)\n",
            "Dec 10 09:12:47.064 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:12:47.074 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:12:47.752 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 352 samples for epoch #38 from 2 peers. ETA 45.45 sec (refresh in 10.00 sec)\n",
            "Dec 10 09:12:58.551 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #39 from 2 peers. ETA 8.23 sec (refresh in 3.29 sec)\n",
            "Dec 10 09:12:58.784 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 39\n",
            "Dec 10 09:12:59.201 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:13:00.984 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:13:00.987 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:13:02.089 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 672 samples for epoch #39 from 2 peers. ETA 39.56 sec (refresh in 10.00 sec)\n",
            "Dec 10 09:13:12.309 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #40 from 2 peers. ETA 5.59 sec (refresh in 2.24 sec)\n",
            "Dec 10 09:13:12.326 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 40\n",
            "Dec 10 09:13:12.372 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:13:14.747 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #40 from 2 peers. ETA 3.27 sec (refresh in 1.31 sec)\n",
            "Dec 10 09:13:15.817 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:13:15.821 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:13:16.335 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 320 samples for epoch #40 from 2 peers. ETA 55.45 sec (refresh in 10.00 sec)\n",
            "Dec 10 09:13:26.603 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 14176 samples for epoch #40 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:13:26.616 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 41\n",
            "Dec 10 09:13:26.673 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:13:27.302 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #41 from 2 peers. ETA 7.62 sec (refresh in 3.05 sec)\n",
            "Dec 10 09:13:30.237 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:13:30.241 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:13:30.555 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 128 samples for epoch #41 from 2 peers. ETA 15.17 sec (refresh in 6.07 sec)\n",
            "Dec 10 09:13:36.852 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7712 samples for epoch #41 from 2 peers. ETA 1.33 sec (refresh in 0.53 sec)\n",
            "Dec 10 09:13:37.610 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8800 samples for epoch #41 from 2 peers. ETA 0.55 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:13:38.341 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9792 samples for epoch #41 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:13:38.344 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 42\n",
            "Dec 10 09:13:38.407 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:13:39.037 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #42 from 2 peers. ETA 6.98 sec (refresh in 2.79 sec)\n",
            "Dec 10 09:13:41.883 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:13:41.890 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:13:42.032 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #42 from 2 peers. ETA 3.99 sec (refresh in 1.60 sec)\n",
            "Dec 10 09:13:43.839 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2592 samples for epoch #42 from 2 peers. ETA 5.87 sec (refresh in 2.35 sec)\n",
            "Dec 10 09:13:46.427 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6016 samples for epoch #42 from 2 peers. ETA 2.96 sec (refresh in 1.18 sec)\n",
            "Dec 10 09:13:47.849 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7392 samples for epoch #42 from 2 peers. ETA 2.46 sec (refresh in 0.99 sec)\n",
            "Dec 10 09:13:49.090 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8544 samples for epoch #42 from 2 peers. ETA 1.12 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:13:49.805 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9248 samples for epoch #42 from 2 peers. ETA 0.55 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:13:50.512 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9856 samples for epoch #42 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:13:50.514 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 43\n",
            "Dec 10 09:13:50.576 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:13:51.249 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #43 from 2 peers. ETA 9.87 sec (refresh in 3.95 sec)\n",
            "Dec 10 09:13:54.164 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:13:54.171 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:13:55.429 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1312 samples for epoch #43 from 2 peers. ETA 12.30 sec (refresh in 4.92 sec)\n",
            "Dec 10 09:14:00.609 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7936 samples for epoch #43 from 2 peers. ETA 1.11 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:14:01.351 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8800 samples for epoch #43 from 2 peers. ETA 0.65 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:14:02.099 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9728 samples for epoch #43 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:14:02.104 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 44\n",
            "Dec 10 09:14:02.204 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:14:02.805 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #44 from 2 peers. ETA 7.91 sec (refresh in 3.16 sec)\n",
            "Dec 10 09:14:05.806 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:14:05.812 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:14:06.189 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 288 samples for epoch #44 from 2 peers. ETA 48.97 sec (refresh in 10.00 sec)\n",
            "Dec 10 09:14:16.403 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #45 from 2 peers. ETA 10.28 sec (refresh in 4.11 sec)\n",
            "Dec 10 09:14:16.441 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 45\n",
            "Dec 10 09:14:16.538 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:14:17.712 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:14:17.714 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:14:20.730 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 4032 samples for epoch #45 from 2 peers. ETA 3.95 sec (refresh in 1.58 sec)\n",
            "Dec 10 09:14:22.561 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6656 samples for epoch #45 from 2 peers. ETA 1.96 sec (refresh in 0.78 sec)\n",
            "Dec 10 09:14:23.574 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8128 samples for epoch #45 from 2 peers. ETA 0.96 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:14:24.282 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9184 samples for epoch #45 from 2 peers. ETA 0.28 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:14:24.571 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 46\n",
            "Dec 10 09:14:24.624 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:14:24.987 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #46 from 2 peers. ETA 7.56 sec (refresh in 3.02 sec)\n",
            "Dec 10 09:14:28.178 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:14:28.187 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:14:28.216 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #46 from 2 peers. ETA 5.78 sec (refresh in 2.31 sec)\n",
            "Dec 10 09:14:30.763 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2688 samples for epoch #46 from 2 peers. ETA 6.13 sec (refresh in 2.45 sec)\n",
            "Dec 10 09:14:33.501 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 5952 samples for epoch #46 from 2 peers. ETA 3.05 sec (refresh in 1.22 sec)\n",
            "Dec 10 09:14:35.137 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8064 samples for epoch #46 from 2 peers. ETA 0.89 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:14:35.858 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9312 samples for epoch #46 from 2 peers. ETA 0.19 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:14:36.085 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 47\n",
            "Dec 10 09:14:36.125 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:14:36.557 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #47 from 2 peers. ETA 6.76 sec (refresh in 2.70 sec)\n",
            "Dec 10 09:14:39.457 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #47 from 2 peers. ETA 3.86 sec (refresh in 1.54 sec)\n",
            "Dec 10 09:14:39.695 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:14:39.701 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:14:41.218 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1440 samples for epoch #47 from 2 peers. ETA 10.97 sec (refresh in 4.39 sec)\n",
            "Dec 10 09:14:45.866 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6912 samples for epoch #47 from 2 peers. ETA 2.28 sec (refresh in 0.91 sec)\n",
            "Dec 10 09:14:47.035 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8288 samples for epoch #47 from 2 peers. ETA 1.15 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:14:47.773 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9120 samples for epoch #47 from 2 peers. ETA 0.45 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:14:48.280 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 48\n",
            "Dec 10 09:14:48.375 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:14:48.561 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 0 samples for epoch #48 from 2 peers. ETA 8.62 sec (refresh in 3.45 sec)\n",
            "Dec 10 09:14:51.893 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:14:51.896 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:14:52.304 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 224 samples for epoch #48 from 2 peers. ETA 9.14 sec (refresh in 3.66 sec)\n",
            "Dec 10 09:14:56.222 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 5536 samples for epoch #48 from 2 peers. ETA 3.19 sec (refresh in 1.28 sec)\n",
            "Dec 10 09:14:57.766 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7392 samples for epoch #48 from 2 peers. ETA 1.81 sec (refresh in 0.72 sec)\n",
            "Dec 10 09:14:58.734 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8512 samples for epoch #48 from 2 peers. ETA 1.04 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:14:59.530 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9280 samples for epoch #48 from 2 peers. ETA 0.42 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:14:59.999 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 49\n",
            "Dec 10 09:15:00.050 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:15:00.312 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 0 samples for epoch #49 from 2 peers. ETA 9.63 sec (refresh in 3.85 sec)\n",
            "Dec 10 09:15:04.362 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #49 from 2 peers. ETA 4.85 sec (refresh in 1.94 sec)\n",
            "Dec 10 09:15:06.510 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #49 from 2 peers. ETA 2.71 sec (refresh in 1.08 sec)\n",
            "Dec 10 09:15:06.660 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:15:06.667 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:15:07.829 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1408 samples for epoch #49 from 2 peers. ETA 13.62 sec (refresh in 5.45 sec)\n",
            "Dec 10 09:15:13.535 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8608 samples for epoch #49 from 2 peers. ETA 1.04 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:15:14.284 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9376 samples for epoch #49 from 2 peers. ETA 0.31 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:15:14.644 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 50\n",
            "Dec 10 09:15:14.735 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:15:15.027 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #50 from 2 peers. ETA 10.43 sec (refresh in 4.17 sec)\n",
            "Dec 10 09:15:19.397 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #50 from 2 peers. ETA 5.10 sec (refresh in 2.04 sec)\n",
            "Dec 10 09:15:21.211 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:15:21.216 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:15:21.756 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 544 samples for epoch #50 from 2 peers. ETA 41.39 sec (refresh in 10.00 sec)\n",
            "Dec 10 09:15:31.963 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #51 from 2 peers. ETA 9.17 sec (refresh in 3.67 sec)\n",
            "Dec 10 09:15:31.990 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 51\n",
            "Dec 10 09:15:32.060 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:15:35.695 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:15:35.697 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:15:35.842 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #51 from 2 peers. ETA 4.28 sec (refresh in 1.71 sec)\n",
            "Dec 10 09:15:37.767 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2816 samples for epoch #51 from 2 peers. ETA 5.32 sec (refresh in 2.13 sec)\n",
            "Dec 10 09:15:40.119 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6240 samples for epoch #51 from 2 peers. ETA 2.29 sec (refresh in 0.91 sec)\n",
            "Dec 10 09:15:41.280 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7808 samples for epoch #51 from 2 peers. ETA 1.28 sec (refresh in 0.51 sec)\n",
            "Dec 10 09:15:42.031 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8640 samples for epoch #51 from 2 peers. ETA 0.89 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:15:42.768 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9280 samples for epoch #51 from 2 peers. ETA 0.44 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:15:43.217 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 52\n",
            "Dec 10 09:15:43.307 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:15:43.503 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 0 samples for epoch #52 from 2 peers. ETA 10.33 sec (refresh in 4.13 sec)\n",
            "Dec 10 09:15:47.834 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #52 from 2 peers. ETA 6.77 sec (refresh in 2.71 sec)\n",
            "Dec 10 09:15:49.852 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:15:49.855 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:15:50.759 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 992 samples for epoch #52 from 2 peers. ETA 21.57 sec (refresh in 8.63 sec)\n",
            "Dec 10 09:15:59.637 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #53 from 2 peers. ETA 7.61 sec (refresh in 3.05 sec)\n",
            "Dec 10 09:15:59.652 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 53\n",
            "Dec 10 09:15:59.717 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:16:02.880 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #53 from 2 peers. ETA 4.33 sec (refresh in 1.73 sec)\n",
            "Dec 10 09:16:03.259 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:16:03.268 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:16:04.860 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1920 samples for epoch #53 from 2 peers. ETA 8.73 sec (refresh in 3.49 sec)\n",
            "Dec 10 09:16:08.570 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7392 samples for epoch #53 from 2 peers. ETA 1.51 sec (refresh in 0.60 sec)\n",
            "Dec 10 09:16:09.386 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8544 samples for epoch #53 from 2 peers. ETA 0.73 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:16:10.135 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9632 samples for epoch #53 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:16:10.174 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 54\n",
            "Dec 10 09:16:10.228 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:16:10.855 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #54 from 2 peers. ETA 7.49 sec (refresh in 3.00 sec)\n",
            "Dec 10 09:16:14.075 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #54 from 2 peers. ETA 5.49 sec (refresh in 2.20 sec)\n",
            "Dec 10 09:16:16.467 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #54 from 2 peers. ETA 3.19 sec (refresh in 1.28 sec)\n",
            "Dec 10 09:16:16.776 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:16:16.778 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:16:17.954 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1344 samples for epoch #54 from 2 peers. ETA 13.84 sec (refresh in 5.54 sec)\n",
            "Dec 10 09:16:23.713 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9696 samples for epoch #54 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:16:23.720 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 55\n",
            "Dec 10 09:16:23.772 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:16:24.415 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #55 from 2 peers. ETA 7.76 sec (refresh in 3.10 sec)\n",
            "Dec 10 09:16:27.391 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:16:27.398 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:16:27.791 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 160 samples for epoch #55 from 2 peers. ETA 9.54 sec (refresh in 3.82 sec)\n",
            "Dec 10 09:16:31.853 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 5920 samples for epoch #55 from 2 peers. ETA 2.64 sec (refresh in 1.06 sec)\n",
            "Dec 10 09:16:33.151 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7808 samples for epoch #55 from 2 peers. ETA 1.21 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:16:33.907 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8736 samples for epoch #55 from 2 peers. ETA 0.56 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:16:34.754 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 10016 samples for epoch #55 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:16:34.757 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 56\n",
            "Dec 10 09:16:34.807 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:16:35.453 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #56 from 2 peers. ETA 5.93 sec (refresh in 2.37 sec)\n",
            "Dec 10 09:16:38.022 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #56 from 2 peers. ETA 3.36 sec (refresh in 1.34 sec)\n",
            "Dec 10 09:16:38.137 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:16:38.140 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:16:39.624 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1152 samples for epoch #56 from 2 peers. ETA 17.38 sec (refresh in 6.95 sec)\n",
            "Dec 10 09:16:46.779 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 10560 samples for epoch #56 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:16:46.815 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 57\n",
            "Dec 10 09:16:46.861 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:16:47.478 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #57 from 2 peers. ETA 6.76 sec (refresh in 2.71 sec)\n",
            "Dec 10 09:16:50.382 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #57 from 2 peers. ETA 4.33 sec (refresh in 1.73 sec)\n",
            "Dec 10 09:16:50.423 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:16:50.429 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:16:52.376 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1952 samples for epoch #57 from 2 peers. ETA 8.01 sec (refresh in 3.20 sec)\n",
            "Dec 10 09:16:55.835 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 5504 samples for epoch #57 from 2 peers. ETA 3.78 sec (refresh in 1.51 sec)\n",
            "Dec 10 09:16:57.582 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7680 samples for epoch #57 from 2 peers. ETA 1.62 sec (refresh in 0.65 sec)\n",
            "Dec 10 09:16:58.451 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8640 samples for epoch #57 from 2 peers. ETA 0.94 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:16:59.170 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9504 samples for epoch #57 from 2 peers. ETA 0.17 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:16:59.358 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 58\n",
            "Dec 10 09:16:59.412 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:16:59.867 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #58 from 2 peers. ETA 7.40 sec (refresh in 2.96 sec)\n",
            "Dec 10 09:17:03.018 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:17:03.021 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:17:03.098 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #58 from 2 peers. ETA 4.17 sec (refresh in 1.67 sec)\n",
            "Dec 10 09:17:04.979 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2496 samples for epoch #58 from 2 peers. ETA 5.95 sec (refresh in 2.38 sec)\n",
            "Dec 10 09:17:07.626 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 5664 samples for epoch #58 from 2 peers. ETA 3.21 sec (refresh in 1.28 sec)\n",
            "Dec 10 09:17:09.128 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7456 samples for epoch #58 from 2 peers. ETA 1.87 sec (refresh in 0.75 sec)\n",
            "Dec 10 09:17:10.195 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8320 samples for epoch #58 from 2 peers. ETA 1.29 sec (refresh in 0.52 sec)\n",
            "Dec 10 09:17:10.922 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9216 samples for epoch #58 from 2 peers. ETA 0.37 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:17:11.336 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 59\n",
            "Dec 10 09:17:11.388 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:17:11.623 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #59 from 2 peers. ETA 8.05 sec (refresh in 3.22 sec)\n",
            "Dec 10 09:17:14.929 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:17:14.933 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:17:15.039 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #59 from 2 peers. ETA 4.75 sec (refresh in 1.90 sec)\n",
            "Dec 10 09:17:17.235 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2848 samples for epoch #59 from 2 peers. ETA 5.33 sec (refresh in 2.13 sec)\n",
            "Dec 10 09:17:19.592 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6464 samples for epoch #59 from 2 peers. ETA 2.06 sec (refresh in 0.82 sec)\n",
            "Dec 10 09:17:20.631 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7936 samples for epoch #59 from 2 peers. ETA 1.08 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:17:21.365 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8768 samples for epoch #59 from 2 peers. ETA 0.74 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:17:22.146 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9696 samples for epoch #59 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:17:22.151 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 60\n",
            "Dec 10 09:17:22.254 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:17:22.852 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #60 from 2 peers. ETA 8.64 sec (refresh in 3.45 sec)\n",
            "Dec 10 09:17:25.812 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:17:25.815 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:17:26.626 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 832 samples for epoch #60 from 2 peers. ETA 22.29 sec (refresh in 8.92 sec)\n",
            "Dec 10 09:17:35.786 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 13888 samples for epoch #60 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:17:35.839 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 61\n",
            "Dec 10 09:17:35.928 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:17:36.492 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #61 from 2 peers. ETA 9.75 sec (refresh in 3.90 sec)\n",
            "Dec 10 09:17:39.714 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:17:39.723 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:17:40.614 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 928 samples for epoch #61 from 2 peers. ETA 18.91 sec (refresh in 7.57 sec)\n",
            "Dec 10 09:17:48.383 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #62 from 2 peers. ETA 6.79 sec (refresh in 2.72 sec)\n",
            "Dec 10 09:17:48.425 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 62\n",
            "Dec 10 09:17:48.559 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:17:50.372 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:17:50.375 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:17:51.318 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 736 samples for epoch #62 from 2 peers. ETA 21.62 sec (refresh in 8.65 sec)\n",
            "Dec 10 09:18:00.276 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #63 from 2 peers. ETA 6.00 sec (refresh in 2.40 sec)\n",
            "Dec 10 09:18:00.305 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 63\n",
            "Dec 10 09:18:00.352 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:18:01.571 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:18:01.574 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:18:02.939 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1440 samples for epoch #63 from 2 peers. ETA 9.66 sec (refresh in 3.86 sec)\n",
            "Dec 10 09:18:07.014 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 5408 samples for epoch #63 from 2 peers. ETA 4.60 sec (refresh in 1.84 sec)\n",
            "Dec 10 09:18:09.090 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7872 samples for epoch #63 from 2 peers. ETA 1.44 sec (refresh in 0.58 sec)\n",
            "Dec 10 09:18:09.913 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8960 samples for epoch #63 from 2 peers. ETA 0.57 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:18:10.614 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9952 samples for epoch #63 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:18:10.616 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 64\n",
            "Dec 10 09:18:10.684 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:18:11.310 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #64 from 2 peers. ETA 7.04 sec (refresh in 2.82 sec)\n",
            "Dec 10 09:18:14.225 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:18:14.229 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:18:14.329 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #64 from 2 peers. ETA 4.03 sec (refresh in 1.61 sec)\n",
            "Dec 10 09:18:16.178 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2528 samples for epoch #64 from 2 peers. ETA 5.84 sec (refresh in 2.34 sec)\n",
            "Dec 10 09:18:18.756 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 5856 samples for epoch #64 from 2 peers. ETA 3.28 sec (refresh in 1.31 sec)\n",
            "Dec 10 09:18:20.349 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7680 samples for epoch #64 from 2 peers. ETA 1.81 sec (refresh in 0.72 sec)\n",
            "Dec 10 09:18:21.320 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8640 samples for epoch #64 from 2 peers. ETA 1.12 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:18:22.052 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9312 samples for epoch #64 from 2 peers. ETA 0.44 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:18:22.531 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 65\n",
            "Dec 10 09:18:22.616 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:18:22.800 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 0 samples for epoch #65 from 2 peers. ETA 10.45 sec (refresh in 4.18 sec)\n",
            "Dec 10 09:18:26.139 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:18:26.145 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:18:27.211 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1184 samples for epoch #65 from 2 peers. ETA 14.41 sec (refresh in 5.76 sec)\n",
            "Dec 10 09:18:33.206 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9728 samples for epoch #65 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:18:33.267 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 66\n",
            "Dec 10 09:18:33.359 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:18:33.908 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #66 from 2 peers. ETA 8.36 sec (refresh in 3.34 sec)\n",
            "Dec 10 09:18:36.733 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:18:36.744 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:18:37.463 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 832 samples for epoch #66 from 2 peers. ETA 21.66 sec (refresh in 8.66 sec)\n",
            "Dec 10 09:18:46.378 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #67 from 2 peers. ETA 6.49 sec (refresh in 2.59 sec)\n",
            "Dec 10 09:18:46.393 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 67\n",
            "Dec 10 09:18:46.496 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:18:49.175 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #67 from 2 peers. ETA 4.42 sec (refresh in 1.77 sec)\n",
            "Dec 10 09:18:49.985 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:18:49.990 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:18:51.148 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1344 samples for epoch #67 from 2 peers. ETA 13.69 sec (refresh in 5.48 sec)\n",
            "Dec 10 09:18:56.839 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9568 samples for epoch #67 from 2 peers. ETA 0.03 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:18:56.906 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 68\n",
            "Dec 10 09:18:56.953 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:18:57.534 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #68 from 2 peers. ETA 7.19 sec (refresh in 2.88 sec)\n",
            "Dec 10 09:19:00.519 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:19:00.523 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:19:00.629 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #68 from 2 peers. ETA 4.10 sec (refresh in 1.64 sec)\n",
            "Dec 10 09:19:02.488 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1568 samples for epoch #68 from 2 peers. ETA 13.13 sec (refresh in 5.25 sec)\n",
            "Dec 10 09:19:07.956 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8960 samples for epoch #68 from 2 peers. ETA 0.38 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:19:08.377 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 69\n",
            "Dec 10 09:19:08.441 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:19:08.665 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 0 samples for epoch #69 from 2 peers. ETA 6.78 sec (refresh in 2.71 sec)\n",
            "Dec 10 09:19:11.577 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #69 from 2 peers. ETA 4.04 sec (refresh in 1.62 sec)\n",
            "Dec 10 09:19:12.015 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:19:12.018 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:19:13.430 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1504 samples for epoch #69 from 2 peers. ETA 11.23 sec (refresh in 4.49 sec)\n",
            "Dec 10 09:19:18.138 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6432 samples for epoch #69 from 2 peers. ETA 3.64 sec (refresh in 1.46 sec)\n",
            "Dec 10 09:19:19.978 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8256 samples for epoch #69 from 2 peers. ETA 1.17 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:19:20.706 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9312 samples for epoch #69 from 2 peers. ETA 0.29 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:19:21.012 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 70\n",
            "Dec 10 09:19:21.090 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:19:21.404 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #70 from 2 peers. ETA 7.69 sec (refresh in 3.08 sec)\n",
            "Dec 10 09:19:24.633 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:19:24.637 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:19:24.683 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #70 from 2 peers. ETA 4.29 sec (refresh in 1.72 sec)\n",
            "Dec 10 09:19:26.610 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2496 samples for epoch #70 from 2 peers. ETA 5.68 sec (refresh in 2.27 sec)\n",
            "Dec 10 09:19:29.116 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6176 samples for epoch #70 from 2 peers. ETA 2.31 sec (refresh in 0.93 sec)\n",
            "Dec 10 09:19:30.281 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7520 samples for epoch #70 from 2 peers. ETA 1.71 sec (refresh in 0.68 sec)\n",
            "Dec 10 09:19:31.206 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8512 samples for epoch #70 from 2 peers. ETA 1.13 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:19:31.909 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9152 samples for epoch #70 from 2 peers. ETA 0.59 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:19:32.662 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9856 samples for epoch #70 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:19:32.673 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 71\n",
            "Dec 10 09:19:32.749 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:19:33.472 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #71 from 2 peers. ETA 9.60 sec (refresh in 3.84 sec)\n",
            "Dec 10 09:19:36.290 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:19:36.295 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:19:37.556 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1440 samples for epoch #71 from 2 peers. ETA 11.22 sec (refresh in 4.49 sec)\n",
            "Dec 10 09:19:42.256 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8384 samples for epoch #71 from 2 peers. ETA 0.88 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:19:42.990 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9408 samples for epoch #71 from 2 peers. ETA 0.13 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:19:43.136 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 72\n",
            "Dec 10 09:19:43.195 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:19:43.693 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #72 from 2 peers. ETA 6.87 sec (refresh in 2.75 sec)\n",
            "Dec 10 09:19:46.638 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #72 from 2 peers. ETA 3.93 sec (refresh in 1.57 sec)\n",
            "Dec 10 09:19:46.759 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:19:46.761 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:19:48.428 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1952 samples for epoch #72 from 2 peers. ETA 7.62 sec (refresh in 3.05 sec)\n",
            "Dec 10 09:19:51.724 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6784 samples for epoch #72 from 2 peers. ETA 1.91 sec (refresh in 0.76 sec)\n",
            "Dec 10 09:19:52.923 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8320 samples for epoch #72 from 2 peers. ETA 0.70 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:19:53.638 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9568 samples for epoch #72 from 2 peers. ETA 0.03 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:19:53.700 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 73\n",
            "Dec 10 09:19:53.747 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:19:54.336 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #73 from 2 peers. ETA 6.33 sec (refresh in 2.53 sec)\n",
            "Dec 10 09:19:57.112 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #73 from 2 peers. ETA 3.56 sec (refresh in 1.42 sec)\n",
            "Dec 10 09:19:57.502 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:19:57.505 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:19:58.768 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1024 samples for epoch #73 from 2 peers. ETA 20.07 sec (refresh in 8.03 sec)\n",
            "Dec 10 09:20:07.038 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 11424 samples for epoch #73 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:20:07.085 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 74\n",
            "Dec 10 09:20:07.151 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:20:07.742 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #74 from 2 peers. ETA 6.52 sec (refresh in 2.61 sec)\n",
            "Dec 10 09:20:10.545 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #74 from 2 peers. ETA 3.77 sec (refresh in 1.51 sec)\n",
            "Dec 10 09:20:10.684 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:20:10.687 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:20:12.307 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1536 samples for epoch #74 from 2 peers. ETA 10.57 sec (refresh in 4.23 sec)\n",
            "Dec 10 09:20:16.794 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 5792 samples for epoch #74 from 2 peers. ETA 4.02 sec (refresh in 1.61 sec)\n",
            "Dec 10 09:20:18.617 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8128 samples for epoch #74 from 2 peers. ETA 1.30 sec (refresh in 0.52 sec)\n",
            "Dec 10 09:20:19.428 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9248 samples for epoch #74 from 2 peers. ETA 0.26 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:20:19.717 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 75\n",
            "Dec 10 09:20:19.762 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:20:20.127 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #75 from 2 peers. ETA 6.73 sec (refresh in 2.69 sec)\n",
            "Dec 10 09:20:23.160 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #75 from 2 peers. ETA 3.70 sec (refresh in 1.48 sec)\n",
            "Dec 10 09:20:23.451 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:20:23.455 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:20:24.859 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1792 samples for epoch #75 from 2 peers. ETA 8.72 sec (refresh in 3.49 sec)\n",
            "Dec 10 09:20:28.605 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6848 samples for epoch #75 from 2 peers. ETA 2.13 sec (refresh in 0.85 sec)\n",
            "Dec 10 09:20:29.688 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7872 samples for epoch #75 from 2 peers. ETA 1.74 sec (refresh in 0.70 sec)\n",
            "Dec 10 09:20:30.622 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8736 samples for epoch #75 from 2 peers. ETA 0.97 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:20:31.359 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9440 samples for epoch #75 from 2 peers. ETA 0.28 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:20:31.690 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 76\n",
            "Dec 10 09:20:31.771 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:20:32.058 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #76 from 2 peers. ETA 10.71 sec (refresh in 4.28 sec)\n",
            "Dec 10 09:20:35.397 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:20:35.402 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:20:36.581 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1536 samples for epoch #76 from 2 peers. ETA 9.98 sec (refresh in 3.99 sec)\n",
            "Dec 10 09:20:40.789 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7904 samples for epoch #76 from 2 peers. ETA 1.14 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:20:41.521 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8992 samples for epoch #76 from 2 peers. ETA 0.39 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:20:41.947 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 77\n",
            "Dec 10 09:20:42.008 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:20:42.261 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 0 samples for epoch #77 from 2 peers. ETA 6.99 sec (refresh in 2.79 sec)\n",
            "Dec 10 09:20:45.256 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #77 from 2 peers. ETA 4.23 sec (refresh in 1.69 sec)\n",
            "Dec 10 09:20:45.570 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:20:45.572 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:20:47.167 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2048 samples for epoch #77 from 2 peers. ETA 6.80 sec (refresh in 2.72 sec)\n",
            "Dec 10 09:20:50.128 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6464 samples for epoch #77 from 2 peers. ETA 1.99 sec (refresh in 0.79 sec)\n",
            "Dec 10 09:20:51.166 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8064 samples for epoch #77 from 2 peers. ETA 0.93 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:20:51.887 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9152 samples for epoch #77 from 2 peers. ETA 0.32 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:20:52.231 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 78\n",
            "Dec 10 09:20:52.284 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:20:52.592 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #78 from 2 peers. ETA 6.52 sec (refresh in 2.61 sec)\n",
            "Dec 10 09:20:55.407 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #78 from 2 peers. ETA 3.71 sec (refresh in 1.48 sec)\n",
            "Dec 10 09:20:55.958 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaged parameters with 2 peers\n",
            "Dec 10 09:20:55.961 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:20:57.146 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1024 samples for epoch #78 from 2 peers. ETA 19.55 sec (refresh in 7.82 sec)\n",
            "Dec 10 09:21:05.005 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 10784 samples for epoch #78 from 2 peers. ETA 0.00 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:21:05.029 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 79\n",
            "Dec 10 09:21:05.090 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:21:05.513 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #79 from 2 peers. ETA 7.58 sec (refresh in 3.03 sec)\n",
            "Dec 10 09:21:08.553 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #79 from 2 peers. ETA 5.53 sec (refresh in 2.21 sec)\n",
            "Dec 10 09:21:10.769 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #79 from 2 peers. ETA 4.03 sec (refresh in 1.61 sec)\n",
            "Dec 10 09:21:12.390 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #79 from 2 peers. ETA 2.93 sec (refresh in 1.17 sec)\n",
            "Dec 10 09:21:13.568 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #79 from 2 peers. ETA 2.13 sec (refresh in 0.85 sec)\n",
            "Dec 10 09:21:14.429 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #79 from 2 peers. ETA 1.55 sec (refresh in 0.62 sec)\n",
            "Dec 10 09:21:15.036 [\u001b[1m\u001b[31mERROR\u001b[0m] [\u001b[1mhivemind.averaging.averager._step:480\u001b[0m] Averaging step failed: could not find a group\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/hivemind/averaging/averager.py\", line 450, in _step\n",
            "    raise AllreduceException(\"Averaging step failed: could not find a group\")\n",
            "hivemind.averaging.partition.AllreduceException: Averaging step failed: could not find a group\n",
            "Dec 10 09:21:15.040 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaging failed with <class 'hivemind.averaging.partition.AllreduceException'>\n",
            "Dec 10 09:21:15.044 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:21:15.061 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #79 from 2 peers. ETA 1.12 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:21:15.566 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 512 samples for epoch #79 from 2 peers. ETA 17.85 sec (refresh in 7.14 sec)\n",
            "Dec 10 09:21:22.711 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7968 samples for epoch #79 from 2 peers. ETA 1.40 sec (refresh in 0.56 sec)\n",
            "Dec 10 09:21:23.275 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8544 samples for epoch #79 from 2 peers. ETA 0.99 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:21:23.801 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8992 samples for epoch #79 from 2 peers. ETA 0.78 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:21:24.314 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9344 samples for epoch #79 from 2 peers. ETA 0.53 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:21:24.821 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9728 samples for epoch #79 from 2 peers. ETA 0.21 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:21:25.073 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 80\n",
            "Dec 10 09:21:25.171 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:21:25.329 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #80 from 2 peers. ETA 9.01 sec (refresh in 3.61 sec)\n",
            "Dec 10 09:21:28.941 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #80 from 2 peers. ETA 6.76 sec (refresh in 2.70 sec)\n",
            "Dec 10 09:21:31.653 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #80 from 2 peers. ETA 5.06 sec (refresh in 2.02 sec)\n",
            "Dec 10 09:21:33.682 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #80 from 2 peers. ETA 3.79 sec (refresh in 1.52 sec)\n",
            "Dec 10 09:21:35.065 [\u001b[1m\u001b[31mERROR\u001b[0m] [\u001b[1mhivemind.averaging.averager._step:480\u001b[0m] Averaging step failed: could not find a group\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/hivemind/averaging/averager.py\", line 450, in _step\n",
            "    raise AllreduceException(\"Averaging step failed: could not find a group\")\n",
            "hivemind.averaging.partition.AllreduceException: Averaging step failed: could not find a group\n",
            "Dec 10 09:21:35.070 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaging failed with <class 'hivemind.averaging.partition.AllreduceException'>\n",
            "Dec 10 09:21:35.073 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:21:35.215 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 160 samples for epoch #80 from 2 peers. ETA 21.80 sec (refresh in 8.72 sec)\n",
            "Dec 10 09:21:43.947 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7648 samples for epoch #80 from 2 peers. ETA 1.69 sec (refresh in 0.68 sec)\n",
            "Dec 10 09:21:44.632 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8320 samples for epoch #80 from 2 peers. ETA 1.21 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:21:45.136 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8864 samples for epoch #80 from 2 peers. ETA 0.76 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:21:45.647 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9376 samples for epoch #80 from 2 peers. ETA 0.42 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:21:46.090 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 81\n",
            "Dec 10 09:21:46.142 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:21:46.157 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #81 from 2 peers. ETA 7.12 sec (refresh in 2.85 sec)\n",
            "Dec 10 09:21:49.011 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #81 from 2 peers. ETA 5.10 sec (refresh in 2.04 sec)\n",
            "Dec 10 09:21:51.063 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #81 from 2 peers. ETA 3.65 sec (refresh in 1.46 sec)\n",
            "Dec 10 09:21:52.528 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #81 from 2 peers. ETA 2.61 sec (refresh in 1.04 sec)\n",
            "Dec 10 09:21:53.579 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #81 from 2 peers. ETA 1.87 sec (refresh in 0.75 sec)\n",
            "Dec 10 09:21:54.331 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #81 from 2 peers. ETA 1.34 sec (refresh in 0.53 sec)\n",
            "Dec 10 09:21:54.873 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #81 from 2 peers. ETA 0.95 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:21:55.380 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #81 from 2 peers. ETA 0.59 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:21:55.890 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #81 from 2 peers. ETA 0.23 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:21:56.095 [\u001b[1m\u001b[31mERROR\u001b[0m] [\u001b[1mhivemind.averaging.averager._step:480\u001b[0m] Averaging step failed: could not find a group\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/hivemind/averaging/averager.py\", line 450, in _step\n",
            "    raise AllreduceException(\"Averaging step failed: could not find a group\")\n",
            "hivemind.averaging.partition.AllreduceException: Averaging step failed: could not find a group\n",
            "Dec 10 09:21:56.105 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaging failed with <class 'hivemind.averaging.partition.AllreduceException'>\n",
            "Dec 10 09:21:56.107 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:21:56.178 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 82\n",
            "Dec 10 09:21:56.267 [\u001b[1m\u001b[34mINFO\u001b[0m] Waiting for delayed updates to finish...\n",
            "Dec 10 09:21:56.398 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #82 from 2 peers. ETA 22.46 sec (refresh in 8.98 sec)\n",
            "Dec 10 09:22:05.390 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 32 samples for epoch #82 from 1 peers. ETA 282.43 sec (refresh in 10.00 sec)\n",
            "Dec 10 09:22:06.178 [\u001b[1m\u001b[31mERROR\u001b[0m] [\u001b[1mhivemind.averaging.averager._step:480\u001b[0m] Averaging step failed: could not find a group\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/hivemind/averaging/averager.py\", line 450, in _step\n",
            "    raise AllreduceException(\"Averaging step failed: could not find a group\")\n",
            "hivemind.averaging.partition.AllreduceException: Averaging step failed: could not find a group\n",
            "Dec 10 09:22:06.181 [\u001b[1m\u001b[34mINFO\u001b[0m] Averaging failed with <class 'hivemind.averaging.partition.AllreduceException'>\n",
            "Dec 10 09:22:06.185 [\u001b[1m\u001b[34mINFO\u001b[0m] Received parameters from background averaging round\n",
            "Dec 10 09:22:15.398 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8000 samples for epoch #82 from 1 peers. ETA 1.88 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:22:15.903 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8480 samples for epoch #82 from 1 peers. ETA 1.45 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:22:16.411 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9024 samples for epoch #82 from 1 peers. ETA 0.90 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:22:16.916 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9536 samples for epoch #82 from 1 peers. ETA 0.42 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:22:17.348 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 83\n",
            "Dec 10 09:22:17.421 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #83 from 1 peers. ETA 9.38 sec (refresh in 2.35 sec)\n",
            "Dec 10 09:22:19.782 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2496 samples for epoch #83 from 1 peers. ETA 6.97 sec (refresh in 1.74 sec)\n",
            "Dec 10 09:22:21.530 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 4320 samples for epoch #83 from 1 peers. ETA 5.58 sec (refresh in 1.40 sec)\n",
            "Dec 10 09:22:22.931 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 5760 samples for epoch #83 from 1 peers. ETA 4.15 sec (refresh in 1.04 sec)\n",
            "Dec 10 09:22:23.986 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6560 samples for epoch #83 from 1 peers. ETA 4.58 sec (refresh in 1.15 sec)\n",
            "Dec 10 09:22:25.143 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7424 samples for epoch #83 from 1 peers. ETA 3.34 sec (refresh in 0.84 sec)\n",
            "Dec 10 09:22:25.992 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8032 samples for epoch #83 from 1 peers. ETA 2.59 sec (refresh in 0.65 sec)\n",
            "Dec 10 09:22:26.646 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8512 samples for epoch #83 from 1 peers. ETA 2.06 sec (refresh in 0.52 sec)\n",
            "Dec 10 09:22:27.166 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8864 samples for epoch #83 from 1 peers. ETA 1.60 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:22:27.687 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9216 samples for epoch #83 from 1 peers. ETA 1.11 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:22:28.191 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9696 samples for epoch #83 from 1 peers. ETA 0.32 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:22:28.488 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 84\n",
            "Dec 10 09:22:28.696 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 160 samples for epoch #84 from 1 peers. ETA 10.45 sec (refresh in 2.61 sec)\n",
            "Dec 10 09:22:31.313 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2912 samples for epoch #84 from 1 peers. ETA 6.64 sec (refresh in 1.66 sec)\n",
            "Dec 10 09:22:32.979 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 4608 samples for epoch #84 from 1 peers. ETA 5.05 sec (refresh in 1.26 sec)\n",
            "Dec 10 09:22:34.246 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 5920 samples for epoch #84 from 1 peers. ETA 3.87 sec (refresh in 0.97 sec)\n",
            "Dec 10 09:22:35.217 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6944 samples for epoch #84 from 1 peers. ETA 2.81 sec (refresh in 0.70 sec)\n",
            "Dec 10 09:22:35.934 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7680 samples for epoch #84 from 1 peers. ETA 2.20 sec (refresh in 0.55 sec)\n",
            "Dec 10 09:22:36.490 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8224 samples for epoch #84 from 1 peers. ETA 1.78 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:22:36.997 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8736 samples for epoch #84 from 1 peers. ETA 1.22 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:22:37.505 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9248 samples for epoch #84 from 1 peers. ETA 0.71 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:22:38.019 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9728 samples for epoch #84 from 1 peers. ETA 0.26 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:22:38.326 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 85\n",
            "Dec 10 09:22:38.528 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 96 samples for epoch #85 from 1 peers. ETA 13.18 sec (refresh in 3.30 sec)\n",
            "Dec 10 09:22:41.833 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2496 samples for epoch #85 from 1 peers. ETA 10.50 sec (refresh in 2.62 sec)\n",
            "Dec 10 09:22:44.471 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 5024 samples for epoch #85 from 1 peers. ETA 4.79 sec (refresh in 1.20 sec)\n",
            "Dec 10 09:22:45.688 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6208 samples for epoch #85 from 1 peers. ETA 3.72 sec (refresh in 0.93 sec)\n",
            "Dec 10 09:22:46.624 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7200 samples for epoch #85 from 1 peers. ETA 2.79 sec (refresh in 0.70 sec)\n",
            "Dec 10 09:22:47.326 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7936 samples for epoch #85 from 1 peers. ETA 1.95 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:22:47.835 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8448 samples for epoch #85 from 1 peers. ETA 1.50 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:22:48.342 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8992 samples for epoch #85 from 1 peers. ETA 0.98 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:22:48.847 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9504 samples for epoch #85 from 1 peers. ETA 0.46 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:22:49.334 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 86\n",
            "Dec 10 09:22:49.364 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 0 samples for epoch #86 from 1 peers. ETA 9.77 sec (refresh in 2.44 sec)\n",
            "Dec 10 09:22:51.817 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2528 samples for epoch #86 from 1 peers. ETA 7.28 sec (refresh in 1.82 sec)\n",
            "Dec 10 09:22:53.646 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 4032 samples for epoch #86 from 1 peers. ETA 8.16 sec (refresh in 2.04 sec)\n",
            "Dec 10 09:22:55.690 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 5504 samples for epoch #86 from 1 peers. ETA 6.36 sec (refresh in 1.59 sec)\n",
            "Dec 10 09:22:57.283 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6656 samples for epoch #86 from 1 peers. ETA 4.57 sec (refresh in 1.14 sec)\n",
            "Dec 10 09:22:58.432 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7712 samples for epoch #86 from 1 peers. ETA 2.19 sec (refresh in 0.55 sec)\n",
            "Dec 10 09:22:58.992 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8288 samples for epoch #86 from 1 peers. ETA 1.69 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:22:59.499 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8800 samples for epoch #86 from 1 peers. ETA 1.17 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:23:00.015 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9312 samples for epoch #86 from 1 peers. ETA 0.66 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:23:00.529 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9824 samples for epoch #86 from 1 peers. ETA 0.14 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:23:00.691 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 87\n",
            "Dec 10 09:23:01.035 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 320 samples for epoch #87 from 1 peers. ETA 9.42 sec (refresh in 2.36 sec)\n",
            "Dec 10 09:23:03.398 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 2784 samples for epoch #87 from 1 peers. ETA 6.79 sec (refresh in 1.70 sec)\n",
            "Dec 10 09:23:05.112 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 4288 samples for epoch #87 from 1 peers. ETA 6.97 sec (refresh in 1.74 sec)\n",
            "Dec 10 09:23:06.861 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 5728 samples for epoch #87 from 1 peers. ETA 5.11 sec (refresh in 1.28 sec)\n",
            "Dec 10 09:23:08.169 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6656 samples for epoch #87 from 1 peers. ETA 4.79 sec (refresh in 1.20 sec)\n",
            "Dec 10 09:23:09.481 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6816 samples for epoch #87 from 1 peers. ETA 11.19 sec (refresh in 2.80 sec)\n",
            "Dec 10 09:23:12.313 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7456 samples for epoch #87 from 1 peers. ETA 8.87 sec (refresh in 2.22 sec)\n",
            "Dec 10 09:23:14.546 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8800 samples for epoch #87 from 1 peers. ETA 1.71 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:23:15.060 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9184 samples for epoch #87 from 1 peers. ETA 1.05 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:23:15.568 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9536 samples for epoch #87 from 1 peers. ETA 0.64 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:23:16.094 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9888 samples for epoch #87 from 1 peers. ETA 0.14 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:23:16.265 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 88\n",
            "Dec 10 09:23:16.602 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 224 samples for epoch #88 from 1 peers. ETA 13.61 sec (refresh in 3.40 sec)\n",
            "Dec 10 09:23:20.013 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 3776 samples for epoch #88 from 1 peers. ETA 5.67 sec (refresh in 1.42 sec)\n",
            "Dec 10 09:23:21.436 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 5248 samples for epoch #88 from 1 peers. ETA 4.53 sec (refresh in 1.13 sec)\n",
            "Dec 10 09:23:22.577 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6400 samples for epoch #88 from 1 peers. ETA 3.55 sec (refresh in 0.89 sec)\n",
            "Dec 10 09:23:23.480 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7360 samples for epoch #88 from 1 peers. ETA 2.51 sec (refresh in 0.63 sec)\n",
            "Dec 10 09:23:24.123 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8000 samples for epoch #88 from 1 peers. ETA 1.86 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:23:24.630 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 8512 samples for epoch #88 from 1 peers. ETA 1.47 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:23:25.138 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9024 samples for epoch #88 from 1 peers. ETA 0.87 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:23:25.643 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 9536 samples for epoch #88 from 1 peers. ETA 0.44 sec (refresh in 0.50 sec)\n",
            "Dec 10 09:23:26.070 [\u001b[1m\u001b[34mINFO\u001b[0m] Transitioning to epoch 89\n",
            "Dec 10 09:23:26.151 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 64 samples for epoch #89 from 1 peers. ETA 9.49 sec (refresh in 2.37 sec)\n",
            "Dec 10 09:23:28.538 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 1888 samples for epoch #89 from 1 peers. ETA 11.08 sec (refresh in 2.77 sec)\n",
            "Dec 10 09:23:31.317 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 3840 samples for epoch #89 from 1 peers. ETA 8.86 sec (refresh in 2.21 sec)\n",
            "Dec 10 09:23:33.539 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 6112 samples for epoch #89 from 1 peers. ETA 3.90 sec (refresh in 0.98 sec)\n",
            "Dec 10 09:23:34.526 [\u001b[1m\u001b[34mINFO\u001b[0m] my_cifar_run accumulated 7104 samples for epoch #89 from 1 peers. ETA 2.86 sec (refresh in 0.72 sec)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import hivemind\n",
        "\n",
        "# Create dataset and model, same as in the basic tutorial\n",
        "# For this basic tutorial, we download only the training set\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "model = nn.Sequential(nn.Conv2d(3, 16, (5, 5)), nn.MaxPool2d(2, 2), nn.ReLU(),\n",
        "                      nn.Conv2d(16, 32, (5, 5)), nn.MaxPool2d(2, 2), nn.ReLU(),\n",
        "                      nn.Flatten(), nn.Linear(32 * 5 * 5, 10))\n",
        "opt = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Create DHT: a decentralized key-value storage shared between peers\n",
        "# dht = hivemind.DHT(start=True)\n",
        "\n",
        "# dht = hivemind.DHT(\n",
        "#     host_maddrs=[\"/ip4/0.0.0.0/tcp/0\", \"/ip4/0.0.0.0/udp/0/quic\"],\n",
        "#     initial_peers=[\n",
        "#         \"/ip4/3.140.223.7/tcp/16497/p2p/12D3KooWBCdJnh6r7n4L4zxCd3iEofpNDbJKLXQ5gq1DqK6RYbcH\",\n",
        "#     ], start=True)\n",
        "\n",
        "# dht = hivemind.DHT(\n",
        "#     host_maddrs=[\"/ip4/0.0.0.0/tcp/0\", \"/ip4/0.0.0.0/udp/0/quic\"],\n",
        "#     initial_peers=[\n",
        "#         f\"/ip4/{ip_address}/tcp/16497/p2p/12D3KooWBCdJnh6r7n4L4zxCd3iEofpNDbJKLXQ5gq1DqK6RYbcH\",\n",
        "#     ], start=True,client_mode=True)\n",
        "\n",
        "\n",
        "\n",
        "print(\"To join the training, use initial_peers =\", [str(addr) for addr in dht.get_visible_maddrs()])\n",
        "\n",
        "# Set up a decentralized optimizer that will average with peers in background\n",
        "opt = hivemind.Optimizer(\n",
        "    dht=dht,                  # use a DHT that is connected with other peers\n",
        "    run_id='my_cifar_run',    # unique identifier of this collaborative run\n",
        "    batch_size_per_step=32,   # each call to opt.step adds this many samples towards the next epoch\n",
        "    target_batch_size=10000,  # after peers collectively process this many samples, average weights and begin the next epoch\n",
        "    optimizer=opt,            # wrap the SGD optimizer defined above\n",
        "    use_local_updates=True,   # perform optimizer steps with local gradients, average parameters in background\n",
        "    matchmaking_time=3.0,     # when averaging parameters, gather peers in background for up to this many seconds\n",
        "    averaging_timeout=10.0,   # give up on averaging if not successful in this many seconds\n",
        "    verbose=True              # print logs incessently\n",
        ")\n",
        "\n",
        "# Note: if you intend to use GPU, switch to it only after the decentralized optimizer is created\n",
        "with tqdm() as progressbar:\n",
        "    while True:\n",
        "        for x_batch, y_batch in torch.utils.data.DataLoader(trainset, shuffle=True, batch_size=32):\n",
        "            opt.zero_grad()\n",
        "            loss = F.cross_entropy(model(x_batch), y_batch)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            progressbar.desc = f\"loss = {loss.item():.3f}\"\n",
        "            progressbar.update()\n",
        "\n",
        "# num_epochs = 2  # 设置你想要的 epoch 数\n",
        "# for epoch in range(num_epochs):\n",
        "#     with tqdm(total=len(trainset), desc=f\"Epoch {epoch+1}/{num_epochs}\") as progressbar:\n",
        "#         for x_batch, y_batch in torch.utils.data.DataLoader(trainset, shuffle=True, batch_size=32):\n",
        "#             opt.zero_grad()\n",
        "#             loss = F.cross_entropy(model(x_batch), y_batch)\n",
        "#             loss.backward()\n",
        "#             opt.step()\n",
        "\n",
        "#             progressbar.set_postfix(loss=loss.item())\n",
        "#             progressbar.update(len(x_batch))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyJ-Vv002idw"
      },
      "source": [
        "To join the training, use initial_peers = ['/ip4/127.0.0.1/tcp/42905/p2p/12D3KooWSZVkzKhaTNAqohpaRbhXFGUbG18mbxczFktxLB4EEMwV']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJLVT7CD2i2r"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02e3ae6e1e28406d90a8867e66424e64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05e661dcbd6f44bfaa7f22c1354e6810": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "080d26b376f243f6b33655b978f7d822": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e682648ddb544baa373415eb141a9eb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1da0d0041ea84b989734b40d38cbda0c",
            "value": 1
          }
        },
        "0ea3abd6bb15432384c71d97f5819508": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99e01f47b4744683a39650e920209823",
            "placeholder": "​",
            "style": "IPY_MODEL_adef8f315fe545ac9b8f7322cbaf76e4",
            "value": " 17216/? [18:38&lt;00:00, 32.83it/s]"
          }
        },
        "0f3a0a362a714d8bbb6f96eac7c9e2a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8eb16492fdbe468cb5e4833997176ef4",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05e661dcbd6f44bfaa7f22c1354e6810",
            "value": 170498071
          }
        },
        "18f0df7e5e844cf48109442f79851652": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc194b33400f4e65a64a071e59e9f430",
            "placeholder": "​",
            "style": "IPY_MODEL_756252a23c474f0981707478ea6d9ce3",
            "value": " 170499072/? [00:11&lt;00:00, 18588230.15it/s]"
          }
        },
        "1da0d0041ea84b989734b40d38cbda0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b147433804f429aafe1416e5e1056fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "756252a23c474f0981707478ea6d9ce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8eb16492fdbe468cb5e4833997176ef4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91a0adb1c7234f458ba0ee2b0d96ea38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "943cc0e49e1e4211b718440252381750": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a21052c85ece4b4fa65a6f0ce72c99ae",
            "placeholder": "​",
            "style": "IPY_MODEL_e65a65f7bcbc42828ae6601a7c2addd8",
            "value": ""
          }
        },
        "99e01f47b4744683a39650e920209823": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e682648ddb544baa373415eb141a9eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a21052c85ece4b4fa65a6f0ce72c99ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a92722172922468b93e0065e8992a549": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c149fb64aee540518facfc37823db46b",
            "placeholder": "​",
            "style": "IPY_MODEL_4b147433804f429aafe1416e5e1056fd",
            "value": "loss = 0.583: "
          }
        },
        "abfa51b4884042b8ab465752d3e4a7df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a92722172922468b93e0065e8992a549",
              "IPY_MODEL_080d26b376f243f6b33655b978f7d822",
              "IPY_MODEL_0ea3abd6bb15432384c71d97f5819508"
            ],
            "layout": "IPY_MODEL_02e3ae6e1e28406d90a8867e66424e64"
          }
        },
        "adef8f315fe545ac9b8f7322cbaf76e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c149fb64aee540518facfc37823db46b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4208eb89de342aba6b90408c476312f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_943cc0e49e1e4211b718440252381750",
              "IPY_MODEL_0f3a0a362a714d8bbb6f96eac7c9e2a2",
              "IPY_MODEL_18f0df7e5e844cf48109442f79851652"
            ],
            "layout": "IPY_MODEL_91a0adb1c7234f458ba0ee2b0d96ea38"
          }
        },
        "dc194b33400f4e65a64a071e59e9f430": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e65a65f7bcbc42828ae6601a7c2addd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}